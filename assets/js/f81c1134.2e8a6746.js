"use strict";(self.webpackChunkaurora_docs=self.webpackChunkaurora_docs||[]).push([[8130],{116:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/how-to-bridge-liquidity-to-aurora","metadata":{"permalink":"/blog/how-to-bridge-liquidity-to-aurora","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/how-to-bridge-liquidity-to-aurora.md","source":"@site/blog/how-to-bridge-liquidity-to-aurora.md","title":"How to bridge liquidity to Aurora?","description":"We will focus on stablecoins, explain their types on Aurora, and take a look at how to bridge them in different ways from other ecosystems","date":"2024-05-22T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":1.3366666666666667,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"How to bridge liquidity to Aurora?","description":"We will focus on stablecoins, explain their types on Aurora, and take a look at how to bridge them in different ways from other ecosystems","date":"2024-05-22","authors":["slava"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1716383835-liqaur.png"},"unlisted":false,"nextItem":{"title":"How to get your tokens from Bastion contracts?","permalink":"/blog/hot-to-get-your-tokens-from-bastion-contract"}},"content":"In this article, we will discuss how to bridge liquidity to Aurora in the most convenient way. We will focus on stablecoins, explain why we have four types of these on Aurora, and take a look at how to bridge them in different ways. Note that this whole bridging process also applies to the ERC-20 tokens.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The global picture \u2013 What stables do we have?\\n\\nFirst, let\u2019s mention three main actors here: Ethereum, Near, and Aurora blockchains. Second, we will consider the two most popular stables, USDC and USDT. To connect the ecosystem, we will use the Rainbow Bridge.\\\\\\n\\\\\\nLet\u2019s take a look at how USDC and USDT tokens are bridged via Rainbow Bridge from Ethereum to Near:\\n\\n![](https://www.datocms-assets.com/95026/1716383440-screenshot-2024-05-21-at-11-51-56.png)\\n\\nAs you can see, Near has the corresponding bridged versions of Ethereum\u2019s tokens: USDC.e and USDT.e (in green), as well as the Near native [*USDC*](https://nearblocks.io/address/17208628f84f5d6ad33f0da3bbbeb27ffcb398eac501a31bd6ad2011e36133a1) and [*USDT*](https://nearblocks.io/address/usdt.tether-token.near) (in blue).\\n\\nThis is needed to separate the bridged liquidity from the native one on the Near blockchain. You may also have heard about such tokens being wrapped. All these versions are interchangeable using [*ref.finance,*](https://app.ref.finance/#a0b86991c6218b36c1d19d4a2e9eb0ce3606eb48.factory.bridge.near%7C17208628f84f5d6ad33f0da3bbbeb27ffcb398eac501a31bd6ad2011e36133a1) on Near Protocol, as depicted by a green arrow in the image.\\n\\nA similar story repeats with Aurora by bridging tokens from Ethereum and Near via Rainbow Bridge. So we\u2019re getting the next picture:\\n\\n![](https://www.datocms-assets.com/95026/1716383465-screenshot-2024-05-21-at-11-53-42.png)\\n\\nThat is why, on Aurora, we have 4 different tokens representing stables. USDC and USDT tokens are the wrapped analog for the Near native tokens. And USDC.e and USDT.e \u2013 for the Ethereum tokens. All these versions are interchangeable by using [*Aurora+ Swap*](https://aurora.plus/swap) feature supported by 1inch.\\n\\n## How to transfer liquidity to Aurora?\\n\\nAs you have seen in the picture above, the most natural way to transfer tokens from Ethereum or Near is to use the [*Rainbow Bridge*](https://rainbowbridge.app/). But we will talk about other variants too. Here is a picture summarizing the most popular ones:\\n\\n![](https://www.datocms-assets.com/95026/1716383517-screenshot-2024-05-21-at-11-16-27.png)\\n\\nIf you have tokens on CEX that support Near, you can use [Forwarder](https://doc.aurora.dev/launch-chain/forwarder/introduction), which allows you to transfer them from CEX to your Aurora address. See Binance instructions [here](https://doc.aurora.dev/launch-chain/forwarder/how-to-use/binance).\\n\\nFor any other EVMs, you can use the [Stargate](https://stargate.finance/) (coming soon) or [Meson](https://meson.fi/) bridges. Stargate supports the Near Native USDC pool on Aurora. You can always [*swap you tokens on Aurora+*](https://aurora.plus/swap), after bridging.\\\\\\n\\\\\\nThat is it! Thank you for reading us!\\\\\\nIf you have any questions or suggestions, please visit our [Discord Community](https://discord.com/invite/WXfbGsSUbT)!"},{"id":"/hot-to-get-your-tokens-from-bastion-contract","metadata":{"permalink":"/blog/hot-to-get-your-tokens-from-bastion-contract","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/hot-to-get-your-tokens-from-bastion-contract.md","source":"@site/blog/hot-to-get-your-tokens-from-bastion-contract.md","title":"How to get your tokens from Bastion contracts?","description":"In this article, you will learn how you can retrieve the stables from Bastion by using Aurora Explorer to call its smart contracts","date":"2024-05-17T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":2.84,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"How to get your tokens from Bastion contracts?","description":"In this article, you will learn how you can retrieve the stables from Bastion by using Aurora Explorer to call its smart contracts","date":"2024-05-17","authors":["slava"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1715949186-bastion.png"},"unlisted":false,"prevItem":{"title":"How to bridge liquidity to Aurora?","permalink":"/blog/how-to-bridge-liquidity-to-aurora"},"nextItem":{"title":"Managing Aurora\'s Validator staking with \'near-cli-rs\'","permalink":"/blog/managing-aurora-s-validator-staking-with-near-cli-rs"}},"content":"Recently, we became aware of this issue and the lack of a way to do it in the Bastion UI, so we decided to create a tutorial for everyone to use independently. Big thanks to the people in the community who helped me create and test this tutorial and provided invaluable insights and feedback!\\n\\nTo formulate the problem more precisely, a user has some `cUSDCcUSDTLP` tokens and wants to convert these back to stables. The Bastion project\'s UI doesn\'t allow this today, so the only way is to call smart contracts directly.\\n\\nWe will go through the next steps:\\n\\n* What contracts should we call?\\n* What method should we call, and how?\\n* How to convert `cUSDC` and `cUSDT` into regular stables?\\n\\nWe will use the most convenient way for users to interact with smart contracts\u2014the Explorer. However, devs can always write a script to perform the steps described in this article with Ethers or Web3.js.\\n\\nLet\'s go!\\n\\n\x3c!-- truncate --\x3e\\n\\n## What contracts?\\n\\nThe main actor of this article will be [`SwapFlashLoan` contract](https://explorer.aurora.dev/address/0x6287e912a9Ccd4D5874aE15d3c89556b2a05f080?tab=write_contract):\\n\\n![](https://www.datocms-assets.com/95026/1715902943-screenshot-2024-05-17-at-00-39-24.png)\\n\\nThe plan is:\\n\\n1. Approve [cUSDCcUSDTLP token](https://explorer.aurora.dev/address/0x0039f0641156cac478b0DebAb086D78B66a69a01?tab=write_proxy) to be used by the `SwapFlashLoan` contract.\\n2. Get cUSDC and cUSDT from `SwapFlashLoan`.\\n3. Redeem [cUSDC](https://explorer.aurora.dev/token/0xe5308dc623101508952948b141fD9eaBd3337D99) and [cUSDT](https://explorer.mainnet.aurora.dev/address/0x845E15A441CFC1871B7AC610b0E922019BaD9826) from their contracts to get stables.\\n\\n## Approve cUSDCcUSDTLP\\n\\nLet\'s start with connecting your wallet. To do this, please open [cUSDCcUSDTLP token contract](https://explorer.aurora.dev/address/0x0039f0641156cac478b0DebAb086D78B66a69a01?tab=write_proxy) and click Contract -> Write Contract -> Connect Wallet:\\n\\n![](https://www.datocms-assets.com/95026/1715948365-screenshot-2024-05-17-at-13-19-16.png)\\n\\nThen you will see the next popup to connect your wallet:\\n\\n![](https://www.datocms-assets.com/95026/1715903570-screenshot-2024-05-17-at-00-52-39.png)\\n\\nWe recommend using [the Aurora Pass wallet](https://auroracloud.dev/pass), which you can connect via the Wallet Connect option above and a QR code. It offers 50 free transactions a month on the Aurora blockchain and is a very user-friendly mobile wallet.\\n\\nAfter connecting it, we\'re ready to move further.\\\\\\n\\\\\\nIf you scroll down, you will see the contract methods, and here is the one we need \u2013 `approve` and enter the arguments there with `spender` being the `swapFlashLoan` contract address and `amount` equal to the number of tokens you want to get back (probably all you have right now):\\n\\n![](https://www.datocms-assets.com/95026/1715948641-screenshot-2024-05-17-at-13-22-10.png)\\n\\nNow, we\'re ready to execute the transaction, just click the \\"Write\\" button on the right and confirm it in your wallet!\\n\\n## Get cUSDC and cUSDT\\n\\nLet\'s open now the [`SwapFlashLoan` contract](https://explorer.aurora.dev/address/0x6287e912a9Ccd4D5874aE15d3c89556b2a05f080?tab=write_contract). Go to the Contract -> Write Contract tab. If you scroll down, you will see the contract methods, and here is the one we need \u2013 `removeLiquidity`:\\n\\n![](https://www.datocms-assets.com/95026/1715903828-screenshot-2024-05-17-at-00-56-14.png)\\n\\nWe\'re unsure about the arguments here yet, so let\'s find out what values we should use. To do this, we will look at one such transaction, which has already been executed by someone. We need to find it in history. So here is [one](https://explorer.aurora.dev/tx/0x0b079aee0e1feae4c10e127a5535877baee23567f22bc5293a5f885ba8d249f9):\\n\\n![](https://www.datocms-assets.com/95026/1715903950-screenshot-2024-05-17-at-00-58-43.png)\\n\\nYou can see what exactly has happened here during the execution in terms of the token transfers:\\n\\n* `cUSDCcUSDTLP` tokens were burned\\n* `cUSDT` and `cUSDC` tokens were transferred to the caller\\n\\nNow, let\'s scroll down a bit and click on \\"View details\\" link at the left bottom of the page, you will see the arguments of the method used there:\\n\\n![](https://www.datocms-assets.com/95026/1715904026-screenshot-2024-05-17-at-00-58-57.png)\\n\\nWe can conclude by looking at the both screenshots above that:\\n\\n1. `amount` argument is equal to your `cUSDCcUSDTLP` tokens amount with 18 decimals added. E.g. in this case, the user has 2021.941835489438, so the correct value should be 2021294184354893800000. You can use [this tool](https://www.eth-to-wei.com/) to convert your values.\\n2. `deadline` is your time now, with 20 minutes added to it in a timestamp format. You can use [the EpochConverter](https://www.epochconverter.com/) tool to get the correct value. Just add 20 minutes to the datetime there and copy-paste the timestamp value.\\n3. The first value in `minAmounts` corresponds to the `cUSDT` token amount transferred back, and the second one is for the `cUSDC`. They have 8 decimals, and if you sum them up, you will get your amount of `cUSDCcUSDTLP` tokens. So you can just enter any values which in sum give you a value smaller or equal to the `amount`.\\n\\nWe\'re ready to execute the method now. Just enter the correct arguments to your Explorer tab, it should look like this:\\n\\n![](https://www.datocms-assets.com/95026/1715907308-screenshot-2024-05-17-at-01-54-36.png)\\n\\nAfter that, just click the \\"Write\\" button and confirm the transaction in your wallet.\\\\\\nThat is it! Now you got back your `cUSDC` and `cUSDT` tokens.\\n\\n## How to convert cTokens to stables?\\n\\nTo do this, we will need to point our attention to these contracts:\\n\\n* cUSDT: [0x845E15A441CFC1871B7AC610b0E922019BaD9826](https://explorer.mainnet.aurora.dev/address/0x845E15A441CFC1871B7AC610b0E922019BaD9826)\\n* cUSDC: [0xe5308dc623101508952948b141fD9eaBd3337D99](https://explorer.aurora.dev/token/0xe5308dc623101508952948b141fD9eaBd3337D99)\\n\\nFor both of them, the process will look the same, so let\'s just talk about `cUSDT` case. To unwrap you need to call this method \u2013 \\\\`redeem\\\\`:\\n\\n![](https://www.datocms-assets.com/95026/1715907708-screenshot-2024-05-17-at-02-01-35.png)\\n\\nIt has only one argument, which is the amount of tokens to unwrap with 8 decimals added to it. So, for [the transaction from the previous section](https://explorer.aurora.dev/tx/0x0b079aee0e1feae4c10e127a5535877baee23567f22bc5293a5f885ba8d249f9), it should be 167994638559. It is the amount of the `cUSDT` tokens you have received after your `removeLiquidity` call.\\n\\n## Final thoughts\\n\\nThat is it \u2013 you have successfully got your `cUSDCcUSDTLP` tokens converted back to stables. If you need any help or have a similar issue, please come [to our Discord](https://discord.com/invite/dEFJBz8HQV), and we will help you! Thank you for reading!\\\\"},{"id":"/managing-aurora-s-validator-staking-with-near-cli-rs","metadata":{"permalink":"/blog/managing-aurora-s-validator-staking-with-near-cli-rs","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/managing-aurora-s-validator-staking-with-near-cli-rs.md","source":"@site/blog/managing-aurora-s-validator-staking-with-near-cli-rs.md","title":"Managing Aurora\'s Validator staking with \'near-cli-rs\'","description":"Let\'s learn how to manage your staking with Near validators and claim your Aurora validator\'s rewards by using \'near-cli-rs\'","date":"2024-05-10T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":4.93,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"Managing Aurora\'s Validator staking with \'near-cli-rs\'","description":"Let\'s learn how to manage your staking with Near validators and claim your Aurora validator\'s rewards by using \'near-cli-rs\'","date":"2024-05-10","authors":["slava"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1715336122-ncrs.png"},"unlisted":false,"prevItem":{"title":"How to get your tokens from Bastion contracts?","permalink":"/blog/hot-to-get-your-tokens-from-bastion-contract"},"nextItem":{"title":"Plugins for smart contract devs building on Near","permalink":"/blog/plugins-for-smart-contract-devs-building-on-near"}},"content":"In this article, we will discuss how to manage your staking on the Aurora Validator. To recap quickly, Aurora is an EVM-compatible blockchain running as an L2 on the Near Protocol. In the heart of it is an Aurora Engine smart contract. That is why every transaction on Aurora is relayed to the Near and has the corresponding Near transaction. You can read more about this [*here*](/blog/convert-aurora-transaction-into-near-s-one). That is why Aurora doesn\u2019t have its own validators \u2013 we\u2019re just re-using the Near ones.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn January 2023, we re-launched [*our validator*](https://aurora.dev/blog/aurora-relaunches-its-validator) with a new address, [*aurora.pool.near*](https://app.mynearwallet.com/staking/aurora.pool.near). What is curious about it is that it gives you the rewards in AURORA tokens directly on the Near network.\\n\\nRecently, the [*Near Wallet was deprecated*](https://near.org/blog/embracing-decentralization-whats-next-for-the-near-wallet) on the 1st of January, 2024. And that has driven users to other wallets. Unfortunately, many of these don\u2019t support staking capabilities, especially with the non-standard validator as \\\\`aurora.pool.near\\\\` is.\\n\\nSo, based on the recent support experience, we have decided to publish a guide on how to use your terminal on your laptop or PC to manage your staking on the Aurora\u2019s Validator. Let\u2019s look into the details now!\\n\\n## Installing \\\\`near-cli-rs\\\\`\\n\\nNear CLI is your human-friendly companion that helps to interact with Near Protocol from the terminal right away. There are multiple ways to install it, see [*here*](https://github.com/near/near-cli-rs?tab=readme-ov-file#install). I am using Mac, so I will choose the first option and execute in my Terminal:\\n\\n```shell\\ncurl --proto \'=https\' --tlsv1.2 -LsSf https://github.com/near/near-cli-rs/releases/latest/download/near-cli-rs-installer.sh | sh \\n```\\n\\nYou can also run it as an npm package:\\n\\n```undefined\\nnpx near-cli-rs \\n```\\n\\nAfter installation, if you execute `near` command you should be able to see this screen:\\n\\n![](https://www.datocms-assets.com/95026/1714679129-screenshot-2024-05-02-at-20-45-17.png)\\n\\n## Connecting your account\\n\\nNow, let\'s connect your account to the near-cli-rs. To do this, execute the near command and choose the account option, which you\'ve seen in the previous screenshot above, using the `Enter` key.\\n\\nYou will see the next screen saying `What do you want to do with an account?`. Choose the `import-account` option there and press `Enter`:\\n\\n![](https://www.datocms-assets.com/95026/1714679473-screenshot-2024-04-26-at-12-12-20.png)\\n\\nYou will see a screen with different import options:\\n\\n![](https://www.datocms-assets.com/95026/1714679597-screenshot-2024-05-02-at-20-52-57.png)\\n\\nChoose one that fits you! I will try to use `using-web-wallet` option. The browser window with [https://app.mynearwallet.com/](https://app.mynearwallet.com/) will be opened, and you will see a popup asking for your permission to connect:\\n\\n![](https://www.datocms-assets.com/95026/1714679775-screenshot-2024-04-26-at-12-13-22.png)\\n\\nClick the `Connect` button to approve. After that, you will need to confirm this choice by typing your full account name into the popup:\\n\\n![](https://www.datocms-assets.com/95026/1714680087-screenshot-2024-05-02-at-20-59-05.png)\\n\\nThen, you will get the next alert about successful authorization:\\n\\n![](https://www.datocms-assets.com/95026/1714680117-screenshot-2024-05-02-at-20-59-31.png)\\n\\nNow, you can go back to your terminal window, and you will see a message asking you to enter your account name again:\\n\\n![](https://www.datocms-assets.com/95026/1714680166-screenshot-2024-05-02-at-21-00-07.png)\\n\\nEnter it there and press `Enter`. After that, choose a keychain to store your keys. I am choosing the first option there:\\n\\n![](https://www.datocms-assets.com/95026/1714679837-screenshot-2024-04-26-at-12-14-36.png)\\n\\nYou will get the final message that \\\\`... access key is saved in the keychain\\\\` and a console command that can replace this manual process of choosing different options in the future:\\n\\n![](https://www.datocms-assets.com/95026/1714680238-screenshot-2024-05-02-at-21-00-41.png)\\n\\nSo, all of the things we did here could be achieved also with this command:\\n\\n```shell\\nnear account import-account using-web-wallet network-config mainnet\\n```\\n\\nThat is great! As you can see, `near-cli-rs` is teaching you the terminal commands automatically while exploring it!\\\\\\n\\\\\\nYou have added your Near account to `near-cli-rs`, and it is now ready to be used.\\\\\\nLet\'s try it to stake some tokens on the Aurora Validator!\\n\\n## Staking tokens\\n\\nTLDR: to stake your tokens, you need to use the next command:\\n\\n```shell\\nnear staking delegation karkunow.near \\\\\\n     deposit-and-stake \'1 NEAR\' \\\\\\n     aurora.pool.near network-config mainnet \\\\\\n     sign-with-keychain send\\n```\\n\\nLet\'s review the rest of the section to learn the details about how it works with `near-cli`.\\\\\\n\\\\\\nFirst, make sure you know what validator you will use to stake. You can check the list of validators with this command:\\n\\n```shell\\nnear staking validator-list network-config mainnet\\n```\\n\\nI, of course, will use `aurora.pool.near` for this demo.\\n\\nTo stake your tokens, start with executing the `near` command and choosing the `staking` option from the list:\\n\\n![](https://www.datocms-assets.com/95026/1714681089-screenshot-2024-05-02-at-21-14-10.png)\\n\\nNow, choose `delegation`:\\n\\n![](https://www.datocms-assets.com/95026/1714681106-screenshot-2024-05-02-at-21-14-23.png)\\n\\nAnd type your Near account into the console and press Enter. In my case, I have it already listed, so I will just choose mine from the list:\\n\\n![](https://www.datocms-assets.com/95026/1714681129-screenshot-2024-05-02-at-21-14-38.png)\\n\\nAfter that, you need to choose `deposit-and-stake` (not just `stake` or `stake-all`, these options won\'t work if your tokens were not deposited to the validator yet):\\n\\n![](https://www.datocms-assets.com/95026/1715217828-screenshot-2024-05-09-at-02-19-05.png)\\n\\nThen, enter the amount of NEAR tokens to be staked, I am entering 1NEAR for the purpose of this demo:\\n\\n![](https://www.datocms-assets.com/95026/1715218002-screenshot-2024-05-09-at-02-15-57.png)\\n\\nNow, type in your validator address or choose from the list (you can use the `tab` key to autocomplete):\\n\\n![](https://www.datocms-assets.com/95026/1715218061-screenshot-2024-05-09-at-02-16-28.png)\\n\\nChoose the network now, I will opt for the `mainnet`:\\n\\n![](https://www.datocms-assets.com/95026/1715218288-screenshot-2024-05-09-at-02-16-56.png)\\n\\nAfter this, you will see your transaction formed and ready to be signed. By default, I am signing it with my keychain:\\n\\n![](https://www.datocms-assets.com/95026/1715218347-screenshot-2024-05-09-at-02-17-12.png)\\n\\nNow, you can `send` the transaction and execute it:\\n\\n![](https://www.datocms-assets.com/95026/1715218434-screenshot-2024-05-09-at-02-17-47.png)\\n\\nYou will see the transaction ID and a link to the Explorer after the successful execution:\\n\\n![](https://www.datocms-assets.com/95026/1715218479-screenshot-2024-05-09-at-02-19-35.png)\\n\\nWe can visit the Explorer link to see the details of the transaction:\\n\\n## Unstaking tokens\\n\\nTLDR: You just need to use the next command, which is really similar to the one used for staking:\\n\\n```undefined\\nnear staking delegation karkunow.near \\\\\\n     unstake-all \\\\\\n     aurora.pool.near network-config mainnet \\\\\\n     sign-with-keychain send\\n```\\n\\nIf you don\'t want to unstake all the funds, just use the `unstake` option and enter the amount of NEAR tokens you want to get back.\\n\\nNow, let\'s go through a few screenshots to understand better how I got this command from the `near-cli-rs`. As we have learned from the previous section, to manage our staking activities, we just execute:\\n\\n```shell\\nnear staking delegation [your account here](your account here)\\n```\\n\\nNow, if you want to unstake your tokens \u2013 just choose the `unstake-all` or `unstake` option from the list:\\n\\n![](https://www.datocms-assets.com/95026/1715219903-screenshot-2024-05-09-at-02-53-21.png)\\n\\nAfter that, you will be guided through the same screens as for the staking to enter the amount, validator address, network config (mainnet or testnet), and then \u2013 sign and send it. After the execution, you will see:\\n\\n![](https://www.datocms-assets.com/95026/1715219915-screenshot-2024-05-09-at-02-52-57.png)\\n\\nExactly the same command will be formed by `near-cli-rs` after that process. So now, you can use this shortcut instead.\\\\\\n\\\\\\nAfter unstaking, you will need to wait for the 4 epochs on Near blockchain to pass, which will take around 50-60 hours of time. And then, you will be ready to withdraw them and the associated rewards. The rewards will be automatically unlocked together with the unstaked tokens.\\n\\n## Withdrawing tokens\\n\\nI won\'t go into details with the screenshots here. Now, we\'re ready just to use the commands.\\n\\nSo, to withdraw your tokens and rewards, you need to execute this:\\n\\n```undefined\\nnear staking delegation karkunow.near \\\\\\n     withdraw-all \\\\\\n     aurora.pool.near network-config mainnet \\\\\\n     sign-with-keychain send\\n```\\n\\nIf you don\'t want to withdraw all the funds, just use \\\\`withdraw\\\\` and enter the amount of NEAR tokens you want to withdraw.\\n\\nAfter the execution, you will see:\\n\\n![](https://www.datocms-assets.com/95026/1714681248-screenshot-2024-05-02-at-21-17-51.png)\\n\\n## Claiming on Aurora\'s validator\\n\\nAurora\'s validator allows you to farm the AURORA tokens instead of NEAR by staking NEAR on it. It is based [on this smart contract](https://github.com/referencedev/staking-farm/). That is the reason why you need to use another way to claim these rewards in AURORA tokens. Can we do it with `near-cli-rs`? Yes! Let\'s see how it is done.\\\\\\n\\\\\\nI will use two variables to track the staking pool and account:\\n\\n```shell\\nexport STAKINGCONTRACT=aurora.pool.near && \\\\\\nexport MYACCOUNT=karkunow.near\\n```\\n\\nTo track how much tokens you have right now in staking you should execute:\\n\\n```undefined\\nnear contract call-function as-read-only aurora.pool.near \\\\\\n     \'get_unclaimed_reward\' json-args \\\\\\n     \'{\\"account_id\\":\\"\'${MYACCOUNT}\'\\", \\"farm_id\\":0}\' \\\\\\n      network-config mainnet now\\n```\\n\\nYou will see the something similar to the next screen:\\n\\n![](https://www.datocms-assets.com/95026/1715334843-screenshot-2024-05-10-at-10-25-15.png)\\n\\nThe value will be in Wei, so you need to convert it to get the real value of 0.0032 AURORA by multiplying it with 10^-18.\\n\\nTo claim your rewards you need to call the `claim` method on `aurora.pool.near` contract:\\n\\n```undefined\\nnear contract call-function as-transaction aurora.pool.near \\\\\\n     \'claim\' json-args \\\\\\n     \'{\\"account_id\\": \\"\'${MYACCOUNT}\'\\", \\\\\\n       \\"token_id\\": \\"aaaaaa20d9e0e2461697782ef11675f668207961.factory.bridge.near\\"}\' \\\\\\n     prepaid-gas \'100.0 Tgas\' attached-deposit \'1 yoctoNEAR\' \\\\\\n     sign-as karkunow.near /\\n     network-config mainnet /\\n     sign-with-keychain / \\n     send\\n```\\n\\nWe\'re passing the account and NEP-141 AURORA token address to the contract\'s `claim` method. Also we attach 100TGas of gas and deposit 1 yoctoNear to it.\\n\\nAfter the execution, you will get the transaction hash, which you can now track in the explorer:\\n\\n![](https://www.datocms-assets.com/95026/1715335148-screenshot-2024-05-10-at-10-58-39.png)\\n\\nThat is it! You claimed your rewards from the Aurora Validator.\\n\\nIf you want to dive deeper, you can read more docs about the `aurora.pool.near` methods [here](https://github.com/referencedev/staking-farm/blob/master/HowTo.md).\\n\\n## Final thoughts\\n\\nThank you for reading the article! We have learned a lot today!\\\\\\nWe hope that `near-cli-rs` will be an indispensable tool for you while working with the Near ecosystem and that it will make it easier for you to interact with the blockchain.\\\\\\nSee you in the next articles!"},{"id":"/plugins-for-smart-contract-devs-building-on-near","metadata":{"permalink":"/blog/plugins-for-smart-contract-devs-building-on-near","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/plugins-for-smart-contract-devs-building-on-near.md","source":"@site/blog/plugins-for-smart-contract-devs-building-on-near.md","title":"Plugins for smart contract devs building on Near","description":"Let\u2019s discover how \u2018near-plugins\u2019 library could be used by your project, and how it can save you some time during the development of your smart contracts","date":"2024-01-19T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":4.733333333333333,"hasTruncateMarker":true,"authors":[{"name":"Moritz Zielke","title":"Research Engineer","imageURL":"https://www.datocms-assets.com/95026/1705626473-screenshot-2024-01-19-at-01-07-40.png","key":"moritz","page":null}],"frontMatter":{"title":"Plugins for smart contract devs building on Near","description":"Let\u2019s discover how \u2018near-plugins\u2019 library could be used by your project, and how it can save you some time during the development of your smart contracts","date":"2024-01-19","authors":["moritz"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1705627571-np2.png"},"unlisted":false,"prevItem":{"title":"Managing Aurora\'s Validator staking with \'near-cli-rs\'","permalink":"/blog/managing-aurora-s-validator-staking-with-near-cli-rs"},"nextItem":{"title":"Contract Callbacks in XCC","permalink":"/blog/contract-callbacks-in-xcc"}},"content":"Some common functionality is required for many smart contracts. Examples are temporarily pausing certain features, staging and deploying a new version of the contract, and restricting access to contract methods. While such functionality is out of scope for an SDK like `near-sdk-rs`, ideally it is not implemented anew for every smart contract.\\n\\nThe most obvious benefits of an open-source library are reusability and the value it adds to the ecosystem. The smart contract features mentioned above can be tricky to implement and cumbersome to test. Without a library, developers might gloss over functionality that does not add business value but still is critical for security. As `near-plugins` is open-source and used by many developers, there are more engineering hours and eyeballs dedicated to it compared to a solution specific to a single smart contract.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Case study: A counter managing permissions with ACL\\n\\nLet\u2019s look at a case study to see how `near-plugins` can be useful to smart contract developers. We are building a `Counter` that stores its current value and has methods to increment, decrement, and reset the value. It is intentionally kept simple to allow us to focus on how `near-plugins` adds functionality. This is what the contract looks like prior to using any plugins:\\n\\n```rust\\n#[near_bindgen]\\nimpl Counter {\\n    #[init]\\n    pub fn new() -> Self {\\n        Self { value: 0 }\\n    }\\n\\n    /// Anyone can retrieve the current value.\\n    pub fn value(&self) -> i64 {\\n        self.value\\n    }\\n\\n    /// Increases the value of the counter by one.\\n    pub fn increment(&mut self) {\\n        self.value += 1;\\n    }\\n\\n    /// Decreases the value of the counter by one.\\n    pub fn decrement(&mut self) {\\n        self.value -= 1;\\n    }\\n\\n    /// Resets the value of the counter to zero.\\n    pub fn reset(&mut self) {\\n        self.value = 0;\\n    }\\n}\\n```\\n\\nThe final version of the code is available [*in this repository on github*](https://github.com/mooori/counter-acl-example). The *`Counter`* example is inspired by [*near-examples/counter-rust*](https://github.com/near-examples/counter-rust).\\n\\n### Permissions\\n\\nThe contract methods defined above can be called by anyone since they are public and inside an implementation block marked with `#[near_bindgen]`. Using `near-sdk-rs` it is possible to restrict some methods such that they can be called only by the contract itself. Either by using `#[private]` or by not exposing the method publicly, as described in the [documentation](https://docs.near.org/sdk/rust/contract-interface/private-methods).\\n\\nHowever, what if we wanted to implement more flexible permissions (e.g. allowing only some set of accounts to call a given function)? This is where the [`AccessControllable`](https://github.com/aurora-is-near/near-plugins#accesscontrollable) plugin comes in handy.\\n\\n### Managing permissions with ACL\\n\\nACL stands for *access control lists* and they are used in the following way within the `AccessControllable` plugin. The user defines the roles required for their use case as Rust enum variants. Then it is possible to restrict access to a method to accounts that have been granted roles. Restricting access is possible with one line of code, for example:\\n\\n```rust\\n#[access_control_any(roles(Role::Decrementer))]\\npub fn decrement(&mut self) {\\n    // ...\\n}\\n```\\n\\nLet\u2019s walk through it step by step to see how you can make your Near smart contract `AccessControllable`.\\n\\n### Step 1: Add `near-plugins` as a dependency\\n\\nFor now, `near-plugins` has not yet been published on crates.io. Still, the crate is ready for usage and it can be added as git dependency:\\n\\n```toml\\n# Add `near-plugins` under `dependencies` in your Cargo.toml.\\n\\n[dependencies]\\nnear-plugins = { git = \\"https://github.com/aurora-is-near/near-plugins.git\\", tag = \\"v0.2.0\\" }\\n```\\n\\n### Step 2: Define roles\\n\\nEvery use case may require a different set of roles, so users may define their roles as variants of an enum. For the `Counter` example, we define the following roles:\\n\\n```rust\\n#[derive(AccessControlRole, Deserialize, Serialize, Copy, Clone)]\\n#[serde(crate = \\"near_sdk::serde\\")]\\npub enum Role {\\n    /// Grantees of this role may decrease the counter.\\n    Decrementer,\\n    /// Grantees of this role may reset the counter.\\n    Resetter,\\n}\\n```\\n\\nDeriving the `AccessControlRole` trait prepares the `Role` enum for usage in the `AccessControllable` plugin.\\n\\n### Step 3: Make the contract `AccessControllable`\\n\\nThe contract is made `AccessControllable` by attaching the `access_control` attribute macro on the definition of the struct which represents the contract\u2019s state. We pass our `Role` as argument to make the `AccessControllable` implementation aware of it:\\n\\n```rust\\n#[access_control(role_type(Role))]\\n#[near_bindgen]\\n#[derive(PanicOnDefault, BorshDeserialize, BorshSerialize)]\\npub struct Counter {\\n    value: i64,\\n}\\n```\\n\\n### Step 4: Restrict contract methods\\n\\nAccess to a contract method is restricted by attaching `#[access_control_any]` and providing the roles to be whitelisted as arguments:\\n\\n```rust\\n#[near_bindgen]\\nimpl Counter {\\n    // We must be inside an implementation block with `#[near-bindgen]`.\\n\\n    /// Resets the value of the counter to zero.\\n    ///\\n    /// Only accounts that have been granted `Role::Resetter` may successfully call this method.\\n    /// If called by an account without this role, the method panics and state remains unchanged.\\n    #[access_control_any(roles(Role::Resetter))] // enables ACL for this method\\n    pub fn reset(&mut self) {\\n        self.value = 0;\\n    }\\n\\n    /// By the way, it is also possible to restrict access to accounts that have been granted any of\\n    /// multiple roles. This is how the syntax looks.\\n    #[access_control_any(roles(Role::Decrementer, Role::Resetter))]\\n    pub fn no_op(&self) { }\\n}\\n```\\n\\nNow the contract is set up for access control. The only step that is missing is granting roles to accounts, enabling them to call restricted methods.\\n\\n### Step 5: Grant permissions\\n\\nIn our contract\u2019s constructor method `new()` we make the contract itself super admin:\\n\\n```rust\\nnear_sdk::require!(\\n    contract.acl_init_super_admin(env::current_account_id()),\\n    \\"Failed to initialize super admin\\",\\n);\\n```\\n\\nThe `AccessControllable` super admin is an admin for every role defined in the `Role` enum. For this example, it is sufficient to know that a super admin may grant and revoke every role. Making the contract itself super admin facilitates the setup procedure as well as testing. More detailed information on admin roles can be found in the [documentation](https://github.com/aurora-is-near/near-plugins/blob/master/near-plugins/src/access_controllable.rs) of the `AccessControllable` trait.\\n\\nTo grant the `Resetter` role to the account `alice.near`, the contract can call the following function on itself:\\n\\n```rust\\n/// See `AccessControllable::acl_grant_role` for details.\\nacl_grant_role(\\"Resetter\\", \\"alice.near\\");\\n```\\n\\nThe `AccessControllable` trait provides many more methods to administer ACL permissions. After following the steps above, all of them are automatically implemented for a contract using the `AccessControllable` plugin.\\n\\n## Done\\n\\nThe steps above are sufficient to add complex and configurable ACL permissions to a contract using `near-plugins`. At this point, `alice.near` is the only account which has been granted the `Resetter` role. This means that only `alice.near` may successfully call the contract\u2019s `reset()` method.\\n\\nThe repo contains an [integration test](https://github.com/mooori/counter-acl-example/blob/main/tests/workflow.rs) which verifies that `AccessControllable` was set up correctly for our `Counter` contract. Take a look at it to learn more about interacting with an `AccessControllable` contract. To run the test on-chain in a local sandbox, it suffices to clone the repo and execute the following command. This is made possible by [near-workspaces-rs](https://github.com/near/near-workspaces-rs).\\n\\n```undefined\\ncargo test\\n```\\n\\n## Teaser: How it works internally\\n\\nUsing `AccessControllable` extends the contract state to store the permissions that have been granted. Moreover, the `AccessControllable` trait is implemented for the contract to enable administering permissions. When `#[access_control_any(roles(...))]` is attached to a method, `near-plugin` injects code that checks if the caller was granted any of the required roles. If not, a panic is generated which aborts the function call.\\n\\nTo learn about all the details, you can dive into the [implementation](https://github.com/aurora-is-near/near-plugins/blob/master/near-plugins-derive/src/access_controllable.rs) of the `AccessControllable` macro.\\n\\n## A note on testing\\n\\nThe functionality provided by `near-plugins` is critical for security and we strive to test it exhaustively. In tests, we compile demo contracts for all plugins and deploy them on-chain in a local sandbox. Then we verify that using a particular plugin adds exactly the expected functionality to the contract. These tests and demo contracts can be found [here](https://github.com/aurora-is-near/near-plugins/tree/master/near-plugins-derive/tests).\\n\\n## Ready for production, though?\\n\\nAs mentioned earlier, `near-plugins` comes with the caveat of not yet being published to *crates.io*. Nevertheless, it is already used in some contracts on mainnet, e.g. contracts related to the [Rainbow Bridge](https://rainbowbridge.app/transfer). Moreover, both [Hacken](https://www.datocms-assets.com/50156/1680101850-hacken-near-plugins-final-report-updated-march2023.pdf) and [AuditOne](https://www.datocms-assets.com/50156/1680590522-auditone-near-plugins-final-report-updated-march2023.pdf) audited `near-plugins`, awarding it high scores.\\n\\n## Conclusion\\n\\nUsing `near-plugins`, developers can add complex functionality to their smart contracts with just a few lines of code. Developers can focus on creating value for their users by relying on `near-plugins` for some cumbersome administrative tasks that are nevertheless critical for security. We are testing all plugins extensively and the `near-plugins` crate has been audited twice. We hope to contribute to the Near ecosystem by providing secure smart contract plugins which developers can build upon.\\n\\nThis article provides a step-by-step guide to using the `AccessControllable` plugin. In principle, using other plugins is similar. Head over to the [repository](https://github.com/aurora-is-near/near-plugins) and have a look at the documentation and tests to get started with other plugins."},{"id":"/contract-callbacks-in-xcc","metadata":{"permalink":"/blog/contract-callbacks-in-xcc","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/contract-callbacks-in-xcc.md","source":"@site/blog/contract-callbacks-in-xcc.md","title":"Contract Callbacks in XCC","description":"In this post we focus on the need to refund tokens to a user in the event of an error. This will reveal a bit of a \u201cgotcha\u201d which developers new to the XCC may come across, and we\u2019ll discuss how to overcome it","date":"2023-11-17T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":4.513333333333334,"hasTruncateMarker":true,"authors":[{"name":"Michael Birch","title":"Senior Research Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043123-t025c6kc9px-u025f7t5npl-c56792be0091-512.jpeg","key":"michael","page":null}],"frontMatter":{"title":"Contract Callbacks in XCC","description":"In this post we focus on the need to refund tokens to a user in the event of an error. This will reveal a bit of a \u201cgotcha\u201d which developers new to the XCC may come across, and we\u2019ll discuss how to overcome it","date":"2023-11-17","authors":["michael"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1700215626-xcc-cc.png"},"unlisted":false,"prevItem":{"title":"Plugins for smart contract devs building on Near","permalink":"/blog/plugins-for-smart-contract-devs-building-on-near"},"nextItem":{"title":"Practical ERC20 Burning","permalink":"/blog/practical-erc20-burning"}},"content":"In previous posts, we have written about the cross-contract calls (XCC) feature on Aurora. These include [*an overview*](/blog/cross-ecosystem-communication), [*an application*](/blog/building-a-game-using-near-aurora-and-bos), and a [*deep dive into writing tests*](/blog/communication-from-aurora-to-near-local-testing).\\n\\nIn this post, we continue with the XCC technical deep dive by discussing in more detail handling XCC results using callbacks. In particular, we focus on the concrete example of needing to refund tokens to a user in the event of an error. Along the way, this example will reveal a bit of a \u201cgotcha\u201d which developers new to the XCC feature may come across, and we\u2019ll discuss how to overcome it.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Scenario\\n\\nThis scenario comes from [*an example*](https://github.com/aurora-is-near/aurora-contracts-sdk/tree/76cb2f4f5932b5b9dd887834e1f7528cdeb1837c/examples/ft-refund) present in the Aurora Contracts SDK. In the example, we suppose there is a contract for some Near app, A, which works with a [*NEP-141*](https://nomicon.io/Standards/Tokens/FungibleToken/Core) token, T, that has also been bridged to Aurora.\\n\\nOur goal is to use XCC to allow Aurora users to interact with A using the ERC-20 version of T tokens they have on Aurora. We specifically want to handle the case where if there is an error in A, then the tokens are automatically returned to the user\u2019s address on Aurora.\\n\\n## The Contracts\\n\\n### The NEP-141 Token T\\n\\nThis is a totally standard [*NEP-141*](https://nomicon.io/Standards/Tokens/FungibleToken/Core) token done with the [*reference implementation*](https://docs.rs/near-contract-standards/latest/near_contract_standards/fungible_token/index.html). The only thing to say about this is that the mint function is public for the sake of the example.\\n\\n```rust\\n#[near_bindgen]\\n#[derive(BorshSerialize, BorshDeserialize, PanicOnDefault)]\\npub struct Contract {\\n    name: String,\\n    symbol: String,\\n    decimals: u8,\\n    token: FungibleToken,\\n}\\n\\n#[near_bindgen]\\nimpl Contract {\\n    #[init]\\n    pub fn new(name: String, symbol: String, decimals: u8) -> Self {\\n        Self {\\n            name,\\n            symbol,\\n            decimals,\\n            token: FungibleToken::new(b\\"t\\".to_vec()),\\n        }\\n    }\\n\\n    #[payable]\\n    pub fn mint(&mut self, account_id: AccountId, amount: U128) {\\n        self.token.internal_deposit(&account_id, amount.into());\\n    }\\n\\n    pub fn burn(&mut self, account_id: AccountId, amount: U128) {\\n        self.token.internal_withdraw(&account_id, amount.into());\\n    }\\n}\\n\\nnear_contract_standards::impl_fungible_token_core!(Contract, token);\\nnear_contract_standards::impl_fungible_token_storage!(Contract, token);\\n```\\n\\n### The Near App Contract A\\n\\nThis is a very simple contract which only implements the ft_on_transfer function from the NEP-141 spec, thus allowing it to receive T tokens. The implementation of that function is also simple. It either accepts all the tokens or if the attached message is `refund` then it sends back all the tokens minus a small fee. This \u201crefund\u201d case is what we will focus on since it is in that situation that the returned tokens need to be given back to the user\u2019s address on Aurora.\\n\\n```rust\\n// A fee that is taken from amounts that are requested to be refunded.\\nconst FEE: u128 = 77;\\n\\n#[near_bindgen]\\n#[derive(BorshDeserialize, BorshSerialize, Default)]\\npub struct FtRefund;\\n\\n#[near_bindgen]\\nimpl FungibleTokenReceiver for FtRefund {\\n    fn ft_on_transfer(\\n        &mut self,\\n        sender_id: AccountId,\\n        amount: U128,\\n        msg: String,\\n    ) -> PromiseOrValue<U128> {\\n        if &msg == \\"refund\\" {\\n            let return_amount = amount.0.saturating_sub(FEE);\\n            PromiseOrValue::Value(U128(return_amount))\\n        } else {\\n            PromiseOrValue::Value(0.into())\\n        }\\n    }\\n}\\n```\\n\\n### The Solidity Contract\\n\\nThis contract uses the XCC feature to allow Aurora users to interact with the Near App Contract. The main entry point is ftTransferCall which takes as input the address of an ERC-20 token bridged from a NEP-141 token, the Near account name of that NEP-141 token, and an amount of tokens. The contract takes the user\u2019s ERC-20 token on Aurora, bridges them back as NEP-141 tokens on its XCC account on Near, and then uses that account to send the NEP-141 tokens to the Near App Contract via `ft_transfer_call`.\\n\\n```solidity\\nfunction ftTransferCall(\\n    IEvmErc20 token,\\n    string memory tokenId,\\n    uint128 amount\\n) public {\\n    token.transferFrom(msg.sender, address(this), amount);\\n    token.withdrawToNear(\\n        abi.encodePacked(AuroraSdk.nearRepresentative(address(this))),\\n        uint(amount)\\n    );\\n\\n    bytes memory data = abi.encodePacked(\\n        \\"{\\",\\n        \'\\"receiver_id\\": \\"\',\\n        nearAccountId,\\n        \'\\",\',\\n        \'\\"amount\\": \\"\',\\n        Strings.toString(amount),\\n        \'\\",\',\\n        \'\\"msg\\": \\"refund\\"\',\\n        \\"}\\"\\n    );\\n    PromiseCreateArgs memory callFtTransfer = near.call(\\n        tokenId,\\n        \\"ft_transfer_call\\",\\n        data,\\n        1,\\n        FT_TRANSFER_CALL_NEAR_GAS\\n    );\\n    PromiseCreateArgs memory callback = near.auroraCall(\\n        address(this),\\n        abi.encodeWithSelector(\\n            this.ftTransferCallCallback.selector,\\n            msg.sender,\\n            tokenId,\\n            amount\\n        ),\\n        0,\\n        CALLBACK_NEAR_GAS\\n    );\\n\\n    callFtTransfer.then(callback).transact();\\n}\\n```\\n\\nThere is also a callback for this function which handles the result of that XCC call. The callback is defined in the function ftTransferCallCallback. The logic of this function is to check if there are any tokens that need to be returned to the user on Aurora, and if there are, bridge them back to the user\u2019s address using another ft_transfer_call from the NEP-141 token to Aurora.\\n\\n```solidity\\nfunction ftTransferCallCallback(\\n    address sender,\\n    string memory tokenIdOnNear,\\n    uint128 amount\\n) public onlyRole(CALLBACK_ROLE) {\\n    PromiseResult memory promiseResult = AuroraSdk.promiseResult(0);\\n    uint128 refundAmount = 0;\\n\\n    if (promiseResult.status != PromiseResultStatus.Successful) {\\n        // if Promise failed we need to do whole refund\\n        refundAmount = amount;\\n    } else {\\n        // else `ft_resolve_transfer` will return used amount of FT,\\n        // which we need to extract from original amount\\n        uint128 usedAmount = _stringToUint(string(promiseResult.output));\\n        refundAmount = amount - usedAmount;\\n    }\\n\\n    if (refundAmount > 0) {\\n        bytes memory data = abi.encodePacked(\\n            \\"{\\",\\n            \'\\"receiver_id\\": \\"\',\\n            AuroraSdk.currentAccountId(),\\n            \'\\",\',\\n            \'\\"amount\\": \\"\',\\n            Strings.toString(refundAmount),\\n            \'\\",\',\\n            \'\\"msg\\": \\"\',\\n            _toHexString(uint160(sender), 20),\\n            \'\\"}\'\\n        );\\n        PromiseCreateArgs memory callFtTransfer = near.call(\\n            tokenIdOnNear,\\n            \\"ft_transfer_call\\",\\n            data,\\n            1,\\n            REFUND_NEAR_GAS\\n        );\\n        callFtTransfer.transact();\\n    }\\n}\\n```\\n\\n## The Trap\\n\\nSo far so good, everything looks straightforward. But this is where we hit a small \u201cgotcha\u201d. The NEP-141 token standard requires attaching 1 yoctoNEAR to ft_transfer_call. This means not only is ftTransferCall spending 1 yoctoNEAR, but so is ftTransferCallCallback in the case that a refund is needed. Someone needs to pay for this cost, and the Aurora Contact SDK [*passes that cost on to the caller of the function*](https://github.com/aurora-is-near/aurora-contracts-sdk/blob/76cb2f4f5932b5b9dd887834e1f7528cdeb1837c/aurora-solidity-sdk/src/AuroraSdk.sol#L142).\\n\\nIn the case of ftTransferCall, that caller is the user, no problem. But who is the caller in the case of ftTransferCallCallback? One hint comes from the permissions on ftTransferCallCallback. It can only be called by the `CALLBACK_ROLE`, which is only assigned to the address computed from `AuroraSdk.nearRepresentitiveImplicitAddress(address(this))`. Therefore this address must approve the Solidity contract to spend its wNEAR in order for it to cover the 1 yoctoNEAR cost in the callback.\\n\\nThis is the reason for the approveWNEAR function, which is also present in the Solidity contract. It does this approval so that wNEAR can be spent in the callback.\\n\\n```solidity\\nfunction approveWNEAR() public {\\n    uint256 amount = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF;\\n    PromiseCreateArgs memory approveCall = near.auroraCall(\\n        address(this.wNEAR()),\\n        abi.encodeWithSelector(\\n            0x095ea7b3, // approve method selector\\n            address(this),\\n            amount\\n        ),\\n        0,\\n        APPROVE_NEAR_GAS\\n    );\\n    approveCall.transact();\\n}\\n```\\n\\nThe need for this function is rather quirky. Logically `nearRepresentitiveImplicitAddress` should be the identity function because it is returning the address on Aurora that corresponds to the XCC account of an Aurora address; meaning that the only way transactions can come from the `nearRepresentitiveImplicitAddress(address)` is if they were originally sent from the address itself.\\n\\nUnfortunately, it is not the identity function because the notion of an implicit Aurora address for any named account on Near was defined long before the XCC feature was invented. The implementation of this is the most natural one: derive the address from the named account the same way addresses are derived from a public key; take the hash and use the last 20 bytes. Composing this implementation with the way XCC accounts are named results in returning a different address than we started with.\\n\\n```rust\\n// The XCC account for an Aurora address is a subaccount of Aurora.\\nfn near_representative(address: Address) -> AccountId {\\n    format!(\\"{}.aurora\\", hex::encode(address))\\n}\\n\\n// The implicit address on Aurora of a Near account is derived\\n// in the \\"obvious\\" way.\\nfn aurora_implicit_address(account: AccountId) -> Address {\\n    hash(account)[12..32]\\n}\\n\\n// Composing these functions logically should be the identity function,\\n// but these implementations do not do that unfortunately.\\nfn near_representative_implicit_address(address: Address) -> Address {\\n    let result = aurora_implicit_address(near_representative(address));\\n    debug_assert!(result != address);\\n    result\\n}\\n```\\n\\n## Conclusion\\n\\nIn conclusion, it is important to remember when working with XCC that there are two addresses which logically correspond to the contract you are working with. One is, of course, the address where the contract is deployed, `address(this)`. The other is the address which becomes the caller in XCC callbacks, `AuroraSdk.nearRepresentitiveImplicitAddress(address(this))`. Sometimes it will be important to have a contract \u201capprove itself\u201d when it comes to spending tokens because these two addresses are different.\\n\\nTo check your understanding of this post, take a look at the full code for this token refund [*example on GitHub*](https://github.com/aurora-is-near/aurora-contracts-sdk/tree/76cb2f4f5932b5b9dd887834e1f7528cdeb1837c/examples/ft-refund) and play with it yourself! What happens when you remove [*the call to approveWNEAR from the integration test*](https://github.com/aurora-is-near/aurora-contracts-sdk/blob/76cb2f4f5932b5b9dd887834e1f7528cdeb1837c/examples/ft-refund/integration-tests/src/lib.rs#L203C1-L223C47)? What error do you see and why?"},{"id":"/practical-erc20-burning","metadata":{"permalink":"/blog/practical-erc20-burning","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/practical-erc20-burning.md","source":"@site/blog/practical-erc20-burning.md","title":"Practical ERC20 Burning","description":"Token burning is the act of permanently removing a certain number of tokens from circulation. This article delves into its intricacies and offers guidance based on my real-world experiences at Aurora","date":"2023-09-22T00:00:00.000Z","tags":[{"inline":false,"label":"Tips & Tricks","permalink":"/blog/tags/tips_and_tricks","description":"Short posts about tech for devs on Aurora"}],"readingTime":1.68,"hasTruncateMarker":true,"authors":[{"name":"Alexey Lapitsky","title":"Head of Engineering","imageURL":"https://www.datocms-assets.com/95026/1695381471-t025c6kc9px-u03al0nrv42-9c9729605d9f-192.jpeg","key":"alex_lapitsky","page":null}],"frontMatter":{"title":"Practical ERC20 Burning","description":"Token burning is the act of permanently removing a certain number of tokens from circulation. This article delves into its intricacies and offers guidance based on my real-world experiences at Aurora","date":"2023-09-22","authors":["alex_lapitsky"],"tags":["tips_and_tricks"],"image":"https://www.datocms-assets.com/95026/1695381651-article-cover.png"},"unlisted":false,"prevItem":{"title":"Contract Callbacks in XCC","permalink":"/blog/contract-callbacks-in-xcc"},"nextItem":{"title":"Integration tests for XCC communication","permalink":"/blog/communication-from-aurora-to-near-local-testing"}},"content":"Token burning is the act of permanently removing a certain number of tokens from circulation. This article delves into its intricacies and offers guidance based on my real-world experiences at Aurora\\n\\n\x3c!-- truncate --\x3e\\n\\n## Why is there a problem?\\n\\nThe ERC20 standard does not inherently specify a token burning mechanism.\\n\\nThe most common implementation of ERC20 [provides](https://docs.openzeppelin.com/contracts/4.x/api/token/erc20?ref=lapitsky.com#ERC20Burnable) `ERC20Burnable` to solve that, but not all deployed OpenZepellin contracts include `ERC20Burnable`. Many ERC20 contracts are locked and not upgradeable.\\n\\nDue to these constraints, projects seek alternative ways to approach token burns.\\n\\n## Do not use contract burns\\n\\nOne often recommended way to burn tokens involves creating a contract that immediately self-destructs and sends tokens to its own address. However, this method comes with its set of challenges:\\n\\n* The overhead of creating, deploying, and testing such contracts, especially if the burn needs to happen periodically\\n* Even if the contract uses `SELFDESTRUCT` it does not preclude the possibility of redeploying another contract at the same address. This has been successfully exploited in the infamous [Tornado Cash attack](https://forum.tornado.ws/t/full-governance-attack-description/62?ref=lapitsky.com) by using a metamorphic contract factory.\\n* There is a negative sentiment against `SELFDESTRUCT` opcode and (although stagnant) [EIP-4758](https://eips.ethereum.org/EIPS/eip-4758?ref=lapitsky.com) that highlights some security concerns.\\n* Token burns via this method aren\'t recognized on most analytics platforms.\\n\\nGiven the listed concerns, I advise against this approach and encourage the use of burn addresses.\\n\\n## Use well-known burn addresses\\n\\nA burn address is a recognized externally owned account ([EOA](https://ethereum.org/en/whitepaper/?ref=lapitsky.com#ethereum-accounts)) where tokens can be sent to symbolize their destruction. While the token count remains unchanged, these tokens are effectively removed from circulation since no private key can control the burn address.\\n\\nOne of the common questions is \\"What if somebody knows or brute forces the private keys for such EOA addresses?\\"\\n\\nEthereum security model rests on the practical impossibility of brute forcing EOA accounts, so it does not make sense to take the risk of such an attack into account when planning the burns. To mitigate the risk of malicious burn addresses, use only the well-known ones.\\n\\nYou can find the list of burn addresses on [Etherscan](https://etherscan.io/accounts/label/burn?ref=lapitsky.com) but I recommend limiting it to the top two that stand out by the TVL and number of transactions: `0x0000000000000000000000000000000000000000` (*null*) and `0x000000000000000000000000000000000000dEaD` (*dead*).\\n\\nInterestingly, OpenZeppelin\'s ERC20 implementation restricts transfers to *null* which could leave you with the second-best choice: *dead.*\\n\\nThe benefit of using well-known burn addresses over \\"contract burns\\" is that burn addresses are accounted for and integrated into numerous analytics tools, ensuring accurate token burn data representation.\\n\\n## Bonus tips\\n\\n* Ensure that your ERC20 contract is locked and immutable before initiating burns.\\n* For ERC20 tokens on multiple networks, execute burns on your primary network only, for unified tracking and analytics.\\n* For the first burn, refrain from using decentralized or ZK-bridges. If your contract unexpectedly rejects the transaction (like disallowing transfers to *null*) \u2013 it might muddle your analytics even though the tokens are technically burned.\\n\\nBig thanks to [Lance Henderson](https://www.linkedin.com/in/lance-henderson/?ref=lapitsky.com) for technical insights and for reviewing this post!"},{"id":"/communication-from-aurora-to-near-local-testing","metadata":{"permalink":"/blog/communication-from-aurora-to-near-local-testing","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/communication-from-aurora-to-near-local-testing.md","source":"@site/blog/communication-from-aurora-to-near-local-testing.md","title":"Integration tests for XCC communication","description":"XCC is a powerful tool to merge blockchain ecosystems together. In this post we will talk about how to write integration tests for the XCC contracts communicating between Aurora and Near using Rust","date":"2023-09-08T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":7.196666666666666,"hasTruncateMarker":true,"authors":[{"name":"Olga Kunyavskaya","title":"Bridge Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043237-t025c6kc9px-u03dl8hkg1w-fe48e17d7ba2-512.png","key":"olga","page":null}],"frontMatter":{"title":"Integration tests for XCC communication","description":"XCC is a powerful tool to merge blockchain ecosystems together. In this post we will talk about how to write integration tests for the XCC contracts communicating between Aurora and Near using Rust","date":"2023-09-08","authors":["olga"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1694085970-article-cover.png"},"unlisted":false,"prevItem":{"title":"Practical ERC20 Burning","permalink":"/blog/practical-erc20-burning"},"nextItem":{"title":"Turning Smart Contracts into Indexers","permalink":"/blog/turning-smart-contracts-into-indexers"}},"content":"In this article, we will learn how to write local tests for the Aurora contracts, which use [XCC calls](/blog/cross-ecosystem-communication) to Near ecosystem. I will use a simple example to demonstrate it, step by step, we will write:\\n\\n1. A simple counter contract for Near blockchain.\\n2. Contract on Aurora, which calls the contract on Near by using the XCC.\\n3. One integration test in the `sandbox`.\\n4. Setup the `git action` for running this test automatically.\\n\\nThe example described in this article: [https://github.com/olga24912/AuroraToNearXCCExample](https://github.com/olga24912/AuroraToNearXCCExample)\\n\\n\x3c!-- truncate --\x3e\\n\\n## Counter contract on Near\\n\\nI assume that you have already cloned a git repo locally or just created your own repo, in the case you want to add everything file by file to your project using this article.\\n\\nWe will start with creating a simple Counter contract on Near, which just has two functions: `increment` \u2013 for changing the value, and `get_num` \u2013 to return the current value.\\n\\nWe should have the following directories and files in `near` folder:\\n\\n```toml\\nAuroraToNearXCCExample: \\n|-- near\\n|   |-- contracts\\n|   |   |-- build.sh\\n|   |   |-- Cargo.toml\\n|   |   |-- src\\n|   |   |   |-- lib.rs\\n```\\n\\nLet\'s take a look at each of the files.\\n\\n`lib.rs`:\\n\\n```rust\\nuse near_sdk::borsh::{self, BorshDeserialize, BorshSerialize};\\nuse near_sdk::{near_bindgen, PanicOnDefault};\\n\\n#[near_bindgen]\\n#[derive(PanicOnDefault, BorshDeserialize, BorshSerialize)]\\npub struct Counter {\\n    val: u64,\\n}\\n\\n#[near_bindgen]\\nimpl Counter {\\n    #[init]\\n    pub fn new() -> Self {\\n        Self{\\n            val: 0\\n        }\\n    }\\n\\n    pub fn get_num(&self) -> u64 {\\n        return self.val;\\n    }\\n\\n    pub fn increment(&mut self, value: u64) {\\n        self.val += value;\\n    }\\n}\\n```\\n\\n`Cargo.toml`:\\n\\n```toml\\n[package]\\nname = \\"counter\\"\\nversion = \\"0.1.0\\"\\nedition = \\"2021\\"\\n\\n[lib]\\ncrate-type = [\\"cdylib\\", \\"rlib\\"]\\n\\n[dependencies]\\nnear-sdk = \\"4.1.1\\"\\n```\\n\\nFor compiling the contract into a WASM file, we will use the script `build.sh`:\\n\\n```bash\\n#!/bin/sh\\nset -e\\n\\nrustup target add wasm32-unknown-unknown\\nRUSTFLAGS=\'-C link-arg=-s\' cargo build --target wasm32-unknown-unknown --release\\n```\\n\\nTo compile the contract run:\\n\\n```bash\\n./build.sh\\n```\\n\\nThe target file: `near/contracts/target/wasm32-unknown-unknown/release/counter.wasm`\\n\\n## Counter contract on Aurora\\n\\nWe already created a counter contract for Near, and now let\'s create the counter contract on Aurora, which will have one method `incrementXCC` inside, which we will call the `increment` method in the Near Counter contract.\\n\\nFirst, create the following folder structure and the `Counter.sol` file\\n\\n```bash\\nAuroraToNearXCCExample:\\n|-- aurora\\n|   |-- contracts\\n|   |   |-- src\\n|   |   |   |-- Counter.sol\\n|-- near\\n```\\n\\n`Counter.sol` file:\\n\\n```solidity\\npragma solidity ^0.8.0;\\n\\nimport {IERC20} from \\"@openzeppelin/contracts/token/ERC20/IERC20.sol\\";\\nimport {AuroraSdk, NEAR, PromiseCreateArgs} from \\"@auroraisnear/aurora-sdk/aurora-sdk/AuroraSdk.sol\\";\\n\\ncontract Counter {\\n    using AuroraSdk for NEAR;\\n    using AuroraSdk for PromiseCreateArgs;    \\n\\n    uint64 constant COUNTER_NEAR_GAS = 10_000_000_000_000;\\n    \\n    NEAR public near;\\n    string counterAccountId;\\n\\n    constructor(address wnearAddress, string memory counterNearAccountId) {\\n        near = AuroraSdk.initNear(IERC20(wnearAddress));\\n        counterAccountId = counterNearAccountId;\\n    }\\n\\n    function incrementXCC() external {\\n        bytes memory args = bytes(\'{\\"value\\": 1}\');\\n        PromiseCreateArgs memory callCounter = near.call(\\n            counterAccountId,\\n            \\"increment\\",\\n            args,\\n            0,\\n            COUNTER_NEAR_GAS\\n        );\\n        callCounter.transact();\\n    }\\n}\\n```\\n\\nMore information about how the aurora contracts with XCC work can be found [here,](/blog/cross-ecosystem-communication) or [in this game example,](/blog/building-a-game-using-near-aurora-and-bos) or in these [official docs](https://github.com/aurora-is-near/aurora-contracts-sdk/blob/main/docs/NearFromAurora.md) in aurora-contracts-sdk repo.\\n\\n### Install dependencies for counter contract on Aurora\\n\\nFor deploying the counter contract on Aurora in integration tests, we should install `foundry` and the dependencies. First, go to `aurora` folder and install `aurora-sdk` by running:\\n\\n```bash\\nyarn init\\nyarn add @auroraisnear/aurora-sdk\\n```\\n\\nFor compiling aurora contracts in the test, we will use foundry. How to install foundry you can read [here](https://book.getfoundry.sh/getting-started/installation).\\n\\nWe should create `foundry.toml` in `aurora/contracts` folder.\\n\\n```bash\\nAuroraToNearXCCExample:\\n|-- aurora\\n|   |-- contracts\\n|   |   |-- src\\n|   |   |-- foundry.toml\\n|   |-- integration-tests\\n|-- near\\n```\\n\\n`foundry.toml`:\\n\\n```toml\\n[profile.default]\\nsrc = \'src\'\\nout = \'out\'\\nlibs = [\'lib\', \'../node_modules\']\\nallow_paths = []\\nsolc = \\"0.8.17\\"\\n```\\n\\nAfter that you need to run the next command from `aurora/contracts` folder:\\n\\n```bash\\nrm -rf lib/aurora-contracts-sdk\\nforge install aurora-is-near/aurora-contracts-sdk --no-commit\\n```\\n\\nAfter command execution in the `aurora/contracts` directory, the `lib` folder with `aurora-contracts-sdk` and all necessary files inside will be created.\\n\\n## Integration test\\n\\nIt is time to create an integration test! Go back to the `aurora` folder with `cd ..` and run (or just use already existing folder from repo):\\n\\n```solidity\\ncargo new --lib integration-tests\\n```\\n\\nThe `integration-tests` folder will be created. We should also create the following `rust-toolchain` file in this folder:\\n\\n```rust\\n[toolchain]\\nchannel = \\"1.66.1\\"\\n```\\n\\nWe need this because this channel is used in dependencies, and we should use the same channel to make contracts work properly. For people outside the Rust community, you can think about this as setting the Rust version, more info is [here](https://rust-lang.github.io/rustup/concepts/toolchains.html).\\n\\nWe should obtain this folder structure:\\n\\n```bash\\nAuroraToNearXCCExample:\\n|-- aurora\\n|   |-- contracts\\n|   |-- integration-tests\\n|   |   |-- Cargo.toml\\n|   |   |-- src\\n|   |   |   |-- lib.rs\\n|   |   |-- rust-toolchain\\n|-- near\\n```\\n\\nEdit now `lib.rs`:\\n\\n```rust\\n#[cfg(test)]\\nmod tests {\\n    use aurora_sdk_integration_tests::tokio;\\n    \\n    #[tokio::test]\\n    async fn counter_test() {\\n    \\n    }\\n}\\n```\\n\\n`and Cargo.toml`:\\n\\n```toml\\n[package]\\nname = \\"integration-tests\\"\\nversion = \\"0.1.0\\"\\nedition = \\"2021\\"\\n\\n[dependencies]\\naurora-sdk-integration-tests = { git = \\"https://github.com/aurora-is-near/aurora-contracts-sdk.git\\" }\\nnear-sdk = \\"4.1.1\\"\\n```\\n\\nThe command for running the test should run this succesfully:\\n\\n```bash\\ncargo test\\n```\\n\\nYou should see output like this afterwards:\\n\\n```shell\\nCompiling integration-tests v0.1.0 (/Users/aurora/Projects/AuroraToNearXCCExample/aurora/integration-tests)\\n    Finished test [unoptimized + debuginfo] target(s) in 2.86s\\n     Running unittests src/lib.rs (target/debug/deps/integration_tests-307b69604bee401f)\\n\\nrunning 1 test\\ntest tests::counter_test ... ok\\n\\ntest result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00ss\\n```\\n\\n### Deploy Near contract in integration tests\\n\\nLet\'s start writing our test with compiling and deploying the Counter contract on Near inside the sandbox. To do this we will: create the sandbox workspace with `workspaces::sandbox()`, compile near contract by using `build.sh` script (as we did above in section `Create Counter contract on Near`), deploy the contract with `worker.dev_deploy` and call the constructor with `near_counter.call(\\"new\\").`\\n\\nAll of that is inside the `deploy_near_counter` function, which we will use now directly in our `counter_test`. The full code is below:\\n\\n```bash\\n#[cfg(test)]\\nmod tests {\\n    use aurora_sdk_integration_tests::{tokio, workspaces, {utils::process}};\\n    use aurora_sdk_integration_tests::workspaces::Contract;\\n    use std::path::Path;\\n\\n    #[tokio::test]\\n    async fn counter_test() {\\n        let worker = workspaces::sandbox().await.unwrap();\\n        let near_counter = deploy_near_counter(&worker).await;\\n    }\\n\\n    async fn deploy_near_counter(\\n        worker: &workspaces::Worker[workspaces::network::Sandbox](workspaces::network::Sandbox),\\n    ) -> Contract {\\n        let contract_path = Path::new(\\"../../near/contracts\\");\\n        let output = tokio::process::Command::new(\\"bash\\")\\n            .current_dir(contract_path)\\n            .args([\\"build.sh\\"])\\n            .output()\\n            .await\\n            .unwrap();\\n\\n        process::require_success(&output).unwrap();\\n\\n        let artifact_path =\\n            contract_path.join(\\"target/wasm32-unknown-unknown/release/counter.wasm\\");\\n        let wasm_bytes = tokio::fs::read(artifact_path).await.unwrap();\\n        let near_counter = worker.dev_deploy(&wasm_bytes).await.unwrap();\\n\\n        near_counter.call(\\"new\\").transact().await.unwrap().into_result().unwrap();\\n\\n        near_counter\\n    }\\n}\\n```\\n\\nYou can run `cargo test` to check if your code is working at this stage.\\n\\n### Deploy Aurora Engine and wNEAR\\n\\nNow, let\'s deploy the Aurora Engine contract itself to the sandbox. Also, we will need to deploy wNEAR in Aurora. It is the ERC-20 on Aurora which corresponds to the Near token on Near. We will use this token later for the payment.\\n\\n```bash\\n#[cfg(test)]\\nmod tests {\\n    use aurora_sdk_integration_tests::{tokio, workspaces, {utils::process}, aurora_engine, wnear, workspaces::Contract};\\n    use aurora_sdk_integration_tests::workspaces::Contract;\\n    use std::path::Path;\\n\\n    #[tokio::test]\\n    async fn counter_test() {\\n        let worker = workspaces::sandbox().await.unwrap();\\n        let near_counter = deploy_near_counter(&worker).await;\\n\\n        let engine = aurora_engine::deploy_latest(&worker).await.unwrap();\\n        let wnear = wnear::Wnear::deploy(&worker, &engine).await.unwrap();\\n    }\\n    ...\\n}\\n```\\n\\n### Deploy counter contract on Aurora in integration tests\\n\\nMoving to deploying counter contract to Aurora. We are creating a new user account and function to deploy the counter. This function takes: (1) aurora engine, (2) user account, (3) wNear address on aurora, (4) Counter Account ID on Near.\\n\\nLet\'s add new dependencies first:\\n\\n```rust\\n#[cfg(test)]\\nmod tests {\\n    use aurora_sdk_integration_tests::{tokio, workspaces, {utils::process}, aurora_engine, wnear, ethabi};\\n    use aurora_sdk_integration_tests::workspaces::Contract;\\n    use std::path::Path;\\n    \\n    use aurora_sdk_integration_tests::aurora_engine_types::types::{Address};\\n    use aurora_sdk_integration_tests::aurora_engine::AuroraEngine;\\n    use aurora_sdk_integration_tests::utils::forge;\\n    use aurora_sdk_integration_tests::utils::ethabi::DeployedContract;\\n...\\n```\\n\\nNow let\'s define `deploy_aurora_counter` function and add it to out test:\\n\\n```rust\\n//....\\n    #[tokio::test]\\n    async fn counter_test() {\\n        //....\\n        \\n        let user_account = worker.dev_create_account().await.unwrap();\\n        let aurora_counter = deploy_aurora_counter(&engine, &user_account, wnear.aurora_token.address, &near_counter).await;\\n    }\\n\\n    async fn deploy_aurora_counter(engine: &AuroraEngine,\\n                                   user_account: &workspaces::Account,\\n                                   wnear_address: Address,\\n                                   near_counter: &Contract) -> DeployedContract {\\n        //....\\n    }\\n```\\n\\nTo deploy aurora contract we should first compile and deploy `aurora_sdk_lib`, and corresponding dependencies:\\n\\n```rust\\nasync fn deploy_aurora_counter(engine: &AuroraEngine,\\n                                   user_account: &workspaces::Account,\\n                                   wnear_address: Address,\\n                                   near_counter: &Contract) -> DeployedContract {\\n    let contract_path = \\"../contracts\\";\\n\\n    let aurora_sdk_path = Path::new(\\"../contracts/lib/aurora-contracts-sdk/aurora-solidity-sdk\\");\\n    let codec_lib = forge::deploy_codec_lib(&aurora_sdk_path, engine).await.unwrap();\\n    let utils_lib = forge::deploy_utils_lib(&aurora_sdk_path, engine).await.unwrap();\\n    let aurora_sdk_lib = forge::deploy_aurora_sdk_lib(&aurora_sdk_path, engine, codec_lib, utils_lib).await.unwrap();\\n\\n    //....\\n}\\n```\\n\\nAfter that, we can compile and deploy the counter contract itself:\\n\\n```rust\\n    //....\\n    \\n    let constructor = forge::forge_build(\\n                      contract_path,\\n                      &[format!(\\n                         \\"@auroraisnear/aurora-sdk/aurora-sdk/AuroraSdk.sol:AuroraSdk:0x{}\\",\\n                         aurora_sdk_lib.encode()\\n                       )], \\n                       &[\\"out\\", \\"Counter.sol\\", \\"Counter.json\\"]).await.unwrap();\\n\\n    let deploy_bytes = constructor.create_deploy_bytes_with_args(&[\\n            ethabi::Token::Address(wnear_address.raw()),\\n            ethabi::Token::String(near_counter.id().to_string()),\\n        ]);\\n\\n    let address = engine\\n            .deploy_evm_contract_with(user_account, deploy_bytes)\\n            .await\\n            .unwrap();\\n\\n    constructor.deployed_at(address)\\n}\\n```\\n\\n### Mint wNEAR for user\\n\\nWhen we use XCC for the first time in our setup, the implicit contract on the Near will be created. You can read more about it [here](https://github.com/aurora-is-near/aurora-contracts-sdk/blob/main/docs/NearFromAurora.md). We also could call this implicit contract as sub-account. The overall scheme could be presented as:\\n\\n![](https://www.datocms-assets.com/95026/1694083461-screenshot-2023-09-07-at-11-42-21.png)\\n\\nCreation of a sub-account will cost you 2 NEAR tokens. That is why we need to mint 2 wNEAR for our user on Aurora after approving the spending of the wNear by counter contract.\\n\\n```rust\\n///....\\nuse aurora_sdk_integration_tests::aurora_engine_sdk::types::near_account_to_evm_address;\\nuse aurora_sdk_integration_tests::aurora_engine_types::{U256, types::Wei};\\n\\n#[tokio::test]\\nasync fn counter_test() {\\n    //....\\n\\n    let user_address = near_account_to_evm_address(user_account.id().as_bytes());\\n    const NEAR_DEPOSIT: u128 = 2 * near_sdk::ONE_NEAR;\\n\\n    engine.mint_wnear(&wnear, user_address, NEAR_DEPOSIT).await.unwrap();\\n\\n    let evm_call_args = wnear\\n        .aurora_token\\n        .create_approve_call_bytes(aurora_counter.address, U256::MAX);\\n    \\n    let result = engine\\n        .call_evm_contract_with(\\n        &user_account,\\n        wnear.aurora_token.address,\\n        evm_call_args,\\n        Wei::zero()).await.unwrap();\\n    aurora_engine::unwrap_success(result.status).unwrap();\\n}\\n```\\n\\n### Call incrementXCC method in counter contract on Aurora\\n\\nIn this section, we will write a function that calls the `incrementXCC` method in the Counter contract on Aurora. `incrementXCC` method is calling inside the `increment` method from the Near contract and counter is incremented on Near.\\n\\nLet\'s write `increment` function in our test now, which will call the `incrementXCC` from the Aurora\'s contract. We\'ll provide as input: (1) aurora engine contract deployed in the sandbox, (2) the near account of the user which will sign the transaction, (3) the counter contract deployed on aurora.\\n\\nNotice that we\'re going to call the method in the aurora contract, but in this function, the user account ID on Near is provided. We can do this because it is possible to call the aurora\'s counter contract method by using `call` method from the Aurora Engine contract.\\n\\nIn that case, the near user will sign a transaction, but inside the Aurora Engine, there is [an implicit mapping](https://github.com/aurora-is-near/aurora-engine/blob/71980db92a9d4b95d4e1f53954b98e0e8f002a4b/engine-sdk/src/types.rs#L28) between the near account ID and aurora addresses. And it is precisely how we will communicate with the contract in our test.\\n\\nNow, let\'s first encode the arguments for the `call` method in the `AuroraEngine` contract on Near and after that \u2013 submit a transaction and check its result:\\n\\n```rust\\n//....\\nuse aurora_sdk_integration_tests::aurora_engine_types::parameters::engine::{CallArgs, FunctionCallArgsV1};\\n\\n#[tokio::test]\\nasync fn counter_test() {\\n    //....\\n\\n    increment(&engine, &user_account, aurora_counter).await;\\n}\\n\\nasync fn increment(\\n    engine: &AuroraEngine,\\n    user_account: &workspaces::Account,\\n    aurora_counter: DeployedContract\\n) {\\n  \\n  let contract_args = aurora_counter.create_call_method_bytes_without_args(\\"incrementXCC\\");\\n\\n  let result = engine\\n      .call_evm_contract_with(\\n          &user_account,\\n          aurora_counter.address,\\n          ContractInput(contract_args),\\n          Wei::zero(),\\n      )\\n      .await\\n      .unwrap();\\n  \\n  aurora_engine::unwrap_success(result.status).unwrap();\\n}\\n```\\n\\n### Check counter value on Near\\n\\nLet\u2019s check that the counter has been incremented at the Counter contract on Near. For that, call the `get_num` view method at the counter and check that the result equals 1.\\n\\n```rust\\n#[tokio::test]\\nasync fn counter_test() {\\n    //....\\n    \\n    let counter_val: u64 = near_counter.view(\\"get_num\\").await.unwrap().json().unwrap();\\n    assert_eq!(counter_val, 1);\\n}\\n```\\n\\n### Run final test\\n\\nNow, when everything is ready, let\'s go to `aurora/integration-tests/` directory and run to check that we have the expected results:\\n\\n```bash\\ncargo test\\n```\\n\\n## Git Action\\n\\nNow, let\'s set up the git action so that the test runs automatically every time we push changes. To set it up, we must create `.github/workflow/test.yml` and `Makefile`.\\n\\n```bash\\nAuroraToNearXCCExample:\\n|-- aurora\\n|-- near\\n|-- Makefile\\n|-- .github/workflow/test.yml\\n```\\n\\nThe `.github/workflows/test.yml` contains the git action description. In our case, we are going to run it on `push` events. First, we install `foundry` for compiling our Solidity contracts, second, we checkout the repository with all submodules, and in the end, run the script from Makefile.\\n\\n```yaml\\nname: aurora-to-near-xcc-example test automatically\\n\\non: [push]\\n\\njobs:\\n  test-counter:\\n    runs-on: ubuntu-latest\\n    name: Test counter\\n    steps:\\n      - name: Install Foundry\\n        uses: foundry-rs/foundry-toolchain@v1\\n      - name: Clone the repository\\n        uses: actions/checkout@v3\\n        with: \\n          submodules: recursive\\n      - name: Test\\n        run: |\\n          make test-counter\\n```\\n\\nNow, let\u2019s take a closer look at the `Makefile` . First, we go to the `aurora` directory and install dependencies, second, we compile near contracts, and in the end, run our integration test.\\n\\n```makefile\\ntest-counter:\\n        cd aurora && \\\\\\\\\\n        yarn add @auroraisnear/aurora-sdk && \\\\\\\\\\n        cd ../near/contracts && \\\\\\\\\\n        ./build.sh && \\\\\\\\\\n        cd ../../aurora/integration-tests && \\\\\\\\\\n        cargo test --all --jobs 4 -- --test-threads 4\\n```\\n\\nThat is it, we have set up the git action! Now, our integration test will run automatically after each push to our GitHub repo.\\n\\n## Conclusion\\n\\nIn this article, we have created a simple contract on Aurora, which calls the function from Near contract. We have learned how it is possible to test such contracts inside the sandbox locally. And in the end, we have set up the git action to make the test run automatically.\\n\\nI hope this article will make it easier for you to develop contracts on Aurora with XCC to Near.\\n\\nHappy development! In a case you will have any questions about this article, feel free to contract our DevSupport team on [our Discord server](https://discord.com/invite/dEFJBz8HQV).\\n\\nThe example from this article you can find in this repo: [https://github.com/olga24912/AuroraToNearXCCExample](https://github.com/olga24912/AuroraToNearXCCExample)"},{"id":"/turning-smart-contracts-into-indexers","metadata":{"permalink":"/blog/turning-smart-contracts-into-indexers","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/turning-smart-contracts-into-indexers.md","source":"@site/blog/turning-smart-contracts-into-indexers.md","title":"Turning Smart Contracts into Indexers","description":"Learn how you can use functional programming patterns in Rust to share a codebase between both a smart contract and an indexer, and how cross-compilation can benefit your project","date":"2023-08-25T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":4.98,"hasTruncateMarker":true,"authors":[{"name":"Michael Birch","title":"Senior Research Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043123-t025c6kc9px-u025f7t5npl-c56792be0091-512.jpeg","key":"michael","page":null}],"frontMatter":{"title":"Turning Smart Contracts into Indexers","description":"Learn how you can use functional programming patterns in Rust to share a codebase between both a smart contract and an indexer, and how cross-compilation can benefit your project","date":"2023-08-25","authors":["michael"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1692963087-tsci.png"},"unlisted":false,"prevItem":{"title":"Integration tests for XCC communication","permalink":"/blog/communication-from-aurora-to-near-local-testing"},"nextItem":{"title":"How to get USDC tokens on Aurora testnet","permalink":"/blog/how-to-get-usdc-tokens-on-aurora-testnet"}},"content":"Recently, Michael Birch gave a [*talk at a virtual Rust conference*](https://www.conf42.com/Rustlang\\\\_2023\\\\_Michael_Birch_smart_contracts_indexers_crosscompilation) about some work we have done here at Aurora to enable our technology. In case you missed it, this blog post is a written version of the talk.\\n\\nThat talk was aimed at a more general audience, giving background about Aurora, Near, and blockchain technology in general. However, this post assumes you are already familiar with most of the Aurora/Near/blockchain background (you are here on our website, after all) and instead focuses more on the Rust side of things.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Motivation\\n\\nThe goal of this post is to describe how you can use functional programming patterns in Rust to share a codebase between both a smart contract and an indexer. But the first question to answer is why this is desirable in the first place.\\n\\nIndexers provide a specialized view of the blockchain state to enable low-latency responses to particular kinds of queries. For example, block explorers will use an indexer to show the balances of all the tokens held by a user. An indexer is required to accomplish this because the on-chain information about balances is indexed in the opposite way to how the block explorer displays the information. By which I mean that on-chain each token has information about all the addresses with a non-zero balance, but the block explorer shows all the non-zero balances for a single address.\\n\\nGenerally, indexers are specialized to follow the state of a particular contract (or class of contracts). Therefore, the code for the indexer is closely related to the code for the smart contract it follows. Thus, it would be lower developer maintenance to have a common codebase for the smart contract and its associated indexer.\\n\\nAdditionally, sharing a codebase makes it possible to create much more powerful indexers than simply something that can respond to queries. For example, an indexer with access to the smart contract logic can simulate whole transactions off-chain to provide free and low-latency feedback to users on potential errors.\\n\\nIn the case of Aurora, the indexer we use for the Aurora Engine smart contract serves data that is used by [our RPC implementation.](/blog/spinning-up-your-own-aurora-node) The Ethereum RPC spec includes a few methods (e.g., `eth_estimateGas`) which require simulating transactions before submitting them to the chain. Therefore, we have a clear use for the extra indexer features that are enabled by having a shared codebase between the Aurora Engine and its indexer.\\n\\n## Rust Features\\n\\nTo reach the goal of having a shared codebase between the Aurora Engine and an indexer for the Engine, we leverage some features of Rust.\\n\\n### Cross-Compilation\\n\\nThe Aurora Engine is written in Rust because it is a smart contract on Near which uses Web Assembly as its runtime. Rust has good support for Web Assembly (Wasm) as a compilation target, so it is a good language choice for writing smart contracts for Near. But, of course, it also is able to compile the same code to executable binaries for typical platforms (e.g., Linux). Compiling the same code to multiple output targets is referred to as \u201ccross-compiling\u201d.\\n\\nThe first step to having our smart contract code also be used as an indexer is to cross-compile the same code as both Wasm and a native executable. In Rust, it is easy to install other compilation targets (the default target will be whatever platform you installed Rust on) and to specify them as the compilation target. The following commands show installing the Wasm target and compiling a project to Wasm.\\n\\n```shell\\n$ rustup target add wasm32-unknown-unknown\\n$ cargo build --release \u2013-target wasm32-unknown-unknown\\n```\\n\\n### Conditional Compilation\\n\\nWhen you start compiling code to multiple platforms, likely there will be situations where you want the implementation to differ depending on the compilation target. For example, native code can read from a local file system, whereas Wasm modules need to delegate to their host (the machine running the Wasm VM) to access state.\\n\\nIn Rust, you can use conditional compilation to have different implementations depending on the target. In the example below, the function \\\\`foo\\\\` has different implementations depending on if the compilation target is Wasm or not.\\n\\n```rust\\nfn foo() {\\n    #[cfg(target_arch = \\"wasm32\\")]\\n    foo_for_wasm();\\n\\n    #[cfg(not(target_arch = \\"wasm32\\"))]\\n    foo_for_generic_arch();\\n}\\n```\\n\\nHowever, conditional compilation has some drawbacks. First of all, it\u2019s a little verbose, which hurts code readability. You can see in the example above that the function `foo` is \u201cnoisier\u201d than it would be if not for the extra conditional compilation annotations. Secondly, IDEs do not handle conditional compilation especially well. They will only analyze one branch of the code at a time, and it is a little tedious to switch between which target you are asking the IDE to check.\\n\\nFortunately, we do not need to use conditional compilation very much because we can adopt coding style patterns from functional programming. The key idea is to write code that is abstract with respect to the implementation of target-specific effects such as reading/writing state. In Rust, we can accomplish this using traits and type generics.\\n\\n### Traits and Type Generics\\n\\nRust\u2019s trait defines an interface. It gives the type signatures of the methods a type implementing that trait must have, but does not necessarily specify the implementation of those methods (though you are allowed to give a default implementation of a method in a trait). Consider the following example:\\n\\n```rust\\ntrait IO {\\n    fn read(&self, key: &[u8]) -> Vec<u8>;\\n    fn write(&mut self, key: &[u8], value: &[u8]);\\n}\\n\\nfn get_balance<I: IO>(io: &I, user: User) -> u128 {\\n    u128::from_be_bytes(&io.read(&user.id()))\\n}r\\n```\\n\\nThis example includes a trait with a (simplified) interface for interacting with state as well as a function with a generic type parameter. The syntax means \u201cthis function accepts any type so long as it implements `IO` the interface\u201d. The benefit of coding in this style is that the `get_balance` function can now be reused in any program, regardless of what compilation target it uses, so long as there is an `IO` implementation for it. This is exactly what enables us to share a codebase between our smart contract and indexer.\\n\\nIn this example above, it might seem like we are going through a lot of trouble to reuse one line of code in two different places. But this approach scales. The function we share does not need to be only a single line, it could have any amount of complexity.\\n\\nMoreover, state access is not the only target-specific effect. We can have traits for accessing environment variables (in the blockchain context, these would be variables like the current block height, the signer of the transaction, etc) and interacting with other processes (in the blockchain context, this corresponds to calling other smart contracts).\\n\\nBeyond reusability, there are other benefits to coding in this style. Code written in this way is easier to test because you can simulate the effects in-memory (for example, instead of actually reading and writing files). It is also easier to reason about this style of code. When there are no side-effects, the function signature gives you all the information you need about the function.\\n\\nIf a function needs access to state, then you know it will include the `IO` trait bound, and conversely, if the state is not needed, then it will not include that bound. When you can learn so much about a function without reading its implementation body, it becomes much easier to navigate the codebase.\\n\\n## Application: Aurora Engine\\n\\nThe entire Aurora Engine is written in this style. For example, [*here*](https://github.com/aurora-is-near/aurora-engine/blob/2.10.2/engine/src/engine.rs#L1280) is the real version of the `get_balance` function we showed a toy example of above. And similarly, there is a `set_balance` [*function*](https://github.com/aurora-is-near/aurora-engine/blob/2.10.2/engine/src/engine.rs#L1269). These two functions are composed together to make an `add_balance` [*function*](https://github.com/aurora-is-near/aurora-engine/blob/2.10.2/engine/src/engine.rs#L1258).\\n\\n```rust\\npub fn get_balance<I: IO>(io: &I, address: &Address) -> Wei {\\n    let raw = io\\n        .read_u256(&address_to_key(KeyPrefix::Balance, address))\\n        .unwrap_or_else(|_| U256::zero());\\n    Wei::new(raw)\\n}\\n\\npub fn set_balance<I: IO>(io: &mut I, address: &Address, balance: &Wei) {\\n    io.write_storage(\\n        &address_to_key(KeyPrefix::Balance, address),\\n        &balance.to_bytes(),\\n    );\\n}\\n\\npub fn add_balance<I: IO>(\\n    io: &mut I,\\n    address: &Address,\\n    amount: Wei,\\n) -> Result<(), BalanceOverflow> {\\n    let current_balance = get_balance(io, address);\\n    let new_balance = current_balance.checked_add(amount).ok_or(BalanceOverflow)?;\\n    set_balance(io, address, &new_balance);\\n    Ok(())\\n}\\n```\\n\\nYou can see the implementation of the `IO` trait for both the [*Near Runtime*](https://github.com/aurora-is-near/aurora-engine/blob/2.10.2/engine-sdk/src/near_runtime.rs#L128), and the \u201c[*standalone engine*](https://github.com/aurora-is-near/aurora-engine/blob/2.10.2/engine-standalone-storage/src/engine_state.rs#L82)\u201d which uses a `rocksdb` instance to persist the state.\\n\\nThe former is used in the Wasm artifact, which is deployed to Near as the Aurora Engine smart contract. The standalone engine is used to [*implement the eth_estimateGas RPC method*](https://github.com/aurora-is-near/borealis-engine-lib/blob/v0.23.4/refiner-app/src/socket.rs#L129), and the state is populated by [*consuming Near blocks*](https://github.com/aurora-is-near/aurora-engine/blob/2.10.2/engine-standalone-storage/src/sync/mod.rs#L229) (from [*Near data lake for example*](https://github.com/aurora-is-near/borealis-engine-lib/tree/v0.23.4#near-data-lake)).\\n\\n## Conclusion\\n\\nThe take-home message from this post is that following the functional programming pattern of only writing business logic using abstractions of target-specific effects such as IO results in code that is easier to test, maintain, and reuse. In the particular case of Aurora, that reuse manifests as having the Aurora Engine smart contract and the indexer that serves the Aurora RPC share a codebase."},{"id":"/how-to-get-usdc-tokens-on-aurora-testnet","metadata":{"permalink":"/blog/how-to-get-usdc-tokens-on-aurora-testnet","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/how-to-get-usdc-tokens-on-aurora-testnet.md","source":"@site/blog/how-to-get-usdc-tokens-on-aurora-testnet.md","title":"How to get USDC tokens on Aurora testnet","description":"While developing your smart contracts on Aurora, there are situations when you will need to get native Ethereum ERC-20 tokens on your testnet account \u2013 let\u2019s find out how to get these by using the USDC token as an example","date":"2023-07-28T00:00:00.000Z","tags":[{"inline":false,"label":"Tips & Tricks","permalink":"/blog/tags/tips_and_tricks","description":"Short posts about tech for devs on Aurora"}],"readingTime":3.05,"hasTruncateMarker":true,"authors":[{"name":"Olga Kunyavskaya","title":"Bridge Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043237-t025c6kc9px-u03dl8hkg1w-fe48e17d7ba2-512.png","key":"olga","page":null}],"frontMatter":{"title":"How to get USDC tokens on Aurora testnet","description":"While developing your smart contracts on Aurora, there are situations when you will need to get native Ethereum ERC-20 tokens on your testnet account \u2013 let\u2019s find out how to get these by using the USDC token as an example","date":"2023-07-28","authors":["olga"],"tags":["tips_and_tricks"],"image":"https://www.datocms-assets.com/95026/1690542624-usdc.png"},"unlisted":false,"prevItem":{"title":"Turning Smart Contracts into Indexers","permalink":"/blog/turning-smart-contracts-into-indexers"},"nextItem":{"title":"EVM gas vs. Near gas on Aurora","permalink":"/blog/evm-gas-near-gas-on-aurora"}},"content":"When you develop a contract, quite often you need ERC-20 tokens for testing. If your contract is rather small and doesn\'t use cross-contract calls, most likely, you don\'t need official USDC tokens or any other specific tokens. In that case, the best solution is just to take the standard ERC-20 contract, deploy it, and mint as many test tokens as you wish.\\n\\nHowever, sometimes the easier solution for testing can be to get official testing tokens. For example, if your contract is use difficult cross-contract calls and dependencies contracts are already deployed on testnet and support only limited numbers of tokens. When I am testing RainbowBridge during development I use the USDC tokens on testnet.\\n\\nIn this article, I will explain how to get official native Ethereum ERC-20 tokens on your Aurora testnet account in the example of USDC tokens. This method will work with other popular native Ethereum ERC-20 as well, and it will be clear how to get these tokens also in Goerli Ethereum and in Near testnet.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Plan for getting USDC tokens on Aurora testnet\\n\\nFor getting USDC tokens, we\'re going to use the following plan:\\n\\n1. Create an account in MetaMask for the Ethereum Goerli network and Aurora testnet\\n2. Mint Ether for your Ethereum account\\n3. Swap Ether to the USDC tokens in the Ethereum network\\n4. Transfer USDC tokens from Ethereum to Aurora by using Rainbow Bridge\\n\\nThe instructions for steps 1 and 2 you can find in article [\\"Getting started with Aurora\\"](/blog/getting-started-with-aurora), so I will not describe them here. For the 1 step see section \\"Creating an account on the Aurora testnet using MetaMask\\", for the 2 step see section \\"Obtaining AuroraEth on the testnet\\" -> \\"The second method: transfer from Ethereum\\".\\n\\nI assume that you already have an account in MetaMask for both Goerli Ethereum network and Aurora testnet and also you have some Ether in Goerli Ethereum network.\\n\\n## USDC tokens accounts\\n\\nThere can be a large number of accounts for USDC on the testnets. Moreover, you can take a USDC token contract and deploy it on your own. We are interested in the official deployment of USDC tokens on Goerli Ethereum and the official wrappers of this token on Aurora and Near.\\n\\nOfficial USDC address on Goerli Ethereum: [0x07865c6E87B9F70255377e024ace6630C1Eaa37F](https://goerli.etherscan.io/token/0x07865c6e87b9f70255377e024ace6630c1eaa37f)\\n\\nFor search the addresses on the Near and Aurora testnet networks and check that address is supported by Rainbow Bridge you can go to [https://testnet.rainbowbridge.app/deploy](https://testnet.rainbowbridge.app/deploy) , write the address of the USDC token in the search and click the `Find Token` button:\\n\\n![](https://www.datocms-assets.com/95026/1690544553-screenshot-2023-07-28-at-12-40-45.png)\\n\\nYou will see the query result:\\n\\n![](https://www.datocms-assets.com/95026/1690545689-screenshot-2023-07-28-at-13-01-18.png)\\n\\nAs we can see from the image above, the address on the NEAR is: `07865c6e87b9f70255377e024ace6630c1eaa37f.factory.goerli.testnet`\\n\\nAnd the address on the Aurora is: `0x901fb725c106e182614105335ad0e230c91b67c8`\\n\\n**WARNING:** Some sites can mint USDC tokens, but with a different address, so you need to double-check the address of minted tokens.\\n\\nThis [repo](https://github.com/aurora-is-near/bridge-assets/tree/master/tokens) also contains the list of tokens supported by the Rainbow Bridge, however this list is not full for the testnets, for example, the USDC tokens are not included.\\n\\n## Get USDC token on Ethereum\\n\\nWe have the Goerli Ethereum account and some GoerliETH. Let\u2019s exchange some Ether for USDC tokens! For swapping, we\'re going to use Uniswap.\\n\\n**1. Open Uniswap site:** [https://app.uniswap.org/#/swap](https://app.uniswap.org/#/swap)\\n\\n**2. Connect to Goerli Network.** It can look like it doesn\u2019t support testnet network, but it actually support it, just it is not clear from the web interface.\\n\\n* Click the `Connect` button. Choose MetaMask and connect to your account.\\n\\n![](https://www.datocms-assets.com/95026/1689675168-uniswapconnect.jpg)\\n\\n* Switch on `Show testnets` option on the Uniswap site:\\n\\n![](https://www.datocms-assets.com/95026/1690544253-screenshot-2023-07-28-at-12-35-32.png)\\n\\n![](https://www.datocms-assets.com/95026/1690544262-screenshot-2023-07-28-at-12-35-41.png)\\n\\n![](https://www.datocms-assets.com/95026/1690544274-screenshot-2023-07-28-at-12-35-54.png)\\n\\n* Change the network to Goerli Testnet.\\n\\n![](https://www.datocms-assets.com/95026/1690544545-screenshot-2023-07-28-at-12-39-49.png)\\n\\n**3. Swap GoerliEth into USDC:**\\n\\n* Click `Select token`. Yes, you doesn\u2019t see the USDC tokens in the list. It is Ok, don\u2019t worry:\\n\\n![](https://www.datocms-assets.com/95026/1690544771-screenshot-2023-07-28-at-12-45-29.png)\\n\\nIn the search field write `USDC` and select the `USD Coin` from the list. For some tokens, even searching by the token\'s name doesn\'t help. In that case, try to use the **token\'s address** in the search.\\n\\n![](https://www.datocms-assets.com/95026/1690544783-screenshot-2023-07-28-at-12-45-51.png)\\n\\n![](https://www.datocms-assets.com/95026/1690544794-screenshot-2023-07-28-at-12-45-57.png)\\n\\n* Put some small amount of ETH in first line. 0.01 G\xf6ETH will be enough.\\n\\n![](https://www.datocms-assets.com/95026/1690544849-screenshot-2023-07-28-at-12-44-59.png)\\n\\n* Click Swap\\n\\n![](https://www.datocms-assets.com/95026/1690544873-screenshot-2023-07-28-at-12-45-06.png)\\n\\nCongratulations! Now you get a lot of test USDC in your Ethereum account. You can check, that you receive tokens in MetaMask and check the address of the received tokens. If you don\u2019t see the USDC tokens click \\"Import tokens\\" in MetaMask and put the address of USDC token.\\n\\n## Transfer USDC tokens to Aurora\\n\\nNow the easy part: transfer USDC tokens from Ethereum to Aurora.\\n\\n* Open the Rainbow Bridge for testnet: [https://testnet.rainbowbridge.app/](https://testnet.rainbowbridge.app/)\\n* Click New Transfer:\\n\\n![](https://www.datocms-assets.com/95026/1690544972-screenshot-2023-07-28-at-12-48-40.png)\\n\\n* Connect to your accounts on Ethereum and on Aurora:\\n\\n![](https://www.datocms-assets.com/95026/1690545004-screenshot-2023-07-28-at-12-48-57.png)\\n\\nAnd now, choose USDC.e tokens and amount for transferring, and click `Continue`:\\n\\n![](https://www.datocms-assets.com/95026/1690545027-screenshot-2023-07-28-at-12-49-11.png)\\n\\nDone! Now you need to wait *20 minutes* before you get your test USDC on Aurora.\\n\\n*Remark*: you also can transfer the USDC tokens or other tokens to your Near accounts in the same way.\\n\\n## Conclusion\\n\\nIn this short article, we learned how to get a lot of USDC tokens on Ethereum, Near and Aurora. This method is also applicable to other popular Ethereum ERC-20 tokens. Now you can use these tokens to test your contracts. Happy development and testing!\\n\\n## References\\n\\n* Article with instructions on how to install MetaMask and mint Ether: [/blog/getting-started-with-aurora](/blog/getting-started-with-aurora)\\n* USDC tokens address on Ethereum Goerli: [https://goerli.etherscan.io/address/0x07865c6e87b9f70255377e024ace6630c1eaa37f](https://goerli.etherscan.io/address/0x07865c6e87b9f70255377e024ace6630c1eaa37f)\\n* Uniswap: [https://app.uniswap.org/#/swap](https://app.uniswap.org/#/swap)\\n* Rainbow Bridge For Testnet: [https://testnet.rainbowbridge.app/](https://testnet.rainbowbridge.app/)\\n* Checking the supported tokens for Rainbow Bridge on Testnet: [https://testnet.rainbowbridge.app/deploy](https://testnet.rainbowbridge.app/deploy)"},{"id":"/evm-gas-near-gas-on-aurora","metadata":{"permalink":"/blog/evm-gas-near-gas-on-aurora","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/evm-gas-near-gas-on-aurora.md","source":"@site/blog/evm-gas-near-gas-on-aurora.md","title":"EVM gas vs. Near gas on Aurora","description":"How the Aurora\'s EVM gas and Near gas are related? What gas limits do we have, and how Engine optimizations are saving your costs?","date":"2023-07-07T00:00:00.000Z","tags":[{"inline":false,"label":"Core Tech","permalink":"/blog/tags/core_tech","description":"Posts about core technologies on Aurora"}],"readingTime":5.733333333333333,"hasTruncateMarker":true,"authors":[{"name":"Michael Birch","title":"Senior Research Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043123-t025c6kc9px-u025f7t5npl-c56792be0091-512.jpeg","key":"michael","page":null}],"frontMatter":{"title":"EVM gas vs. Near gas on Aurora","description":"How the Aurora\'s EVM gas and Near gas are related? What gas limits do we have, and how Engine optimizations are saving your costs?","date":"2023-07-07","authors":["michael"],"tags":["core_tech"],"image":"https://www.datocms-assets.com/95026/1688080861-gas.png"},"unlisted":false,"prevItem":{"title":"How to get USDC tokens on Aurora testnet","permalink":"/blog/how-to-get-usdc-tokens-on-aurora-testnet"},"nextItem":{"title":"Aurora Cloud: Borealis Business","permalink":"/blog/aurora-cloud-borealis-business"}},"content":"A core piece of Aurora\u2019s technology is the [*Aurora Engine smart contract*](https://github.com/aurora-is-near/aurora-engine), which is an Ethereum Virtual Machine (EVM) implementation deployed as a smart contract on Near. Therefore, Aurora sits at the intersection of both EVM and Near runtimes. It naturally draws us to think about comparisons between EVM and Near.\\n\\nFor example, the concept of \u201cgas\u201d exists in both the EVM and Near\u2019s runtime. The reason is because of the famous [*halting problem*](https://en.wikipedia.org/wiki/Halting_problem), which says we cannot know in advance if an arbitrary computer program will finish in a finite time. In the context of a smart contract platform, this means we must measure (and limit) the computation the contract does at runtime. In both the EVM and Near, \u201cgas\u201d is the unit that is used to measure the computational work done by a smart contract.\\n\\nEven though EVM gas and Near gas both measure the same thing, they are not identical. One analogy is miles and kilometers; both measure distance, but the numerical value of the same physical distance will be different depending on which unit is used. Computation is a more abstract concept than distance, but this analogy leads us to expect some kind of approximately linear relationship between EVM gas and Near gas, similar to how 1 mile equals 1.61 kilometers.\\n\\nIn this blog post, we explore this question and discuss the implications for developers building on Aurora.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The theoretical relation\\n\\nIn theory, we should be able to derive the relationship between EVM gas and Near gas by considering the EVM gas cost of each operation in the EVM and calculating how much Near gas this same operation costs based on its implementation in Aurora. Unfortunately, this is much more difficult in practice than it sounds. The Aurora Engine is written in Rust and compiled to Web Assembly (Wasm).\\n\\nThis compilation process convolutes the conceptual mapping between EVM opcodes and operations in the Near runtime. There are additional complexities in trying to do this calculation in that Aurora virtualizes the whole EVM inside Wasm, and hence how much Near gas an opcode takes may depend on the overall VM state (e.g., because more Wasm memory needs to be allocated).\\n\\nWhile it is good to have this idea of being able to calculate the relationship from first principles (and we will revisit it later in this post), it is not a practical way to answer our question. For that, we will use empirical data instead.\\n\\n## Gathering data\\n\\nData for EVM and Near gas used for all transactions on Aurora is available via a combination of our RPC and Near\u2019s RPC. Consider the following call (done via the command line using the [*HTTPie*](https://httpie.org) tool):\\n\\n```shell\\nhttp post https://mainnet.aurora.dev/ jsonrpc=2.0 id=1 \\\\\\n  method=eth_getTransactionReceipt \\\\\\n  params:=\'[\\"0x4c2b8b5d766fe0411d0003bf4c9d2becc9d6dd7120272cf9f1a6cac73e4c3543\\"]\'\\n```\\n\\nThe parameter in this call can be any hash of a transaction on Aurora (the given one is only an example). Notice the `gasUsed` field in the response, which gives the (hexadecimal encoded) amount of EVM gas used in the transaction (46,574 in this example).\\n\\nIn addition to the standard response fields defined by the [*Ethereum standard*](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactionreceipt), the Aurora RPC returns two other fields: \\\\`nearReceiptHash\\\\` and \\\\`nearTransactionHash\\\\`. These give the receipt/transaction hashes corresponding to the underlying transaction that was executed on Near (by the Aurora Engine contract).\\n\\nTo use these extra fields, there is some additional work involved because Near hashes are always presented in [*base58 encoding*](https://digitalbazaar.github.io/base58-spec/), whereas our RPC returns them in hexadecimal encoding (to be consistent with how Ethereum usually presents hashes).\\n\\nYou can read more about this in a [*previous article*](/blog/convert-aurora-transaction-into-near-s-one). For our purposes here, it is easy enough to write a [*Python script to do the conversion*](https://gist.github.com/birchmd/a336269596651992ed9b742c843b9b0f) for us and chain this together with the [*jq tool*](https://jqlang.github.io/jq/) to get the Near transaction hash in one command:\\n\\n```shell\\nhttp post https://mainnet.aurora.dev/ jsonrpc=2.0 id=1 \\\\\\n method=eth_getTransactionReceipt \\\\\\n params:=\'[\\"0x4c2b8b5d766fe0411d0003bf4c9d2becc9d6dd7120272cf9f1a6cac73e4c3543\\"]\' \\\\\\n | jq .result.nearTransactionHash | hex2b58\\n```\\n\\nFrom the Near transaction hash, we can get the amount of Near gas used in the transaction from the Near RPC:\\n\\n```shell\\nhttp post https://archival-rpc.mainnet.near.org jsonrpc=2.0 id=dontcare \\\\\\n  method=tx \\\\\\n  params:=\'[ \\"46ACGRcUQadezAWQuZ9WVopSAbeeWpJZ1H8hmVuWPhJu\\", \\"relay.aurora\\"]\'\\n```\\n\\nWhere the first parameter is the Near transaction hash obtained from the Aurora RPC by the previous command. There is a lot of data returned from the response, but for our purposes, we only care about the gas used in the Aurora Engine execution. We can isolate just this part of the response using `jq`:\\n\\n```shell\\nhttp post https://archival-rpc.mainnet.near.org jsonrpc=2.0 id=dontcare \\\\\\n  method=tx \\\\\\n  params:=\'[ \\"46ACGRcUQadezAWQuZ9WVopSAbeeWpJZ1H8hmVuWPhJu\\", \\"relay.aurora\\"]\' \\\\\\n  | jq \'.result.receipts_outcome[0].outcome.gas_burnt\'\\n```\\n\\nGiven this, it\u2019s pretty easy to automate obtaining the EVM and Near gas data from any Aurora transactions we want!\\n\\n## Empirical results\\n\\nIn what follows, we consider all the successful (i.e., ignoring obvious failures like incorrect nonce \u2013 these would be outliers in our data because they don\u2019t do any real EVM execution) Aurora transactions from June 4, 2023 (block height 93442283) to June 12, 2023 (block height 94047083). Below is a plot of EVM gas vs Near gas. The Near numbers have been scaled by 10^12 since Tgas is the common unit Near gas values are presented in, and the EVM numbers have been scaled by 10^3 since the smallest EVM gas possible is 2100.\\n\\n![](https://www.datocms-assets.com/95026/1688079135-screenshot-2023-06-29-at-23-51-52.png)\\n\\nAs expected, there is a strong linear correlation between the values. Though interestingly, there are (at least) 3 distinct lines as opposed to just one.\\n\\nThe line with the shallowest slope (orange line in the plot) corresponds to storage-heavy transactions (e.g., contract deployments). These transactions use a lot of EVM gas but not very much Near gas. The reason is because of the difference in how the EVM charges for storage and how Near charges for it. In the EVM, storage access is pretty expensive in terms of gas, but there is a gas refund when storage is released.\\n\\nOn the other hand, Near does not change much gas for storage access but does charge the account in the form of [*storage staking*](https://docs.near.org/concepts/storage/storage-staking) (the account must maintain a minimum Near balance to be allowed to have so much storage used). This difference in how storage is charged means disproportionately less Near gas is used for storage compared to other computational costs (e.g., CPU and memory access).\\n\\nThe majority of points in the plot lie on the steepest line (green line in the plot), though there is a lot of variance around it. Taking a linear regression of this data, we determine the average slope is around 0.122. This provides us an empirical answer to our question of how EVM and Near gas are related on Near. Approximately 1.22 x10^8 Near gas is spent per EVM gas. In fact, this relation is what informs the fixed EVM gas price set by Aurora\u2019s relayers.\\n\\nThe relationship between EVM gas and Near gas allows us to convert Near\u2019s gas price into an EVM gas price to charge our users (of course, most users take advantage of the free transaction available from [*AuroraPass*](https://aurora.dev/blog/introducing-aurora-pass-your-gateway-to-the-decentralized-web) and don\u2019t worry about gas prices anyway).\\n\\nThe red line in the plot follows a distinct collection of points between the \u201cstorage-heavy\u201d and \u201cmain\u201d lines. I do not know what is special about these transactions, which makes them use less Near gas than those on the main trendline. It is difficult to learn high-level information about transactions just from the set of addresses they call and the binary input they send.\\n\\nOne hypothesis could be that these transactions are literally a middle-ground between the two extremes of the gas, primarily coming from CPU costs and primarily coming from storage costs. There could be something about the algorithm the smart contracts implement such that the amount of storage access they need is proportional to the amount of CPU-bound computation they perform. Regardless of the reason, this may be useful information for the developers of those contracts to know since they are able to complete transactions with higher EVM gas values than transactions on the main line.\\n\\nThis data has additional consequences for developers on Aurora. For example, [*our documentation*](https://doc.aurora.dev/evm/evm-overview) mentions an edge case incompatibility between Aurora and Ethereum mainnet where a transaction may run out of Near gas before it runs out of EVM gas.\\n\\nThis causes the transaction to fail on Aurora when it would pass on Ethereum. The transaction gas limit on Near (no such concept exists on Ethereum, there is only the block gas limit) is 300 Tgas, which implies that this edge case described in the documentation arises for EVM transactions exceeding approximately 2.5 x 10^6 EVM gas. This assumes the transaction lies on the main trendline, though, as we discussed, there are other kinds of transactions with different Near/EVM gas conversion ratios that can achieve higher EVM gas values.\\n\\n## Future directions\\n\\nFor us internally at Aurora, this plot also gives us a clear metric for our Engine\u2019s performance. Our goal is to process EVM transactions as efficiently as possible (i.e., use as little Near gas as possible per EVM gas), which corresponds to lowering the slope of the main trendline in the EVM gas vs. Near gas plot.\\n\\nSince Aurora launched, we have made a lot of progress in this respect: more than a factor of 2 improvement since February 2022 (Engine v2.4.0 vs. v2.9.0).  But we still have more work to do. We would like to make the amount of EVM gas that fits into 300 Near Tgas equal to the Ethereum block gas limit (30 x 10^6 EVM gas) so that our developers no longer need to worry about the edge case discussed above.\\n\\nBecause, in this case, we will be sure that no EVM transaction which succeeds on the Ethereum mainnet can exceed 300TGas on Near. Going back to the theoretical argument from earlier in the article, we know that we should be able to improve the Engine\u2019s efficiency by changing the implementation details. In particular, the overhead of running an EVM interpreter must contribute to the Near gas cost significantly.\\n\\nOur next innovation towards this goal is to develop an [*EVM to Wasm compiler*](https://github.com/aurora-is-near/evm2near). Such a compiler will allow directly executing EVM contracts in the Near runtime instead of needing to interpret them within a virtualized EVM. Some [*simple benchmarking data*](https://github.com/aurora-is-near/aurora-engine/pull/463) suggests that we should be able to get orders of magnitude performance improvements using this kind of approach."},{"id":"/aurora-cloud-borealis-business","metadata":{"permalink":"/blog/aurora-cloud-borealis-business","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/aurora-cloud-borealis-business.md","source":"@site/blog/aurora-cloud-borealis-business.md","title":"Aurora Cloud: Borealis Business","description":"Learn how to hide the fees complexities from your users by using Borealis Business deals","date":"2023-06-20T00:00:00.000Z","tags":[{"inline":false,"label":"Core Tech","permalink":"/blog/tags/core_tech","description":"Posts about core technologies on Aurora"}],"readingTime":5.8,"hasTruncateMarker":true,"authors":[{"name":"Boris Polania","title":"DevRel","imageURL":"https://www.datocms-assets.com/95026/1678396869-twiter_profile_pic.png","key":"boris","page":null}],"frontMatter":{"title":"Aurora Cloud: Borealis Business","description":"Learn how to hide the fees complexities from your users by using Borealis Business deals","date":"2023-06-20","authors":["boris"],"tags":["core_tech"],"image":"https://www.datocms-assets.com/95026/1687257758-bb-cover.png"},"unlisted":false,"prevItem":{"title":"EVM gas vs. Near gas on Aurora","permalink":"/blog/evm-gas-near-gas-on-aurora"},"nextItem":{"title":"Getting started with Aurora","permalink":"/blog/getting-started-with-aurora"}},"content":"Since its inception, the Aurora Protocol has continued to break boundaries in the blockchain world. Its latest innovation is a service known as Borealis Business, aimed at solving one of the most significant challenges for users of Web3 products \u2013 the concept of transaction fees.\\n\\n\x3c!-- truncate --\x3e\\n\\nBorealis Business is a transaction processing and accounting service that allows Aurora Cloud customers to hide the fees complexities from their users while implementing nearly any conceivable business model to manage costs. This article aims to shed light on Borealis Business, its operations, benefits, and integration details with the comprehensive suite of [*Aurora Cloud*](https://auroracloud.dev/) offerings.\\n\\n## How does it work?\\n\\nAurora has a relaying architecture mapping Aurora to NEAR transactions, separating the origination and payment. At the core of the Borealis Business is the Rule Engine (BBRE), which oversees this transaction relaying to fulfill its cost management goals. It allows the transfer of transaction costs to a third party\u2013typically a decentralized app (dApp)\u2013that seeks to cover its users\' fees. This way, businesses can make their users\' experience friction-free by shouldering transaction fees.\\n\\nCompanies can establish Customer Deals through the Rule Engine by setting specific rules determining who should pay for a transaction and under what conditions. E.g., incoming transactions to the Aurora+ staking contract are now made free in this way. The strategies which Rule Engine allows are particularly advantageous for companies seeking to offer region-specific or time-bound promotions.\\n\\nFor instance, businesses can provide free transactions exclusively to their European customers around the clock while extending this offer to customers from other regions only on weekends. This level of customization empowers companies to accommodate diverse business models and opens up possibilities for novel concepts, including cross-business interactions.\\n\\n## Setting Up a Deal\\n\\nThe setup process for a Customer Deal begins with the company formulating specific terms and conditions and the AuroraLabs team translating those into rules for use within the Rule Engine.\\\\\\n\\\\\\nFor instance, a rule might be as follows: \\"All users interacting with contract A will receive 50 free transactions per month.\\" If a transaction meets the specified criteria outlined in these rules, the associated cost is billed directly to the business that owns the deal. The rule engine diligently executes this checking and matching process, ensuring accurate transaction cost allocation.\\n\\nWhile Borealis Business does not have a user interface, efforts are underway to incorporate this shortly. Storing all matched transactions within a Borealis Business database can offer immense value by providing comprehensive analytics about the deals. We plan to support an analytics dashboard using a [*Metabase*](https://www.metabase.com/), providing the companies with critical insights into that data.\\n\\nLet\u2019s see this setup process in more detail.\\n\\n### How is a Deal Set?\\n\\nAs previously discussed, Deals consist of rules. Therefore, when a business engages with Aurora\'s engineering team, two key aspects need to be established:\\n\\n* Which smart contracts will be part of a deal?\\n* What is the business logic around free transactions for users?\\\\\\n\\nTypically, setting up a deal would initiate with specific parameters. These, however, are not strict boundaries but flexible starting points. Our adaptability allows us to fine-tune the operational rules by leveraging a wide range of resources. These could range from IP addresses and authentication tokens to the internal data embedded within each transaction. Nevertheless, right now, we propose using the following set of parameters:\\n\\n* **FROM:** This parameter specifies the originator of the transaction, and it can take values such as ***All***, meaning that the rule engine will not filter any transactions based on their origin address (i.e., all origin addresses are valid for this deal) or ***EOA*** in which case the rule engine will only pick up transactions coming from a specific list of addresses (EOAs). We refer to this list as the whitelist, which must be populated by the businesses.\\n* **TO:** This parameter specifies the transaction\'s target, and it can take values such as an ***address*** so that the rule engine will pick up transactions directed to this specific contract address. If a transaction goes to another contract, it cannot be associated with this deal.\\n* **DEAL**: This parameter specifies the number of transactions that the beneficiaries of this deal can get. It can be set to UNLIMITED or a specific number.\\n\\nHere are a few simple examples of Borealis Business deals:\\n\\n![](https://www.datocms-assets.com/95026/1687255307-untitled-2023-06-12-1504.png)\\n\\n### Aurora Pass as a Deal\\n\\nA notable example of a deal within Borealis Business is Aurora Pass (AP), which stands out due to its unique approach. Unlike other deals, Aurora Pass does not utilize the address as the FROM parameter. Instead, it employs an authorization (AUTH) token system that is automatically generated when a new user sets up an account on Aurora Pass.\\n\\nThe Rule Engine plays a crucial role when transactions occur by validating each associated AUTH token. Upon identifying a token that corresponds to an Aurora Pass account, the engine applies the specified deal, ensuring that transaction costs are allocated according to the conditions outlined in the Aurora Pass deal. Moreover, AUTH tokens allow future support of multiple addresses within Aurora Pass while keeping the possibility of applying the benefits of free transactions to a whole account and not to a specific address.\\\\\\n\\\\\\nHere is an image describing how the AuroraPass (AP) Deal works:\\n\\n![](https://www.datocms-assets.com/95026/1687255382-pasted-image-0-1.png)\\n\\n## Whitelisting\\n\\nBusinesses must define a list of approved addresses that can benefit from their deal. The whitelisted addresses are managed via a dedicated API to enable companies to:\\n\\n* Add an address.\\n* Remove an address.\\n* Check if an address is on the whitelist.\\n\\nThe Aurora team will provide businesses with the credentials for this API as part of the Borealis deal setup process.\\n\\nHowever, it\'s important to note that the scope of this API will extend far beyond this whitelisting function. Future enhancements will see the addition of variables like gas price thresholds, among other rule-based parameters, and our partners will also be granted the ability to modify these parameters.\\n\\n## User Experience and User Journey\\n\\nBorealis Business\u2019 user journey is seamless. Once a user signs into a dApp with a Borealis deal, the dApp checks the whitelist status of the user\'s address. If approved, the user can make transactions within the app without bearing the transaction cost. This process is managed by the Borealis rule engine, which matches the transaction with the relevant deal.\\n\\n### User Journey\\n\\n1. A user signs into a Decentralized App (dApp).\\n2. This dApp has a Borealis deal.\\n3. The dApp checks whether this address was added to the whitelist.\\n4. If not, the dApp decides whether to send the address for whitelisting. This depends entirely on the business logic. For example, when requesting a transaction\u2019s signature from a whitelisted wallet, the dApp must set gasPrice to 0 because regular wallets will use the default gas price.\\n5. The user makes a transaction within the app.\\n6. The user signs the transaction.\\n7. The transaction goes through Aurora\u2019s infrastructure, and the Borealis rule engine checks for deal matches.\\n8. It finds a match with the business deal here, so it will report the gas fees to the business, leaving the transaction gas free for the user, and will let the transaction go through and be submitted to Aurora\u2019s internal mempool.\\n\\nHere is a scheme describing the User Journey above:\\n\\n![](https://www.datocms-assets.com/95026/1687256296-untitled-2023-06-20-1009.png)\\n\\n## Anti-abuse Rules\\n\\nIn addition, Aurora has established anti-abuse rules to prevent potential abuse of the business goals, which can be adjusted according to the client\'s request. For example, businesses can limit the number of transactions per minute or day. So, a user can have 50 free transactions per month but can do up to 10 per minute and 25 per day.\\n\\n## Multiple Deals\\n\\nA transaction can be part of multiple deals. Aurora has created a hierarchy of deals and a randomization process to manage this. If a user connects with Aurora Pass on a dApp, the transaction is attributed to the dApp deal, not the Aurora Pass deal. This hierarchy ensures that dApps take precedence over Aurora\'s own deals.\\n\\nThe randomization process comes into play when some transaction matches multiple deals. In such cases, the transaction will be randomly added to one of the deals. This balanced system ensures fair distribution and usage of the Borealis Business service across various deals.\\n\\n## Developers Considerations\\n\\nWhile the Aurora engineering team is responsible for crafting Customer Deals and the rules that regulate them, there are a few essential aspects that developers need to keep in mind, particularly when these deals are directed at smart contracts. For instance, a modular architecture might be required if the aim is to set up multiple contracts based on the varying benefits allocated to different users. Moreover, if the business model requires the dynamic deployment of contracts through contract factories, it might be necessary to whitelist users for all the contracts that require it.\\n\\nIn conclusion, the Borealis Business provides an innovative solution to a significant issue within the blockchain ecosystem: the cost of transactions. As a result, Aurora is paving the way for more user-friendly blockchain applications and potentially transformative business models, which developers should consider while creating new applications and products.\\n\\n## What\u2019s next?\\n\\nBorealis Business represents a transformative approach to managing transaction costs in the realm of blockchain. Its strategic alignment with the needs of businesses and users sets it apart, reflecting the evolving demands of the digital landscape. Its innovative mechanisms allow businesses to absorb transaction costs, providing a seamless user experience. Its ability to distinguish between the initiator of a transaction and the payer of transaction costs has proven to be a game-changer.\\n\\nA significant advantage of Borealis Business is its inherent ability to adapt and expand based on market demands and technological advancements. The planned release of public APIs will add another dimension to the offering. It will give businesses more control over the customization and management of their deals and whitelist. The autonomy our APIs will provide is a significant leap forward, allowing businesses to adapt swiftly and efficiently to changing market conditions and user demands.\\n\\nFuture advancements will reinforce Borealis Business\' role as a cutting-edge solution and strengthen Aurora\'s standing as an innovative leader in the blockchain industry. As we enter an increasingly digital future, the agility and adaptability of systems like this will undoubtedly become more crucial. Aurora is already paving the way, redefining the status quo, and pushing the boundaries of what\'s possible in transaction cost management."},{"id":"/getting-started-with-aurora","metadata":{"permalink":"/blog/getting-started-with-aurora","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/getting-started-with-aurora.md","source":"@site/blog/getting-started-with-aurora.md","title":"Getting started with Aurora","description":"Practical guide for beginners who want to learn how to use Aurora and develop smart contracts","date":"2023-06-06T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":8.92,"hasTruncateMarker":true,"authors":[{"name":"Olga Kunyavskaya","title":"Bridge Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043237-t025c6kc9px-u03dl8hkg1w-fe48e17d7ba2-512.png","key":"olga","page":null}],"frontMatter":{"title":"Getting started with Aurora","description":"Practical guide for beginners who want to learn how to use Aurora and develop smart contracts","date":"2023-06-06","authors":["olga"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1686009470-gswa.png"},"unlisted":false,"prevItem":{"title":"Aurora Cloud: Borealis Business","permalink":"/blog/aurora-cloud-borealis-business"},"nextItem":{"title":"Spinning up your own Aurora node","permalink":"/blog/spinning-up-your-own-aurora-node"}},"content":"This article is a practical guide for beginners who want to learn how to work with the Aurora blockchain. It covers various aspects such as the connection of Aurora with Ethereum and Near blockchains, setting up an account on the Aurora\'s `testnet` using MetaMask, writing a small smart contract, and interacting with it using the Hardhat. Additionally, it includes writing a simple test and exploring different explorers to view transaction details.\\n\\nThe article assumes no prior knowledge of Ethereum or experience working with it. However, it does expect basic programming skills, familiarity with the command line, and a general understanding of blockchain and smart contracts. All commands provided in the article will be specific to the Linux operating system.\\n\\n\x3c!-- truncate --\x3e\\n\\n## How Aurora is related to Ethereum and Near\\n\\nWhile working with Aurora, you must often interact with first-layer blockchains such as Ethereum and NEAR. Ethereum is one of the most well-known and popular blockchains with a large ecosystem. Nevertheless, it exhibits some technological limitations, the most significant being the transaction cost. As a result, interacting with contracts on Ethereum often requires a considerable amount of money for transaction fees. Conversely, NEAR is a blockchain developed later with specific technical advantages over Ethereum, including significantly lower transaction costs.\\n\\nAurora is a second-layer blockchain built on NEAR and designed to be highly compatible with Ethereum, making it easier to migrate Ethereum\'s codebase to Aurora.\\n\\n### Connection with Ethereum\\n\\nAurora uses AuroraEth as the payment currency for transactions. AuroraEth is essentially the same as Ether but operates within the Aurora network. You will notice that it is named just ETH everywhere: in MetaMask, Explorer, etc., so there is no difference actually for the users and devs.\\n\\nContracts in Aurora are written in Solidity and have the same structure and syntax as Ethereum contracts. The addressing system is also the same. Consequently, you can use tools such as MetaMask, Hardhat, and other applications to interact with Aurora. The general idea is that contracts developed for Ethereum can be easily transferred to Aurora, providing a seamless user experience and minimizing the need for modifications.\\n\\n### Connection with Near\\n\\nAurora is a second-layer blockchain built on Near. As a result, interaction with Aurora via a NEAR smart contract is possible, allowing, for example, monitoring transactions within Aurora on the NEAR blockchain, see [How to get NEAR transaction from the Aurora\u2019s one?](/blog/convert-aurora-transaction-into-near-s-one). Aurora and NEAR enable efficient cross-chain communication with each other, you can read more about this in the next blog posts: [Cross-Ecosystem Communication](/blog/cross-ecosystem-communication), [Building a game using Near, Aurora and BOS](/blog/building-a-game-using-near-aurora-and-bos).\\n\\n## Hardhat: create the project\\n\\nBefore we begin writing the contract, setting up the development environment is necessary. This article will utilize [Hardhat](https://hardhat.org/tutorial) to interact with the Aurora contract.\\n\\nAurora is designed to be highly compatible with Ethereum, which means that tools and frameworks created for Ethereum can also be used for working with Aurora. This compatibility allows developers to leverage their existing knowledge and tools when working with Aurora. So whether you choose Hardhat, Truffle, or another Ethereum-compatible tool, you can interact with Aurora similarly.\\n\\nLet\'s start by [installing Hardhat](https://hardhat.org/hardhat-runner/docs/guides/project-setup):\\n\\n```bash\\nyarn init -y\\nyarn add --dev hardhat\\n```\\n\\nTo create a Hardhat project, you can use the following command in the desired directory:\\n\\n```bash\\nnpx hardhat\\n```\\n\\nAfter running the `npx hardhat` command, an interactive process will start. Select `Create JavaScript project`. It will ask a few questions. Enter the values you want to set, or you can just use the default values by pressing `Enter`. Following these steps, you\'ll have a basic Hardhat project set up and ready to be customized for your specific needs.\\n\\nIn this article, we will not delve into the details of text editors for working with contracts. I use the Clion by myself, which supports plugins for Solidity. You can choose [Remix](https://remix.ethereum.org/) or even a simple editor like Notepad or Vim.\\n\\n## The Smart-Contract\\n\\nIt is time to start writing the contract. Delete the `contracts/Lock.sol` file and create a new file called `contracts/Incrementer.sol`. Write the following simple contract:\\n\\n```solidity\\npragma solidity 0.8;\\n\\ncontract Incrementer {\\n    uint counter;\\n\\n    constructor(uint startValue) {\\n        counter = startValue;\\n    }\\n\\n    function increment() public {\\n        counter = counter + 1;\\n    }\\n\\n    function getCounter() public view returns (uint) {\\n        return counter;\\n    }\\n}\\n```\\n\\nThe contract is named `Incrementer`. It has one state variable `counter` of type `uint`. When the contract is deployed, the constructor `constructor(uint startValue)` is called. It initializes the `counter` with the `startValue` provided during deployment. The `increment()` function is a public function that increments the value of the `counter` by 1. The `getCounter()` function is a `public view` function that returns the current value of the `counter` without modifying the state of the contract.\\n\\n## Creating an account on the Aurora testnet using MetaMask\\n\\nTo create the wallet in Aurora, you should install a Chromium-based web browser with the extensions support (e.g., Chrome, Brave, etc.) and then MetaMask ([*https://metamask.io/*](https://metamask.io/)), an Ethereum/Aurora (in general, EVM) wallet that runs as an extension.\\n\\nDuring the installation of MetaMask, you will be asked to create a new wallet secured by a \\"**seed phrase**\\" consisting of twelve words. Storing this phrase securely is essential, as any unauthorized access could allow anyone to recreate your wallet and steal all your funds!\\n\\nWe must add the Aurora network now that MetaMask is installed in Chrome. (It comes preconfigured with Ethereum, and other networks have to be added manually.) To add Aurora to MetaMask, visit the Aurora Start page:\\n\\n[*https://aurora.dev/start*](https://aurora.dev/start)\\n\\nThen click `Add Network` (Testnet) to add the Aurora network to MetaMask.\\n\\n## Obtaining AuroraEth on the testnet\\n\\nTo interact with the contract, you have to obtain some AuroraEth in the Aurora `testnet`. There are two ways to accomplish this:\\n\\n### The first method: directly obtain AuroraETH\\n\\nTo directly obtain AuroraETH in the `testnet`, you can follow these steps:\\n\\n* Go to the following link: [https://aurora.dev/faucet](https://aurora.dev/faucet)\\n* Select the Testnet.\\n* Connect to MetaMask. Click on \\"Connect to Aurora Testnet.\\" This will likely open your MetaMask wallet and prompt you to perform a few simple instructions.\\n* Check the wallet address to which you have connected. If you have multiple accounts in MetaMask and it is not connected to the desired account, click on the MetaMask icon in your browser and select the account you want to connect to.\\n* Click on \\"Request 0.001 ETH from the faucet.\\" This will initiate the process of receiving AuroraETH.\\n\\nCongratulations! You now have AuroraETH in your `testnet` wallet!\\n\\n![](https://www.datocms-assets.com/95026/1685341594-auroaeth.jpg)\\n\\nSadly, using this method can only obtain a limited amount of ETH. Luckily, to acquire larger amounts of AuroraETH, you can follow the method described below.\\n\\n### The second method: transfer from Ethereum\\n\\nThis method will take approximately 20 minutes. First, we will obtain ETH in Goerli testnet on Ethereum and then transfer it to Aurora using the Rainbow Bridge. Aurora and Ethereum use the same address space. Therefore, the address you created in MetaMask can be used in Aurora and Ethereum.\\n\\nObtain the Eth in Goerli testnet in Ethereum:\\n\\n* Go to the following link:[*https://goerli-faucet.pk910.de/*](https://goerli-faucet.pk910.de/). Of course, it is not the only option. But here, you can get the Eth without a daily limit.\\n* Enter the address where you want the Eth to be sent.\\n* Click \u201cStart Mining\u201d and wait\u2026\\n* Finish the mining and receive Eth.\\n\\nTransfer the Eth to Aurora using the Rainbow Bridge:\\n\\n* Visit[*https://testnet.rainbowbridge.app/*](https://testnet.rainbowbridge.app/)\\n* Click \u201cNew Transfer\u201d and select \u201cTransfer from Ethereum\u201d and \u201cTransfer to Aurora\u201d\\n* Connect to the desired address using MetaMask in both networks\\n* Wait for approximately 20 minutes for the transfer to complete\\n\\nYou get the AuroraEth! Now you are ready for contract deployment!\\n\\n## Contract deployment\\n\\nFirst, we should edit the `hardhat.config.js` and add information about aurora testnet.\\n\\nYour `hardhat.config.js` should look like this:\\n\\n```javascript\\nrequire(\\"@nomicfoundation/hardhat-toolbox\\");\\n\\nrequire(\'dotenv\').config();\\nconst AURORA_PRIVATE_KEY = process.env.AURORA_PRIVATE_KEY;\\n\\n/** @type import(\'hardhat/config\').HardhatUserConfig */\\nmodule.exports = {\\n  solidity: \\"0.8.18\\",\\n  networks: {\\n    testnet_aurora: {\\n      url: \'https://testnet.aurora.dev\',\\n      accounts: [`0x${AURORA_PRIVATE_KEY}`]\\n    }\\n  }\\n};\\n```\\n\\nWe use the `AURORA_PRIVATE_KEY` environment variable to designate the account through which we will interact with the network.\\n\\nYou should save your private key into an `.env` file by using the following command:\\n\\n```bash\\necho \\"AURORA_PRIVATE_KEY=[YOUR_AURORA_PRIVATE_KEY_HERE>\\" >](YOUR_AURORA_PRIVATE_KEY_HERE>\\" >) .env\\n```\\n\\nYou can get your private key from MetaMask:\\n\\n![](https://www.datocms-assets.com/95026/1685342401-metamaskgetprivatekey-1.jpg)\\n\\n> *WARNING: the space of the account for Aurora testnet, Aurora mainnet, Ethereum mainnet, and Ethereum testnets is the same. So, the Aurora testnet\'s private key can also be used for Aurora/Ethereum mainnet. Please ensure that the provided account is indeed a test account and that it does not hold any real funds in any live networks*\\n\\nLet\u2019s edit the `scripts/deploy.js` file:\\n\\n```javascript\\nconst hre = require(\\"hardhat\\");\\n\\nasync function main() {\\n  const Incrementer = await hre.ethers.getContractFactory(\\"Incrementer\\");\\n  const incrementer = await Incrementer.deploy(0);\\n  await incrementer.deployed();\\n\\n  console.log(\\n    `Deployed to ${increment.address}`\\n  );\\n}\\n\\nmain().catch((error) => {\\n  console.error(error);\\n  process.exitCode = 1;\\n});\\n```\\n\\nIn the script above we deploy the `Incrementer` contract and print the deployed contract\u2019s address.\\n\\nThe `hre` (Hardhat Runtime Environment) object from `hardhat` library provides utilities for interacting with the Ethereum/Aurora network and with the contract. In our case, we use `hre` to obtain the contract factory for the `Incrementer` contract.\\n\\n```javascript\\nconst Incrementer = await hre.ethers.getContractFactory(\\"Incrementer\\");\\nconst incrementer = await Incrementer.deploy(0);\\nawait incrementer.deployed();\\n```\\n\\nThese lines obtain the contract factory for the \\"Incrementer\\" contract using `hre.ethers.getContractFactory` and then deploy an instance of the contract with an initial counter value of 0 using `Incrementer.deploy(0)`. The `await incrementer.deployed()` ensures that the deployment transaction is confirmed and the contract instance is ready for use. In the function `getContractFactory`, you should specify the contract name. As long as this contract is in the `contracts` folder it will be detected.\\n\\n```javascript\\nconsole.log(`Deployed to ${increment.address}`);\\n```\\n\\nThis line prints the aurora address of the deployed contract.\\n\\nTo run this script you can execute the following command in your terminal:\\n\\n```bash\\nyarn hardhat run scripts/deploy.js --network testnet_aurora\\n```\\n\\nCongratulations, your smart contract is deployed! You can find more details about transactions with this contract in the [Aurora Testnet Explorer](https://explorer.testnet.aurora.dev/address/0x0a11fF48B2D9B4eE14658b0836168219E1676118):\\n\\n![](https://www.datocms-assets.com/95026/1686009148-screenshot-2023-06-06-at-00-52-03.png)\\n\\n## Interaction with the contract by using Hardhat\\n\\nNow, we want to learn how to interact with our contract. The easiest way is to create tasks within the `hardhat.config.json` file. Inside each `task` we will write the code of the interaction with the contract.\\n\\nThe structure of the `hardhat.config.json` should look like this:\\n\\n```javascript\\nrequire(\\"@nomicfoundation/hardhat-toolbox\\");\\n\\nrequire(\'dotenv\').config();\\nconst AURORA_PRIVATE_KEY = process.env.AURORA_PRIVATE_KEY;\\n\\ntask(\'task1\', \'Task 1 Description\')\\n    .addParam(\'arg1\', \'Description of the first arg\')\\n    .addParam(\'arg2\', \'Description of the second arg\')\\n    .setAction(async taskArgs => {\\n        // The first task code here\\n    });\\n\\ntask(\'task2\', \'Task 2 Description\')\\n    .addParam(\'arg1\', \'Description of the first arg\')\\n    .addParam(\'arg2\', \'Description of the second arg\')\\n    .setAction(async taskArgs => {\\n       // The second task code here\\n    });\\n\\n/** @type import(\'hardhat/config\').HardhatUserConfig */\\nmodule.exports = {\\n  solidity: \\"0.8.18\\",\\n  networks: {\\n    testnet_aurora: {\\n      url: \'https://testnet.aurora.dev\',\\n      accounts: [`0x${AURORA_PRIVATE_KEY}`]\\n    }\\n  }\\n};\\n```\\n\\nTo run the task, you can execute the following command in your terminal:\\n\\n```bash\\nyarn hardhat task1 ---arg1 [ARG1> --arg2 <ARG2](ARG1> --arg2 <ARG2) --network testnet_aurora\\n```\\n\\nLet\u2019s write a task that displays the current `counter` value:\\n\\n```javascript\\ntask(\'get-counter\', \'Returns the current counter for the provided Incrementer\')\\n    .addParam(\'incrementerAddress\', \'Aurora address of Incrementer contract\')\\n    .setAction(async taskArgs => {\\n        const incrementerAddress = hre.ethers.utils.getAddress(taskArgs.incrementerAddress);\\n\\n        const Incrementer = await hre.ethers.getContractFactory(\\"Incrementer\\");\\n        const incrementer = await Incrementer\\n          .attach(incrementerAddress);\\n\\n        console.log(\\n          \\"Current counter value in Incrementer: \\",\\n          (await incrementer.getCounter()).toString()\\n        );\\n    });task(\'get-counter\', \'Returns the current counter for the provided Incrementer\')\\n    .addParam(\'incrementerAddress\', \'Aurora address of Incrementer contract\')\\n    .setAction(async taskArgs => {\\n        const incrementerAddress = hre.ethers.utils.getAddress(taskArgs.incrementerAddress);\\n\\n        const Incrementer = await hre.ethers.getContractFactory(\\"Incrementer\\");\\n        const incrementer = await Incrementer\\n          .attach(incrementerAddress);\\n\\n        console.log(\\n          \\"Current counter value in Incrementer: \\",\\n          (await incrementer.getCounter()).toString()\\n        );\\n    });\\n```\\n\\nHere, we create the `get-counter` task. The `addParam` specifies the arguments that must be provided in the terminal. In this case, we will give the Aurora address of the `Incrementer` contract.\\n\\nIn the following lines, we get an incremental contract deployed to a specific address:\\n\\n```javascript\\nconst incrementerAddress = hre.ethers.utils.getAddress(taskArgs.incrementerAddress);\\n\\nconst Incrementer = await hre.ethers.getContractFactory(\\"Incrementer\\");\\nconst incrementer = await Incrementer.attach(incrementerAddress);\\n```\\n\\nAnd here we call the `getCounter` view method of the `Incrementer` contract and print the results:\\n\\n```javascript\\nconsole.log(\\n    \\"Current counter value in Incrementer: \\",\\n    (await incrementer.getCounter()).toString()\\n );\\n```\\n\\nTo run the `get-counter` task in `aurora testnet`, you should execute the following command in your terminal:\\n\\n```bash\\nexport INCREMENTER_ADDRESS=0x089d821d729B449DC890cF3F25365589Fc92e1b8\\nyarn hardhat get-counter --network testnet_aurora --incrementer-address $INCREMENTER_ADDRESS\\n```\\n\\nHere I provide the address where the `Incrementer` contract was deployed. You should provide the address which was shown in the terminal after the contract was deployed.\\n\\n![](https://www.datocms-assets.com/95026/1685344118-run-deploy.jpg)\\n\\nThe task for incrementing `counter` looks similar:\\n\\n```javascript\\ntask(\'increment-counter\', \'Increments the counter for the provided Incrementer\')\\n    .addParam(\'incrementerAddress\', \'Aurora address of Incrementer contract\')\\n    .setAction(async taskArgs => {\\n        const incrementerAddress = hre.ethers.utils.getAddress(taskArgs.incrementerAddress);\\n\\n        const Incrementer = await hre.ethers.getContractFactory(\\"Incrementer\\");\\n        const incrementer = await Incrementer\\n            .attach(incrementerAddress);\\n        \\n        await incrementer.increment();\\n    });\\n```\\n\\nThe command for running `increment-counter` task:\\n\\n```bash\\nyarn hardhat increment-counter --network testnet_aurora --incrementer-address $INCREMENTER_ADDRESS\\n```\\n\\nAfter the increment, you can run `get-counter` task and check that counter is increased:\\n\\n![](https://www.datocms-assets.com/95026/1685344456-screenshot-from-2023-05-22-17-52-10.png)\\n\\n## Testing\\n\\nIn the Hardhat template project also, the `test` folder was created. This folder contains the files with the tests for our smart contract. In this section, we will write a small test for the contract and learn how to run it.\\n\\nFirst, let\u2019s delete the `test/Lock.js` file and create the `test/Incrementer.js`. In our test, we will deploy the `Incrementer` contract, increment the counter, and check the counter value.\\n\\nThe final `test/Incrementer.js` file:\\n\\n```javascript\\nconst { expect } = require(\\"chai\\");\\nconst hre = require(\\"hardhat\\");\\n\\ndescribe(\\"Incrementer\\", function () {\\n  it(\\"After calling increment, the counter should increase by one\\", async function () {\\n    const Increment = await hre.ethers.getContractFactory(\\"Incrementer\\");\\n    const increment = await Increment.deploy( 0 );\\n    await increment.deployed();\\n\\n    expect(await increment.getCounter()).to.equal(0);\\n    await increment.increment();\\n    expect(await increment.getCounter()).to.equal(1);\\n  });\\n});\\n```\\n\\nThe `describe` function is used to define a test suite for our contract. Inside the test suite, the `it` function is used to define a specific test case. So, the structure of the tests generally looks like this:\\n\\n```javascript\\ndescribe(\\"Test suite\\", function () {\\n  it(\\"Test case 1\\", async function () {\\n     // The code for the first test here\\n  });\\n  \\n  it(\\"Test case 2\\", async function () {\\n     // The code for the second test here\\n  });\\n});\\n```\\n\\nFor writing [asserts](https://ethereum-blockchain-developer.com/2022-04-smart-wallet/05-exceptions-assert/) in tests we use `expect` function from the `chai`ibrary:\\n\\n```javascript\\nconst { expect } = require(\\"chai\\");\\n\\n//...\\n\\nexpect(await increment.getCounter()).to.equal(0);\\n```\\n\\nThe part with that deploys and interacts with the contracts is the same as in previous sections.\\n\\nTo run the tests in the local network, you can execute the following command in your terminal:\\n\\n```bash\\nyarn hardhat test\\n```\\n\\nTo run the tests in the Aurora Testnet, use the following command:\\n\\n```bash\\nyarn hardhat test --network testnet_aurora\\n```\\n\\n## Aurora and Near Explorers\\n\\nAfter we submit the transaction, we can find it on the Aurora Explorer website:[*https://explorer.testnet.aurora.dev/*](https://explorer.testnet.aurora.dev/)\\n\\nFor example, here you can find information about one of the transactions in our Increment contract [here.](https://explorer.testnet.aurora.dev/tx/0x17f890b73366dd251d00f2df5b187ee9107b9c344d9cd02ab4bb683125916b58)\\n\\nYou can search for transactions using the transaction hash, contract address, or signer account.\\n\\nFurthermore, for each transaction on Aurora, we can find the corresponding transaction on the Near blockchain. For example, there is a corresponding transaction in Near Explorer for the transaction mentioned above: [*here.*](https://explorer.testnet.near.org/transactions/5tLaTtR6KuUvVfmUkguKis3JMB8unK7q1cMP1tfRd52F)\\n\\nTo find the correspondent transaction in Near Explorer, you can use [this dApp](https://aurora-helpers.vercel.app/aurora_to_near). More detail in [this blog post](/blog/demystifying-transaction-failures).\\n\\n## Conclusion\\n\\nAurora, a blockchain practically identical to Ethereum, provides a similar experience in terms of how users interact. Smart contracts intended for Ethereum are generally compatible with Aurora, and many Ethereum-centric tools align well. Yet, it operates on the Near blockchain, allowing for interaction akin to a Near smart contract. Consequently, every transaction within this platform can be associated with corresponding activity within Near.\\n\\nIn this article, we have learned how to: (1) create accounts in Aurora, (2) get AuroraETH, and (3) deploy and interact with Aurora contracts using Hardhat.\\n\\n## References\\n\\n* Hardhat: [https://hardhat.org/tutorial](https://hardhat.org/tutorial)\\n* MetaMask: [https://metamask.io/](https://metamask.io/)\\n* Get AuroraETH: [https://aurora.dev/faucet](https://aurora.dev/faucet)\\n* Mining Goerli ETH: [https://goerli-faucet.pk910.de/](https://goerli-faucet.pk910.de/)\\n* Rainbow Bridge for testnet: [https://testnet.rainbowbridge.app/](https://testnet.rainbowbridge.app/)\\n* Explorer for Aurora testnet: [explorer.testnet.aurora.dev](https://explorer.testnet.aurora.dev/)\\n* Explorer for Near testnet: [https://explorer.testnet.near.org](https://explorer.testnet.near.org)\\n* dApp for get Near tx from Aurora tx: [https://aurora-helpers.vercel.app/aurora_to_near](https://aurora-helpers.vercel.app/aurora_to_near)\\n* Demystifying Transaction Failures: [/blog/demystifying-transaction-failures](/blog/demystifying-transaction-failures)"},{"id":"/spinning-up-your-own-aurora-node","metadata":{"permalink":"/blog/spinning-up-your-own-aurora-node","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/spinning-up-your-own-aurora-node.md","source":"@site/blog/spinning-up-your-own-aurora-node.md","title":"Spinning up your own Aurora node","description":"Learn the details of starting your own Aurora node using the Standalone RPC repo","date":"2023-05-26T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":3.8666666666666667,"hasTruncateMarker":true,"authors":[{"name":"Oleksii Krasynskyi","title":"Head of Infrastructure","imageURL":"https://www.datocms-assets.com/95026/1726603153-screenshot-2024-09-17-at-20-59-04.png","key":"oleksii_krasynskyi","page":null}],"frontMatter":{"title":"Spinning up your own Aurora node","description":"Learn the details of starting your own Aurora node using the Standalone RPC repo","date":"2023-05-26","authors":["oleksii_krasynskyi"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1685097397-node.png"},"unlisted":false,"prevItem":{"title":"Getting started with Aurora","permalink":"/blog/getting-started-with-aurora"},"nextItem":{"title":"Aurora Chains: Code Overview","permalink":"/blog/aurora-chains-code-overview"}},"content":"At Aurora Labs, we encourage everyone to use [mainnet.aurora.dev](https://mainnet.aurora.dev) or [testnet.aurora.dev](https://testnet.aurora.dev) to build and deploy their apps. Those endpoints are scalable and reliable. When registering at [https://aurora.plus](https://aurora.plus/) you can even get a bunch of free transactions (soon through the Aurora Pass wallet).\\n\\nThat said, many dapps that are deployed on Aurora rely on running their own JSON-RPC Etherium-compatible server. Here we call this server \u2013 a relayer. You\'ve probably already read the details about our new version of it in [How the Aurora Relayer 2.0 works?](/blog/aurora-relayer-2-0)\\n\\n\x3c!-- truncate --\x3e\\n\\n### Who needs it?\\n\\nRunning your own relayer has benefits since you get full control over both hardware and software. Additionally, you will be the one paying for all the transactions in NEAR, thus you are free to charge your users with whatever gas price you desire. Or, maybe, if for some reason you feel like a good samaritan, do not charge for transactions at all.\\n\\nThere is another category of users who might consider running their own setup, and those are developers or newcomers who want to understand a bit more, or even contribute. So, what does it take to run your own relayer? First, we need to understand what is the relayer, and to do that we will take a look at what it consists of.\\n\\n### Relayer Components\\n\\nThe Relayer consists of three components:\\n\\n* ***a JSON-RPC server*** compatible with Ethereum\'s [Web3 API](https://eth.wiki/json-rpc/API) for [Aurora Engine](https://github.com/aurora-is-near/aurora-engine) instances deployed on the NEAR Protocol.\\n* ***Aurora Refiner*** which allows users to download all NEAR Blocks and produce Ethereum-compatible blocks, transactions, and logs.\\n* ***Indexer*** which continuously reads JSON files generated by [Aurora Refiner](https://github.com/aurora-is-near/borealis-engine-lib) and populates a database, that is used by the JSON-RPC server to serve data.\\n\\n![](https://www.datocms-assets.com/95026/1680267260-relayer-20.png)\\n\\nThis means that in order to deploy the relayer, we need to deploy these three components. JSON-RPC server and Indexer is a single project written in Go (you can check all the source code of the Relayer [here](https://github.com/aurora-is-near/relayer2-public)). While [Aurora Refiner](https://github.com/aurora-is-near/borealis-engine-lib) is a separate one written in Rust.\\n\\nAlthough there is documentation on how to run and deploy them manually, for the ease of use we have developed an [installation script](https://github.com/aurora-is-near/standalone-rpc) that greatly simplifies the whole process. Now let\'s take a closer look at it.\\n\\n### Standalone RPC\\n\\n\\\\\\nThis installation script is called [standalone-rpc](https://github.com/aurora-is-near/standalone-rpc). It has multiple steps and in this blog post, I would like to explain what it actually does and what options on running relayer do you have.\\n\\nFirst, we can split the whole process into a set of steps:\\n\\n1. Generate NEAR account and signing key.\\n2. Generating configuration files for relayer, refiner, and nginx.\\n3. Download the latest database snapshot for relayer (optional, but recommended).\\n4. Download the latest NEAR Node Data Snapshot and configuration, that is required to correctly run the refiner in `nearcore` mode.\\n5. Set up AWS credentials if instead of `nearcore` mode you decided to run the refiner in `nearlake` mode.\\n\\nDownload and start four docker containers: `relayer`, `refiner`, `watchtower`, and `nginx`.\\n\\nIf some or all of those steps are unclear \u2013 don\'t worry, we will dig into each of those steps in a moment.\\n\\n### Generate NEAR account and signing key\\n\\nWhen running your own relayer, if you intend to send a transaction via `eth_sendRawTransaction` this transaction will eventually be executed on NEAR. This means that some NEAR will have to be charged from your account for the execution. For the relayer to charge your account, this account needs to be generated first, which is exactly what happens during this step.\\n\\nKeep in mind that you have to send some NEAR to that account, so it can be properly charged for transactions. You can also use your own NEAR account and signing key and put them into **srpc2/config/relayer/relayer.json** instead of a pre-generated one. If you already have a NEAR account, the simplest way to generate a signing key would be to use [near-cli](https://docs.near.org/tools/near-cli).\\n\\n### Generating configuration files for relayer, refiner, and nginx\\n\\nBefore diving into the configuration, let\'s discuss what are the different options to run the Relayer. It\'s pretty straightforward.\\n\\n1. You can run `relayer` in mainnet or testnet mode.\\n2. You can use `nearlake` or `nearcore` as a source of data for the `refiner`.\\n\\nChoosing to run the mainnet or testnet is quite self-explanatory. But the second option is not.\\n\\n### Nearcore Mode\\n\\nIn this mode `refiner` is running a `nearcore` under the hood, that is constantly synced with the network. It will constantly extract NEAR blocks from the database, then refine them into Aurora blocks and feed them to the Indexer. If you would like to reindex the whole Aurora network starting from genesis, without using any data snapshots \u2013 this is the way to do that. Keep in mind that it will take many weeks, or even months to reindex the whole network, and it will use up to 6TB of storage.\\n\\nYou have the option to download [near data snapshot](https://near-nodes.io/intro/node-data-snapshots) to fasten the process, though it will still take several weeks to refine all of the NEAR blocks into Aurora blocks.\\n\\nThe recommended approach, that is being used in this [installation script,](https://github.com/aurora-is-near/standalone-rpc) is to download the Relayer Database snapshot and NEAR RPC data snapshot. NEAR RPC data snapshot has data for the last two weeks and is made every 12 hours. This is more than enough to quickly sync with the network and catch up with the HEAD; storage wise it is somewhere around ~800 GB.\\n\\n### Nearlake Mode\\n\\nThe `refiner` can also be run in `nearlake` mode. This mode does not require you to download any NEAR data snapshots, but instead relies on [Near Lake Framework.](https://docs.near.org/concepts/advanced/near-lake-framework) Lake Framework relies on the data being dumped to AWS S3, the Refiner can download it and use it as a source.\\n\\nThis approach will save most of the storage for you and is the fastest way to get started. It does require you to set up AWS credentials which is a requirement for using [Near Lake Framework.](https://docs.near.org/concepts/advanced/near-lake-framework) There is a quick [guide](https://www.youtube.com/watch?v=GsF7I93K-EQ\\\\&t=277s) on how to do that and it shouldn\'t take a lot of time.\\n\\n### Starting relayer\\n\\nThe final step of the whole process is to download docker containers and start them. It will be done for you. The containers that will be running are:\\n\\n1. `nearaurora/srpc2-relayer` \u2013 JSON RPC server and indexer.\\n2. `nearaurora/srpc2-refiner` \u2013 [Aurora Refiner](https://github.com/aurora-is-near/borealis-engine-lib) .\\n3. `nearaurora/reverseproxy` \u2013 Nginx (used to isolate backend server from the outer world, redirects requests to the relayer container).\\n4. `containerrr/watchtower` \u2013 service that will check on any updates, and will update images accordingly.\\n\\n### Conclusions\\n\\nWe have presented a comprehensive overview of the key components of the Relayer and the specific user needs it fulfills. Furthermore, we have thoroughly explored the process of setting up your Aurora RPC Node, focusing on the configuration of the standalone-rpc script, and emphasized the significance of data snapshots in expediting this setup.\\\\\\n\\\\\\nThanks for reading! Stay tuned with the updates!"},{"id":"/aurora-chains-code-overview","metadata":{"permalink":"/blog/aurora-chains-code-overview","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/aurora-chains-code-overview.md","source":"@site/blog/aurora-chains-code-overview.md","title":"Aurora Chains: Code Overview","description":"Discover the source code for Aurora Chains: how fixed gas cost and access control are achieved","date":"2023-05-19T00:00:00.000Z","tags":[{"inline":false,"label":"Core Tech","permalink":"/blog/tags/core_tech","description":"Posts about core technologies on Aurora"}],"readingTime":7.446666666666666,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"Aurora Chains: Code Overview","description":"Discover the source code for Aurora Chains: how fixed gas cost and access control are achieved","date":"2023-05-19","authors":["slava"],"tags":["core_tech"],"image":"https://www.datocms-assets.com/95026/1701394771-ac4.png"},"unlisted":false,"prevItem":{"title":"Spinning up your own Aurora node","permalink":"/blog/spinning-up-your-own-aurora-node"},"nextItem":{"title":"Building a game using Near, Aurora and BOS","permalink":"/blog/building-a-game-using-near-aurora-and-bos"}},"content":"The main goal of this article is to understand the Aurora Chain code. In a future post, we will discuss how it embellishes the Aurora Engine and how the advantages of an Aurora Chain correspond to different parts of code and Aurora architecture.\\n\\n\x3c!-- truncate --\x3e\\n\\nFor now, just recall that Aurora Chain is just the Aurora Engine with a couple of new features on top of it: see `What are Aurora Chains?` section in [Aurora Chains: Walkthrough](/blog/aurora-chains-demo). Let\'s take a closer look at the [Aurora Engine repo](https://github.com/aurora-is-near/aurora-engine) to find a code for Aurora Chain. You will see sometimes Aurora Chains called Silos. The meaning is the same. It is just a more user-friendly renaming of the technology. The Rust module for Aurora Chain is actually called `silo`.\\\\\\n\\\\\\nThe source code of Aurora Chain is inside the pull request (PR) [#746: feat: add possibility to use fixed gas cost (silo).](https://github.com/aurora-is-near/aurora-engine/pull/746) The first question that comes to mind is why it is called so? The clue is in the description right away and leads us to the first feature:\\n\\n> *The PR adds the possibility to set fixed gas cost per EVM transaction. The feature could be switched on by calling `set_fixed_gas_cost`.*\\n\\nThe second feature is access control, which is realized with the four types of whitelists to regulate the rights to deploy code and submit transactions.\\n\\nNow, let\'s look closer at the PR itself and what Aurora Chain actually is.\\n\\n### Where is it?\\n\\nFirst, we take a look at the folders in which developers have changed files:\\n\\n![](https://www.datocms-assets.com/95026/1684180353-screenshot-2023-05-15-at-20-52-18.png)\\n\\n`engine-standalone-storage` folder shouldn\'t worry you: it is kinda an IO for the Engine, definitely not the main part of it. As for the `engine-tests` and `engine-types,` those are not critical for understanding, but they can give you some insights about the details because \u2013 as we all know \u2013 tests and types are foundational for a nicely working code. So, the only folder left is `engine` and that is the right guess to look into it:\\n\\n![](https://www.datocms-assets.com/95026/1684180726-screenshot-2023-05-15-at-20-58-36.png)\\n\\nThis folder is the heart of the repo and the Aurora itself. Inside we will see some files of the Engine changed, among which `engine.rs` , and `lib.rs` are the key ones. Also, notice the `src/silo` folder. Which is the thing we were looking for!\\n\\n### Aurora Chain Module Imports\\n\\nAurora Engine is written in Rust, the native language for the NEAR contracts. In our case, the main entry point to the Aurora Chain module is the `mod.rs` file, which is the core part of the module. In its turn, it also relies on two submodules `parameters.rs` and `whitelist.rs`:\\n\\n```rust\\nuse parameters::{WhitelistArgs, WhitelistKindArgs, WhitelistStatusArgs};\\nuse whitelist::Whitelist;\\npub use whitelist::WhitelistKind;\\n\\npub mod parameters;\\nmod whitelist;\\n```\\n\\nLet\'s start with reviewing the `parameters.rs` file.\\n\\n### Parameters.rs\\n\\nThis file contains all of the important function arguments\' structs and enums for Aurora Chain. The reason to have those is to decouple the arguments from the implementation: it will be easier to change them in one place later and leave function implementations as is. The file starts importing some useful types, [traits](https://en.wikipedia.org/wiki/Ad_hoc_polymorphism) , and the `WhitelistKind` enum:\\n\\n```rust\\nuse aurora_engine_types::account_id::AccountId; // corresponds to NEAR account\\nuse aurora_engine_types::types::{Address, Wei}; // Aurora Address, and Wei for ETH\\nuse borsh::{BorshDeserialize, BorshSerialize}; // borsh traits\\n\\nuse crate::silo::whitelist::WhitelistKind; // type of the whitelist\\n```\\n\\n#### Whitelist Kinds\\n\\n`WhitelistKind` can be one of the four types, you can find the definition in `whitelist.rs`:\\n\\n```rust\\npub enum WhitelistKind {\\n    /// The whitelist of this type is for storing NEAR accounts. \\n    /// Accounts stored in this whitelist have an admin role. \\n    /// The admin role allows to add new admins and add new entities\\n    /// (`AccountId` and `Address`) to whitelists.\\n    /// This role allows to deploy of EVM code.\\n    Admin = 0x0,\\n    /// The whitelist of this type is for storing EVM addresses. \\n    /// Addresses included in this whitelist can deploy EVM code.\\n    EvmAdmin = 0x1,\\n    /// The whitelist of this type is for storing NEAR accounts.\\n    /// Accounts included in this whitelist can submit transactions.\\n    Account = 0x2,\\n    /// The whitelist of this type is for storing EVM addresses. \\n    /// Addresses included in this whitelist can submit transactions.\\n    Address = 0x3,\\n}\\n```\\n\\nWe can whitelist users by a NEAR account or Aurora address. EVM address is their own one, but with the NEAR account situation is trickier because it is the one from which the engine transactions go to the NEAR node (i.e., it is a relayer\'s NEAR account). This account will pay for the NEAR gas on behalf of the user.\\\\\\n\\\\\\nTo understand this part better, take a look at this picture which illustrates how Aurora works in general:\\n\\n![](https://www.datocms-assets.com/95026/1682422805-screenshot-2023-04-25-at-12-39-54.png)\\n\\n\\\\\\nThe RPC in the picture above is our Relayer instance (it includes [RPC, relayer, and refiner](https://github.com/aurora-is-near/standalone-rpc), but that is a matter for another article). At the triangle base, we have NEAR Node and Engine Contract. So it is the address of the top vertex we\'re filtering with the account\'s whitelists.\\\\\\n\\\\\\nTo continue with the whitelist kinds, we have another dimension to whitelist users: either to allow the deployment of new contracts or allow them to transact. We can make this really clear by using this table (with the exception, that an Admin can also edit whitelists):\\n\\n![](https://www.datocms-assets.com/95026/1684454005-screenshot-2023-05-19-at-00-53-10.png)\\n\\n#### Whitelist Args\\n\\nThe main part of the `parameters.rs` is related to the whitelists args of different types:\\n\\n```rust\\npub enum WhitelistArgs {\\n    WhitelistAddressArgs(WhitelistAddressArgs),\\n    WhitelistAccountArgs(WhitelistAccountArgs),\\n} // Enum to separate Address vs Account whitelist args.\\n\\npub struct WhitelistAddressArgs {\\n    pub kind: WhitelistKind,\\n    pub address: Address,\\n} // This one contains kind (0x1, 0x3) + Aurora address.\\n\\npub struct WhitelistAccountArgs {\\n    pub kind: WhitelistKind,\\n    pub account_id: AccountId,\\n} // Kind (0x0, 0x2) + NEAR account\\n\\npub struct WhitelistStatusArgs {\\n    pub kind: WhitelistKind,\\n    pub active: bool,\\n} // Status to track if the whitelist is active or not.\\n  // If not - it won\'t be used by a Aurora Chain at all.\\n\\npub struct WhitelistKindArgs {\\n    pub kind: WhitelistKind,\\n} // just another parametrization to track the kind.\\n```\\n\\nThere is also one small test at the end of the file with the whitelist args [borsh serialization](https://github.com/near/borsh-rs). I will skip [the code](https://github.com/aurora-is-near/aurora-engine/blob/0de3198c2d602a8f23d5ea9797a6ab4c921e6f52/engine/src/silo/parameters.rs#L60) for brevity.\\n\\n### Whitelists\\n\\nLet\'s move on to the second file: `whitelists.rs`. We have already seen a part of it above \u2013 `WhitelistKind` enum.\\n\\n#### Imports\\n\\nNow, let\'s take a look at what imports are inside the file:\\n\\n```rust\\nuse aurora_engine_sdk::io::{StorageIntermediate, IO};\\nuse aurora_engine_types::storage::{bytes_to_key, KeyPrefix};\\nuse aurora_engine_types::AsBytes;\\nuse borsh::{BorshDeserialize, BorshSerialize};\\n\\nuse crate::prelude::Vec;\\n//seen those before, right?\\nuse crate::silo::parameters::{WhitelistKindArgs, WhitelistStatusArgs};\\n```\\n\\nAurora Engine SDK is a [FFI way](https://en.wikipedia.org/wiki/Foreign_function_interface) to write a NEAR contract in Rust, which deserves a separate article, so we won\'t concentrate on it. We\'re importing it to communicate with the [NEAR storage](https://docs.near.org/concepts/storage/data-storage), which is just a key-value database. To generate a key for the data to store, we use `bytes_to_key` function and `KeyPrefix`. We also have `AsBytes` trait to help us interpret things as an array of bytes.\\n\\n#### Whitelist Type\\n\\nLet\'s overview the Whitelist type now:\\n\\n```rust\\nconst STATUS: &[u8] = b\\"LIST_STATUS\\";\\n\\nimpl<I> Whitelist<I> where I: IO + Copy {\\n  /// Constructor.\\n  pub const fn init(io: &I, kind: WhitelistKind) -> Self {...}\\n\\n  /// Create keys for storage.\\n  fn key(&self, value: &[u8]) -> Vec<u8> {...}\\n\\n  /// Status.\\n  pub fn enable(&mut self) {...} /// set STATUS key in storage to true.\\n  pub fn disable(&mut self) {...} /// set STATUS key in storage to false.\\n  pub fn is_enabled(&self) -> bool {...} /// get STATUS key from storage.\\n  \\n  /// Entries.\\n  pub fn add<A: AsBytes + ?Sized>(&mut self, element: &A) {...}\\n  pub fn remove<A: AsBytes + ?Sized>(&mut self, element: &A) {...}\\n  pub fn is_exist<A: AsBytes + ?Sized>(&self, element: &A) -> bool {...}\\n}\\n```\\n\\nI have also omitted the bodies for brevity, overall they\'re just working with storage and get/set the key-value pairs. As you can see, we can separate methods in the Whitelist into two main groups: `Status` and `Entries`. The first group is used to enable or disable the whitelist and check its status. The status \\"field\\" tells us if the whitelist will be used by a Aurora Chain or not. The special prefix, defined by the `STATUS` variable, is used to produce a key to store this field.\\n\\n`The Entries` group is used to add, remove or check the inclusion of an element into the whitelist. Which can be anything, defined by a type `A` here, implementing `AsBytes` trait.\\n\\n#### Storage and Key functions\\n\\nWhitelist is also parametrized by a type `I:IO` to allow different ways of IO interactions. Notice that it is a special kind of trait `IO` and not `std::io` . `IO` trait is part of Aurora Engine SDK, created to write NEAR contracts with FFI, so it works with key-value storages (like NEAR storage).\\n\\nThat is the reason why the `key` function is the core of the Whitelist structure: because it heavily relies on storage. Let\'s take a closer look at it:\\n\\n```rust\\nfn key(&self, value: &[u8]) -> Vec<u8> {\\n    let mut bytes = Vec::with_capacity(1 + value.len());\\n\\n    bytes.push(u8::from(self.kind));\\n    bytes.extend_from_slice(value);\\n    bytes_to_key(KeyPrefix::Whitelist, &bytes)\\n}\\n\\n/// Included this one to demonstrate the usage of `key` function.\\npub fn add<A: AsBytes + ?Sized>(&mut self, element: &A) {\\n    let key = self.key(element.as_bytes());\\n    self.io.write_storage(&key, &[]);\\n}\\n```\\n\\nAs you can see, it is based upon the `bytes_to_key` function, and joins the kind prefix byte to the value (in bytes) and adds a special `KeyPrefix` for Whitelist used to differentiate different parts of storage in Aurora Engine.\\n\\nThe last part of the file includes two functions to operate with the whitelist status, but using `WhitelistStatusArgs`, which currently includes `active : bool` field and `WhitelistKind`:\\n\\n```rust\\n/// Set status of the whitelist.\\npub fn set_whitelist_status<I: IO + Copy>(io: &I, args: &WhitelistStatusArgs) {\\n    let mut list = Whitelist::init(io, args.kind);\\n    if args.active {\\n        list.enable();\\n    } else {\\n        list.disable();\\n    }\\n}\\n\\n/// Get status of the whitelist.\\npub fn get_whitelist_status<I: IO + Copy>(io: &I, args: &WhitelistKindArgs) -> WhitelistStatusArgs {\\n    WhitelistStatusArgs {\\n        kind: args.kind,\\n        active: Whitelist::init(io, args.kind).is_enabled(),\\n    }\\n}\\n```\\n\\nThese are helpful to operate on any kind of the Whitelist without having an instance of it.\\n\\n### Aurora Chain Module\\n\\nWe can divide the public functions of this module into two groups: `Whitelists` and `Fixed Gas`. The first is responsible for editing whitelists and checking the user rights. And the second one is for storing the fixed gas price for transactions inside the Aurora Chain.\\n\\n#### Whitelists\\n\\nLet\'s start with the Whitelists. This group can also be divided into 3 subgroups: Entries, Status, and Rights. The `Entries` subgroup is about adding/removing entries from the whitelists:\\n\\n```rust\\npub fn add_entry_to_whitelist<I: IO + Copy>(io: &I, args: &WhitelistArgs) {...}\\npub fn add_entry_to_whitelist_batch<I: IO + Copy, A: IntoIterator<Item = WhitelistArgs>> {...}\\npub fn remove_entry_from_whitelist<I: IO + Copy>(io: &I, args: &WhitelistArgs) {...}\\n```\\n\\nThe second one, `Status`, is to get/set the status of the whitelists:\\n\\n```rust\\npub fn set_whitelist_status<I: IO + Copy>(io: &I, args: &WhitelistStatusArgs) {...}\\npub fn get_whitelist_status<I: IO + Copy>(io: &I, args: &WhitelistKindArgs) -> WhitelistStatusArgs {...}\\n```\\n\\nAnd the last one, `Rights`, is the most interesting one:\\n\\n```rust\\n/// Check if the calling user is in Admin whitelist and owner of the Engine contract.\\npub fn assert_admin<I: IO + Env + Copy>(io: &I) -> Result<(), EngineErrorKind> {...}\\n\\n/// Check if user has rights to deploy EVM code (EVMAdmin and/or Admin whitelists).\\npub fn is_allow_deploy<I: IO + Copy>(io: &I, account: &AccountId, address: &Address) -> bool {...}\\n\\n/// Check if user has rights to submit transaction (Address and/or Account whitelists entry).\\npub fn is_allow_submit<I: IO + Copy>(io: &I, account: &AccountId, address: &Address) -> bool {...}\\n```\\n\\nWhy? Because it is the first place in the code where we see that NEAR Accounts whitelists act in pairs with the EVM addresses ones. If we take a look into `is_allow_deploy` function:\\n\\n```rust\\npub fn is_allow_deploy<I: IO + Copy>(io: &I, account: &AccountId, address: &Address) -> bool {\\n    let admin_list = Whitelist::init(io, WhitelistKind::Admin);\\n    let evm_admin_list = Whitelist::init(io, WhitelistKind::EvmAdmin);\\n\\n    (!admin_list.is_enabled() || admin_list.is_exist(account))\\n        && (!evm_admin_list.is_enabled() || evm_admin_list.is_exist(address))\\n}\\n```\\n\\nIt has checks for both accounts and addresses and the reason for that is that EVM address signs the EVM transaction and afterwards the relayer must wrap it into the NEAR transaction and sign it with its NEAR account \u2013 as we have discussed above \u2013 while talking about the `WhitelistKind`.\\n\\n#### Fixed Gas\\n\\nThis group is quite simple, and just stores the `fixed_gas_cost` field or retrieves it from storage:\\n\\n```rust\\n/// storage utilities.\\nconst GAS_COST_KEY: &[u8] = b\\"GAS_COST_KEY\\";\\nfn fixed_gas_cost_key() -> Vec<u8> {...}\\n\\n/// get/set fixed gas cost.\\npub fn get_fixed_gas_cost<I: IO>(io: &I) -> Option<Wei> {}\\npub fn set_fixed_gas_cost<I: IO>(io: &mut I, cost: Option<Wei>) {}\\n```\\n\\nThe price is used inside the Aurora Engine in the `submit` function [here](https://github.com/aurora-is-near/aurora-engine/blob/0de3198c2d602a8f23d5ea9797a6ab4c921e6f52/engine/src/engine.rs#L863) , and the `charge_gas` function [here](https://github.com/aurora-is-near/aurora-engine/blob/0de3198c2d602a8f23d5ea9797a6ab4c921e6f52/engine/src/engine.rs#L438), while submitting the EVM transaction to the engine. We will discuss this part of the code with more detail in our next post about Aurora Chains.\\\\\\n\\\\\\nThe `fixed_gas_cost` could be set by a Aurora Chain admin interacting directly with an Engine contact on the NEAR network and calling `set_fixed_gas_cost`method [here](https://github.com/aurora-is-near/aurora-engine/blob/0de3198c2d602a8f23d5ea9797a6ab4c921e6f52/engine/src/lib.rs#L1080).\\n\\n### Conclusions\\n\\nWe\'ve overviewed one pull request introducing Aurora Chains within the Aurora Engine repo. Now we know that inside the Aurora Chain, we have access control and fixed gas cost parts hidden. We will discuss the outer connections of the Aurora Chains in articles to come. We will also cover how the methods of the Aurora Chain impact the mechanics of the EVM itself.\\\\\\n\\\\\\nThanks for reading!"},{"id":"/building-a-game-using-near-aurora-and-bos","metadata":{"permalink":"/blog/building-a-game-using-near-aurora-and-bos","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/building-a-game-using-near-aurora-and-bos.md","source":"@site/blog/building-a-game-using-near-aurora-and-bos.md","title":"Building a game using Near, Aurora and BOS","description":"Find out how to build a fully decentralized UI and back-end of an on-chain application using NEAR and Aurora","date":"2023-05-05T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":6.2,"hasTruncateMarker":true,"authors":[{"name":"Michael Birch","title":"Senior Research Engineer","imageURL":"https://www.datocms-assets.com/95026/1683043123-t025c6kc9px-u025f7t5npl-c56792be0091-512.jpeg","key":"michael","page":null}],"frontMatter":{"title":"Building a game using Near, Aurora and BOS","description":"Find out how to build a fully decentralized UI and back-end of an on-chain application using NEAR and Aurora","date":"2023-05-05","authors":["michael"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1683223806-bos-article.png"},"unlisted":false,"prevItem":{"title":"Aurora Chains: Code Overview","permalink":"/blog/aurora-chains-code-overview"},"nextItem":{"title":"Aurora Chains: Walkthrough","permalink":"/blog/aurora-chains-demo"}},"content":"In this blog post, we explore building a simple Tic Tac Toe game using the Near ecosystem\u2019s tech stack. This includes using Aurora for a seamless onboarding experience (free transactions), Near for complex smart contract logic, and BOS for the front end. The final result is a free-to-use, fully decentralized application that anyone can pick up and play.\\n\\n\x3c!-- truncate --\x3e\\n\\nTic Tac Toe was chosen as an example because it is easy to understand and small enough for the code to be used in a blog post. But this same architecture and tech stack could also be applied to non-trivial projects! For example, the smart contract could be running a chess engine instead of a Tic Tac Toe engine. Or it could have nothing to do with games, and the smart contract runs a zero-knowledge proof verifier for some application. The possibilities are endless!\\n\\nThis post shows some code snippets to be self-contained pieces; however, not all the code is shown. The complete code for the smart contracts used in this example is [*available on GitHub*](https://github.com/aurora-is-near/aurora-contracts-sdk/tree/main/examples/tic-tac-toe). The complete front-end code is [*available on BOS*](https://bos.gg/#/mob.near/widget/WidgetSource?src=nearcon.birchmd.near/widget/Aurora-Tic-Tac-Toe).\\n\\n### Architecture\\n\\nThis project consists of three components:\\n\\n1. A stateless smart contract written in Rust and deployed to Near, which takes a Tic Tac Toe board state and input and returns an updated state as output.\\n2. A Solidity contract deployed to Aurora, which users interact with to start Tic Tac Toe games and make their moves. This contract uses the Near one to make a computer opponent, and it persists the users\u2019 games in storage.\\n3. A front-end written in JavaScript that is powered by [*BOS*](https://near.org/blog/near-announces-the-blockchain-operating-system/). This is what the user interacts with directly, and it sends the transactions to the Solidity smart contract on Aurora.\\n\\nAll of these components run on top of a blockchain platform; I did not need to acquire any hardware resources to deploy this dApp, and yet anyone can interact with it.\\n\\nOne way to think of this architecture is as being analogous to a Web2 app which uses both JavaScript (JS) and WebAssembly (Wasm). The JS code handles the state (cookies, DOM, etc.), while the Wasm handles the heavier computation that would be inefficient to do in JS directly. In our case, the Solidity code handles the state while the Rust code on Near handles the heavier computation (and it ultimately runs as Wasm, too, making the analogy even stronger).\\n\\nIn the next sections, we will discuss each of these components in some detail.\\n\\n### Near contract\\n\\nAs described above, the Near contract is stateless and handles the more complex logic of our application, in this case, the Tic Tac Toe computer player. It is very clean and easy to write such code in Rust. We have a module where a few basic types are defined:\\n\\n```rust\\n#[repr(i8)]\\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\\npub enum CellState {\\n    Empty = 0,\\n    X = 1,\\n    O = -1,\\n}\\n\\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]\\npub struct GameState {\\n    /// Row-major representation of the board\\n    pub board: [CellState; BOARD_SIZE],\\n}\\n```\\n\\nAnd another module which uses those types to analyze a Tic Tac Toe position, then make a good move:\\n\\n```rust\\npub enum MoveResult {\\n    Move { updated_state: GameState },\\n    GameOver { winner: CellState },\\n}\\n\\npub fn get_move(state: GameState) -> MoveResult {\\n    // ... elided for brevity\\n}\\n\\nenum Evaluation {\\n    Sums {\\n        sums: [i8; ROW_SIZE + ROW_SIZE + 2],\\n        total: i8,\\n    },\\n    GameOver {\\n        winner: CellState,\\n    },\\n}\\n\\nfn evaluate_position(state: GameState) -> Evaluation {\\n    // ... elided for brevity\\n}\\n```\\n\\nFinally, there is contract entry-point written using Near SDK:\\n\\n```rust\\n#[near_bindgen]\\n#[derive(BorshDeserialize, BorshSerialize, Default)]\\npub struct TicTacToe;\\n\\n#[near_bindgen]\\nimpl TicTacToe {\\n    pub fn get_move(&self, state: String) -> GetMoveResponse {\\n        let parsed_state: types::GameState = state\\n            .parse()\\n            .unwrap_or_else(|_| env::panic_str(\\"Invalid state string\\"));\\n        match logic::get_move(parsed_state) {\\n            logic::MoveResult::Move { updated_state } => {\\n                let serialized_state = updated_state.to_string();\\n                let winner = match logic::get_move(updated_state) {\\n                    logic::MoveResult::GameOver { winner } => Some(format!(\\"{winner:?}\\")),\\n                    logic::MoveResult::Move { .. } => None,\\n                };\\n                GetMoveResponse {\\n                    updated_state: serialized_state,\\n                    winner,\\n                }\\n            }\\n            logic::MoveResult::GameOver { winner } => GetMoveResponse {\\n                updated_state: state,\\n                winner: Some(format!(\\"{winner:?}\\")),\\n            },\\n        }\\n    }\\n}\\n\\n#[derive(serde::Serialize, serde::Deserialize)]\\npub struct GetMoveResponse {\\n    updated_state: String,\\n    #[serde(skip_serializing_if = \\"Option::is_none\\")]\\n    winner: Option<String>,\\n}\\n```\\n\\nThe nice thing about this being a stateless contract is that you can interact with it entirely using view calls (essentially using Near as a serverless computation platform).\\n\\nI wrote a [*front-end powered by BOS*](https://alpha.near.org/birchmd.near/widget/tic-tac-toe) to directly interact with this Near contract to illustrate this point. Since no transactions are actually sent to the chain, it\u2019s much more responsive than the final product we\u2019re building toward in this post. But stateless computing has limited applications, so committing transactions on-chain to access the state is still important in real-world use cases. For this, we are making use of Aurora.\\n\\n### Aurora contract\\n\\nThe Solidity contract deployed on Aurora handles the state management and is the contract users make transactions to. This contract uses Aurora\u2019s XCC to call the Near contract directly when it needs to get the computer opponent\u2019s next move. Here is essentially what the code looks like (some details omitted for brevity):\\n\\n```solidity\\ncontract TicTacToe is AccessControl {\\n    using AuroraSdk for NEAR;\\n    using AuroraSdk for PromiseCreateArgs;\\n    using AuroraSdk for PromiseWithCallback;\\n    using AuroraSdk for PromiseResult;\\n    using Codec for bytes;\\n\\n    constructor(string memory _ticTacToeAccountId, IERC20 _wNEAR) {\\n        ticTacToeAccountId = _ticTacToeAccountId;\\n        near = AuroraSdk.initNear(_wNEAR);\\n        wNEAR = _wNEAR;\\n        _grantRole(OWNER_ROLE, msg.sender);\\n        _grantRole(CALLBACK_ROLE, AuroraSdk.nearRepresentitiveImplicitAddress(address(this)));\\n\\n    }\\n\\n    // Start a new game where `player_preference = 0` means player goes second (plays O) and\\n    // `player_preference > 0` means the plater goes first (plays X).\\n    function newGame(uint256 player_preference) public {\\n        address player = msg.sender;\\n        games[player] = 0;\\n        if (player_preference == 0) {\\n            takeComputerTurn(player, 0);\\n        }\\n    }\\n\\n    function takePlayerTurn(uint256 move) public {\\n        address player = msg.sender;\\n        uint256 currentState = games[player];\\n        require(currentState < 0x1000000000000000000, \\"Game Over\\");\\n        require(legalMoves[move] > 0, \\"Invalid move\\");\\n        require(move & currentState == 0, \\"Move at filled cell\\");\\n        currentState ^= move;\\n        games[player] = currentState;\\n        takeComputerTurn(player, currentState);\\n    }\\n\\n    function getGameState(address player) public view returns (uint256) {\\n        return games[player];\\n    }\\n\\n    // Call the tic tac toe contract on NEAR to make a move.\\n    function takeComputerTurn(address player, uint256 initialState) private {\\n        bytes memory data = abi.encodePacked(\\"{\\\\\\"state\\\\\\":\\\\\\"\\", encodeStateForNear(initialState), \\"\\\\\\"}\\");\\n\\n        PromiseCreateArgs memory callGetMove = near.call(ticTacToeAccountId, \\"get_move\\", data, 0, GET_MOVE_NEAR_GAS);\\n        PromiseCreateArgs memory callback = near.auroraCall(\\n            address(this),\\n            abi.encodeWithSelector(this.computerTurnCallback.selector, player),\\n            0,\\n            COMPUTER_TURN_CALLBACK_NEAR_GAS\\n        );\\n\\n        callGetMove.then(callback).transact();\\n    }\\n\\n    // Get the result of calling the NEAR contract. Update the internal state of this contract.\\n    function computerTurnCallback(address player) public onlyRole(CALLBACK_ROLE) {\\n        PromiseResult memory result = AuroraSdk.promiseResult(0);\\n\\n        if (result.status != PromiseResultStatus.Successful) {\\n            revert(\\"Tic tac toe Near call failed\\");\\n        }\\n\\n        // output is of the form `{\\"updated_state\\":\\"<NINE_STATE_BYTES>\\",\\"winner\\":\\"CellState::<X|O|Empty>\\"}`\\n        // where the `winner` field is optional.\\n        uint256 updatedState = decodeNearState(result.output);\\n\\n        if (result.output.length > 37) {\\n            // Indicate the game is over by setting some higher bytes\\n            updatedState ^= 0x1100000000000000000000;\\n        }\\n\\n        games[player] = updatedState;\\n\\n        emit Turn(player, string(result.output));\\n    }\\n}\\n```\\n\\nThe nice thing about using Aurora for the on-chain transactions is that we can easily onboard users with the 50 free transactions Aurora provides to any user (the onboarding is simpler because they do not need to purchase crypto to cover gas fees; they can just start playing our game right away).\\n\\nThe final piece of the puzzle is for there to be a front-end the user interacts with and makes transactions to this contract on their behalf.\\n\\n### BOS front-end\\n\\nThe Blockchain Operating System (BOS) allows the creation of decentralized front-ends where the code is hosted on the Near blockchain. BOS gateways (which anyone can run) then serve the code to end-users. This is convenient for me as the developer because I do not need to host any servers for my front end; I know that BOS gateways will take care of it for me.\\\\\\n\\\\\\nIf you are familiar with using the React JavaScript framework, you will have no problem writing front-ends in BOS. I\u2019m not much of a JS developer myself, and even I found it reasonably easy to use BOS to make a simple front-end (keep this in mind when you look at the front-end; I am not a professional front-end developer). The complete source code can be [*viewed on BOS itself*](https://bos.gg/#/mob.near/widget/WidgetSource?src=nearcon.birchmd.near/widget/Aurora-Tic-Tac-Toe), but here are some highlights of the code:\\n\\n```jsx\\nconst sender = Ethers.send(\\"eth_requestAccounts\\", [])[0];\\n\\nif (!sender) return <Web3Connect connectLabel=\\"Connect with Web3\\" />;\\n\\nconst contractAbi = fetch(\\n  \\"https://gist.githubusercontent.com/birchmd/3db801d6115ceaaafb3d7e8fd94e0dc2/raw/5aa660a746d8f137df2c77142bfba36057dab6ef/TicTacToe.abi.json\\"\\n);\\n\\nconst iface = new ethers.utils.Interface(contractAbi.body);\\n\\nconst contract = new ethers.Contract(\\n  contract_address,\\n  contractAbi.body,\\n  Ethers.provider().getSigner()\\n);\\n\\ninitState({\\n  board: {\\n    isGameOver: false,\\n    board: [\\".\\", \\".\\", \\".\\", \\".\\", \\".\\", \\".\\", \\".\\", \\".\\", \\".\\"],\\n  },\\n  pendingPlayer: \\"X\\",\\n  player: \\"X\\",\\n  playerNumber: 1,\\n  expectNewState: true,\\n  firstQuery: true,\\n  startingNewGame: false,\\n});\\n\\nconst newGame = () => {\\n  // Don\'t allow sending new transactions while waiting\\n  // for the state to update.\\n  if (state.expectNewState) {\\n    return;\\n  }\\n\\n  let player_prefernece;\\n\\n  if (state.pendingPlayer == \\"X\\") {\\n    State.update({ player: \\"X\\", playerNumber: 1 });\\n    player_prefernece = 1;\\n  } else {\\n    State.update({ player: \\"O\\", playerNumber: 17 });\\n    player_prefernece = 0;\\n  }\\n\\n  contract.newGame(player_prefernece).then((tx) => {\\n    State.update({ expectNewState: true, startingNewGame: true });\\n    tx.wait().then((rx) => {\\n      console.log(rx);\\n      getGameState();\\n    });\\n  });\\n};\\n\\nconst playerMove = (index) => {\\n  if (\\n    !state.expectNewState &&\\n    !state.board.isGameOver &&\\n    state.board.board[index] == \\".\\"\\n  ) {\\n    const move =\\n      \\"0x\\" +\\n      (\\n        new BN(state.playerNumber) * new BN(256).pow(new BN(8 - index))\\n      ).toString(16);\\n    contract.takePlayerTurn(move).then((tx) => {\\n      State.update({ expectNewState: true, startingNewGame: false });\\n      tx.wait().then((rx) => {\\n        console.log(rx);\\n        getGameState();\\n      });\\n    });\\n  }\\n};\\n\\nconst getGameState = () => {\\n  // shot curcuit to avoid constantly hitting the RPC\\n  if (!state.expectNewState) {\\n    return;\\n  }\\n\\n  const encodedData = iface.encodeFunctionData(\\"getGameState\\", [sender]);\\n\\n  Ethers.provider()\\n    .call({\\n      to: contract_address,\\n      data: encodedData,\\n    })\\n    .then((boardHex) => {\\n      const result = parseBoardHex(boardHex);\\n      const expectNewState =\\n        state.expectNewState &&\\n        !state.firstQuery &&\\n        result.isGameOver == state.board.isGameOver &&\\n        JSON.stringify(result.board) === JSON.stringify(state.board.board);\\n\\n      State.update({\\n        board: result,\\n        player,\\n        playerNumber,\\n        winner,\\n        expectNewState,\\n        firstQuery: false,\\n      });\\n    });\\n};\\n\\nreturn (\\n  <>\\n    {getGameState()}\\n    <table>\\n      <tr>\\n        <TopLeftCell onClick={() => playerMove(0)}>\\n          {state.board.board[0]}\\n        </TopLeftCell>\\n        <TopCenterCell onClick={() => playerMove(1)}>\\n          {state.board.board[1]}\\n        </TopCenterCell>\\n        <TopRightCell onClick={() => playerMove(2)}>\\n          {state.board.board[2]}\\n        </TopRightCell>\\n      </tr>\\n      <tr>\\n        <MiddleLeftCell onClick={() => playerMove(3)}>\\n          {state.board.board[3]}\\n        </MiddleLeftCell>\\n        <MiddleCenterCell onClick={() => playerMove(4)}>\\n          {state.board.board[4]}\\n        </MiddleCenterCell>\\n        <MiddleRightCell onClick={() => playerMove(5)}>\\n          {state.board.board[5]}\\n        </MiddleRightCell>\\n      </tr>\\n      <tr>\\n        <BottomLeftCell onClick={() => playerMove(6)}>\\n          {state.board.board[6]}\\n        </BottomLeftCell>\\n        <BottomCenterCell onClick={() => playerMove(7)}>\\n          {state.board.board[7]}\\n        </BottomCenterCell>\\n        <BottomRightCell onClick={() => playerMove(8)}>\\n          {state.board.board[8]}\\n        </BottomRightCell>\\n      </tr>\\n    </table>\\n    <br></br>\\n    {state.board.isGameOver && <div>{state.winner}</div>}\\n    {state.expectNewState ? (\\n      <div>\\n        <p>Waiting for new data from RPC...</p>\\n      </div>\\n    ) : (\\n      <div />\\n    )}\\n    <br></br>\\n    <label for=\\"selectPlayer\\">Play as:</label>\\n    <select\\n      id=\\"selectPlayer\\"\\n      onChange={(e) => State.update({ pendingPlayer: e.target.value })}\\n    >\\n      <option value=\\"X\\">X</option>\\n      <option value=\\"O\\">O</option>\\n    </select>\\n    <div class=\\"mb-3\\">\\n      <button onClick={newGame}>New Game</button>\\n    </div>\\n  </>\\n);\\n```\\n\\n### Demo and Conclusion\\n\\nThis app is live on BOS now! You can play with it yourself [*here*](https://bos.gg/#/nearcon.birchmd.near/widget/Aurora-Tic-Tac-Toe) or view a pre-recorded demo [*here*](https://youtu.be/\\\\_tSuGRN9Lok). To use the demo app, ensure your MetaMask is connected to the Aurora Testnet (the BOS interface might say the network is unrecognized, but it should still work for sending the transactions).\\n\\nThis post explored the Near tech stack for building fully decentralized applications. This entire application is hosted on-chain from the front to the back end. The Near blockchain provides the base computation layer with its WebAssembly-powered runtime, Aurora provides the persistence layer while maintaining easy onboarding in free transactions, and BOS provides a serverless front-end built on the Near blockchain.\\n\\nI hope you enjoyed this blog post and are feeling inspired to go build some yourself using Aurora, Near, and BOS!"},{"id":"/aurora-chains-demo","metadata":{"permalink":"/blog/aurora-chains-demo","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/aurora-chains-demo.md","source":"@site/blog/aurora-chains-demo.md","title":"Aurora Chains: Walkthrough","description":"Dive into the Aurora Innovation Chain details: custom access control, \u0441ustom token mechanics, interoperability and more","date":"2023-04-28T00:00:00.000Z","tags":[{"inline":false,"label":"Tutorials","permalink":"/blog/tags/tutorials","description":"Longer posts talking about the subject in detail"}],"readingTime":4.213333333333333,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"Aurora Chains: Walkthrough","description":"Dive into the Aurora Innovation Chain details: custom access control, \u0441ustom token mechanics, interoperability and more","date":"2023-04-28","authors":["slava"],"tags":["tutorials"],"image":"https://www.datocms-assets.com/95026/1701394098-ac2.png"},"unlisted":false,"prevItem":{"title":"Building a game using Near, Aurora and BOS","permalink":"/blog/building-a-game-using-near-aurora-and-bos"},"nextItem":{"title":"Cross-Ecosystem Communication","permalink":"/blog/cross-ecosystem-communication"}},"content":"Aurora Chains are dedicated blockchains that go beyond mere Ethereum compatibility through a set of industry-first innovations like:\\n\\n* *custom token & fee mechanics* (e.g., gasless transactions; paying for gas with a custom token; some percentage of any transaction value to be stored in Aurora Chain Treasury, etc.);\\n* *custom access control* (public vs private chain, who can transact, who can deploy contracts? e.g., NFT-based access to the blockchain, private chain can be built by using a private NEAR shard \u2013 [Calimero](https://www.calimero.network/));\\n* *seamless interoperability* with Aurora, NEAR, and any other Aurora Chains: you can freely move your assets using Rainbow Bridge, call contracts via cross-contract calls, etc.; This is the main difference between Chains and other solutions (like Avalanche or Cosmos). There is no disjointness in between. You can call any smart contract in any other Chain or Near and interact with it freely.\\n* *tremendous transaction throughput* \u2013 we can provide you with dozens of millions of transactions daily for your ecosystem.\\n\\nEvery Aurora Chain is based upon the [Aurora smart contract.](https://github.com/aurora-is-near/aurora-engine/) Aurora Chain is just another instance of it that can be configured in way that will work in the best way possible to be aligned with your business model and goals. The Aurora Labs team will gladly help you maintain and support your chain.\\n\\n\\\\\\nIf you feel your business could benefit from its own blockchain, please do not hesitate to contact us at [hello@auroracloud.dev](emailto:hello@auroracloud.dev).\\\\\\n\\\\\\nLet\'s do a walkthrough demo of Aurora Innovation Chain to see how it benefits your users.\\n\\n\x3c!-- truncate --\x3e\\n\\n**Note**: you will see sometimes Aurora Chains called Silos on the screenshots. The meaning is the same. It is just a more user-friendly renaming of the technology.\\n\\n### Access Control\\n\\nLet\'s go to the [https://auroracloud.dev/demo](https://auroracloud.dev/demo) site first, connect the [MetaMask wallet](https://dev.aurora.dev/ecosystem/MetaMask), and we\'ll be ready for our first step \u2013 Access Control demo:\\n\\n![](https://www.datocms-assets.com/95026/1682424716-screenshot-2023-04-25-at-12-05-26.png)\\n\\nIn the case of the Innovation Chain, we just need to fill in a simple form and submit it for review to Aurora:\\n\\n![](https://www.datocms-assets.com/95026/1682424978-screenshot-2023-04-25-at-12-07-41.png)\\n\\nAfter submitting it, you will need to wait for some time until you will get your access approved:\\n\\n![](https://www.datocms-assets.com/95026/1682425059-screenshot-2023-04-25-at-13-17-04.png)\\n\\nAfter approval, you will see this confirmation message:\\n\\n![](https://www.datocms-assets.com/95026/1682425145-screenshot-2023-04-25-at-13-18-35.png)\\n\\nAnd receive your first free 500 INNO tokens to be used:\\n\\n![](https://www.datocms-assets.com/95026/1682425188-screenshot-2023-04-25-at-12-19-41.png)\\n\\nWith those in hand, we can move on to the next step.\\n\\n### Ethereum compatibility & custom token mechanics\\n\\nIn the next stage, we will see a popup notifying us that every transaction in Aurora Innovation Chain will cost us 1 INNO token. Isn\'t that great?\\n\\n![](https://www.datocms-assets.com/95026/1682455553-screenshot-2023-04-25-at-21-42-50.png)\\n\\n\\\\\\nYou can also notice the balance of INNO tokens at the top right corner widget on the site. As you can see, we got 500 INNO tokens after the access approval. So we have some tokens to pay for the gas on the Innovation Chain now and play with it.\\\\\\n\\\\\\nLet\'s try this Chain in a real-world example and swap some tokens. First, we\u2019ll swap INNO for our \\"dog-token\\", Poodle, using a Uniswap fork. Notice, that in every Chain, you can pre-install key applications from the list of Aurora partners (including Oracles, AMMs, Lending platforms, NFT marketplaces, etc.) So you can benefit immediately from the ecosystem we already have on Aurora!\\n\\nLet\'s swap the tokens now and enter some amount of INNO into the widget:\\n\\n![](https://www.datocms-assets.com/95026/1682455898-screenshot-2023-04-25-at-21-51-26.png)\\n\\nAfter clicking the Swap button we will see the following info about the transaction in MetaMask:\\\\\\n\\n![](https://www.datocms-assets.com/95026/1682456030-screenshot-2023-04-25-at-21-53-11.png)\\n\\nAs expected, we will spend 1 INNO per gas fee on that transaction! After the swap is complete, you will notice that your Poodle balance has been updated, and you will be able to see the transaction on the Chain Explorer:\\n\\n![](https://www.datocms-assets.com/95026/1682456144-screenshot-2023-04-25-at-21-55-03.png)\\n\\nChain Explorer is a dedicated instance of the [Block Explorer.](https://dev.aurora.dev/ecosystem/block-explorer) It can help you monitor your activity, look into the details of transactions, verify contracts, and call your contract methods from the UI directly. Every Chain can have its own explorer, which we can set up for you.\\\\\\n\\\\\\nLet\'s open the following [link](https://explorer.innovation.aurora.dev/tx/0x729676bb7db14c0dd907d2398d2905d1f9286a0e0478cb6aa5375dde0d1bfb25), we will see the Aurora Innovation Explorer window with all the details of the transaction executed:\\\\\\n\\n![](https://www.datocms-assets.com/95026/1682516992-screenshot-2023-04-26-at-14-49-39.png)\\n\\nAs you can see, the data exactly corresponds to our expectations: we have 1 INNO spent as a fee and 10 INNO swapped. And notice that transaction has been confirmed within 1.116 seconds, corresponding to the usual time on NEAR and Aurora.\\n\\n### Interoperability\\n\\nLet\'s now move on to the next step and talk about the interoperability of the Aurora Chain:\\\\\\n\\n![](https://www.datocms-assets.com/95026/1682517331-screenshot-2023-04-26-at-14-54-31.png)\\n\\nAurora Chains can transfer assets to and from Ethereum, NEAR, and Aurora, and in between any other Aurora Chains using the Rainbow Bridge technology. We will move AURORA tokens between NEAR and Aurora Innovation in this demo. Let\'s connect a NEAR wallet to do this:\\\\\\n\\n![](https://www.datocms-assets.com/95026/1682517522-screenshot-2023-04-26-at-14-58-15.png)\\n\\nAfter clicking the \\"Connect NEAR Wallet\\" button, you will need to choose your wallet:\\n\\n![](https://www.datocms-assets.com/95026/1682518634-screenshot-2023-04-26-at-14-59-01.png)\\n\\nI will continue by choosing the \\"NEAR Wallet\\" option. After that, you will be redirected to the NEAR Wallet page to confirm the connection to the [auroracloud.dev](https://auroracloud.dev/) site, and then you will see the next widget:\\n\\n![](https://www.datocms-assets.com/95026/1682518704-screenshot-2023-04-26-at-15-13-30.png)\\n\\nNow you can transfer some Aurora tokens from NEAR to Aurora Innovation here. This transfer is possible to do with Rainbow Bridge (read more about how the bridge works [here](https://near.org/blog/eth-near-rainbow-bridge/) or [here)](https://aurora.dev/blog/2021-how-the-rainbow-bridge-works), which our developers have configured to process transactions between Aurora Innovation and NEAR. The abilities of this widget are limited due to the demo purposes, but you can bridge any ERC-20 token or ETH using it on your own Aurora Chain.\\n\\nLet\'s bridge the 0.48 AURORA we have in the wallet to Aurora Innovation now, let\'s enter the value and push the \\"Transfer tokens\\" button. You will need to confirm the transaction on NEAR now:\\\\\\n\\n![](https://www.datocms-assets.com/95026/1682519151-screenshot-2023-04-26-at-15-14-10.png)\\n\\nAnd just in a second, it is done! You will see this confirmation message with the link to the NEAR Explorer transaction:\\n\\n![](https://www.datocms-assets.com/95026/1682519295-screenshot-2023-04-26-at-15-15-15.png)\\n\\nWe now notice that your Aurora Innovation balance has been topped up in the top-right corner widget by the amount you\'ve bridged. And if we go directly to the [NEAR explorer link:](https://nearblocks.io/txns/86EGzooMqaSsetC1BbwknjNRTytthaFgFgLCWH153QT7)\\n\\n![](https://www.datocms-assets.com/95026/1682519404-screenshot-2023-04-26-at-15-28-37.png)\\n\\nWe will see there our bridge transfer which has been done using a call to the NEP-141 token:\\\\\\n*aaaaaa20d9e0e2461697782ef11675f668207961.factory.bridge.near* which represent AURORA token on NEAR. And that balance of the [aurora-silo-dev.near](https://nearblocks.io/address/aurora-silo-dev.near) has been topped up, which is our Aurora Chain contract on NEAR, the little brother of the [aurora.near,](https://nearblocks.io/address/aurora.near) but with the same capabilities in a nutshell.\\n\\n### Contract Deployment Rights\\n\\nNow we can move to the easiest part of the demo, where we can just make sure that we can not deploy a contract on Aurora Innovation:\\n\\n![](https://www.datocms-assets.com/95026/1682520005-screenshot-2023-04-26-at-15-34-16.png)\\n\\nThis rule was also made simple for demonstration purposes, but of course, we can implement any other rule: e.g., having a whitelist of accounts that can deploy contracts. And actually, we have it! However we have only allowed the contract deployment to be done by some of our developers on the team. So let\'s deploy the contract anyway and push the button. We will receive the MetaMask transaction popup:\\n\\n![](https://www.datocms-assets.com/95026/1682520201-screenshot-2023-04-26-at-15-34-33.png)\\n\\nLet\'s confirm it, and then we\'ll get this message:\\n\\n![](https://www.datocms-assets.com/95026/1682520228-screenshot-2023-04-26-at-15-35-16.png)\\n\\nWe can check the transaction history in MetaMask to see that it has failed:\\n\\n![](https://www.datocms-assets.com/95026/1682520426-screenshot-2023-04-26-at-15-45-58.png)\\n\\n### Conclusions\\n\\nNow we\'re at the end of the demo:\\n\\n![](https://www.datocms-assets.com/95026/1682520850-screenshot-2023-04-26-at-15-35-27.png)\\n\\nThat is it for today! We\'ve seen how Aurora Chain can implement Custom Access Control, be fully Ethereum compatible, have its token mechanics, and have fast interoperability with NEAR using Rainbow Bridge.\\\\\\n\\\\\\nIn upcoming articles, we will discuss the technical details of the Aurora Chains and other Aurora Cloud components. So stay tuned for the updates!\\\\\\n\\\\\\nThank you for your reading!"},{"id":"/cross-ecosystem-communication","metadata":{"permalink":"/blog/cross-ecosystem-communication","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/cross-ecosystem-communication.md","source":"@site/blog/cross-ecosystem-communication.md","title":"Cross-Ecosystem Communication","description":"Discover how cross-contracts calls communication can happen between NEAR and Aurora using Aurora Contracts SDK","date":"2023-04-21T00:00:00.000Z","tags":[{"inline":false,"label":"Core Tech","permalink":"/blog/tags/core_tech","description":"Posts about core technologies on Aurora"}],"readingTime":4.836666666666667,"hasTruncateMarker":true,"authors":[{"name":"Boris Polania","title":"DevRel","imageURL":"https://www.datocms-assets.com/95026/1678396869-twiter_profile_pic.png","key":"boris","page":null}],"frontMatter":{"title":"Cross-Ecosystem Communication","description":"Discover how cross-contracts calls communication can happen between NEAR and Aurora using Aurora Contracts SDK","date":"2023-04-21","authors":["boris"],"tags":["core_tech"],"image":"https://www.datocms-assets.com/95026/1682340168-cec-article-cover.png"},"unlisted":false,"prevItem":{"title":"Aurora Chains: Walkthrough","permalink":"/blog/aurora-chains-demo"},"nextItem":{"title":"How the Aurora Relayer 2.0 works?","permalink":"/blog/aurora-relayer-2-0"}},"content":"Aurora\u2019s infrastructure is built upon an innovative combination\u2014our Ethereum Virtual Machine (EVM) operates as a smart contract running atop the powerful NEAR protocol. Harnessing NEAR\'s innate ability for smart contracts to communicate with one another, we seamlessly route EVM-compatible transactions to any smart contract deployed within NEAR. By doing so, developers are granted unparalleled access to the best of both ecosystems - from a rich collection of sound and robust Solidity libraries to the groundbreaking NEAR accounts model and an ever-growing, expansive user base.\\n\\n\x3c!-- truncate --\x3e\\n\\nEmbracing Aurora\'s dedication to exceptional user experiences, our team has crafted a Software Development Kit (SDK) tailored to provide developers with a seamless method for facilitating cross-blockchain transactions. Access the SDK in the dedicated [repository](https://github.com/aurora-is-near/aurora-contracts-sdk), or integrate it into your project effortlessly.\\n\\nAurora\'s Solidity developers can install an npm package by executing `npm i @auroraisnear/aurora-sdk` in any terminal, while NEAR Rust developers can similarly incorporate a cargo package from our [repository](https://github.com/aurora-is-near/aurora-engine.git). For a more customized installation, or if you want to contribute to the project, you can also follow the installation instructions in the repository.\\n\\n![](https://www.datocms-assets.com/95026/1682019691-screen-shot-2023-04-20-at-12-41-15-pm.png)\\n\\nFor this article, we have prepared two examples for developers to understand how to use the SDK. The first is a Solidity smart contract that connects the SocialDB contract, the storage layer that backs the [NEAR.social](https://near.social/#/) decentralized social media platform. Even though this integration would allow using MetaMask as an entry point into that social network, its importance extends further.\\n\\nSocialDB, initially designed to store various types of social data on the NEAR protocol, has evolved over time to become the foundation for a user-centric Open Web, where users maintain control over their data. This approach has ultimately led to the development of NEAR\'s Blockchain Operating System (BOS). As such, the seamless integration of SocialDB with BOS is crucial, as it provides Aurora developers with access to one of the most potent tools within the NEAR ecosystem .\\n\\nThe second integration example involves calling the Uniswap contract deployed in Aurora from a Rust contract deployed in NEAR. This integration is vital because it allows NEAR users to access Uniswap\'s decentralized exchange platform, one of the most popular and widely used in the cryptocurrency space.\\n\\nBy having access to Uniswap, NEAR users can benefit from its liquidity pools, token swaps, and other DeFi services, enhancing their ability to trade and interact with a diverse range of digital assets. This seamless connection between NEAR and Uniswap not only enriches the user experience but also fosters the growth of the broader decentralized finance ecosystem in both protocols.\\n\\n### From Aurora to NEAR\\n\\nIn this example, a solidity contract called \\\\`SocialDB.sol\\\\` will call the \\\\`set\\\\` function\u2013used to store data in the SocialDB rust contract deployed on NEAR and will implement a callback function that receives the result of the \\\\`set\\\\` call.\\\\\\n\\\\\\nIn summary, this contract interacts with the SocialDB contract on the NEAR platform. It sends wNEAR tokens as a fee to cover the storage cost of data being persisted on NEAR and using promises to chain cross-contract calls and callbacks. This regular solidity contract implements common libraries such as OpenZeppelin\'s AccessControl.\\n\\n![](https://www.datocms-assets.com/95026/1682019506-screen-shot-2023-04-20-at-12-37-46-pm.png)\\n\\nNow, to interact with the SocialDB contract, this contract imports the Aurora SDK.\\n\\n```solidity\\nimport \\"@aurora/sdk/solidity/AuroraSdk.sol\\";\\n```\\n\\nThen, it attaches the AuroraSdk library functions to the `NEAR`, `PromiseCreateArgs`, and `PromiseWithCallback` data types, allowing the contract to call these functions as if they were methods of the respective data types. This enables a more intuitive and readable syntax when working with NEAR instances, such as `near.call()` or `near.auroraCall()`, and simplifies the usage of `PromiseCreateArgs` and `PromiseWithCallback` instances, like `callSet.then()` and `callSet.then(callback).transact()`.\\n\\n```solidity\\nusing AuroraSdk for NEAR;\\nusing AuroraSdk for PromiseCreateArgs;\\nusing AuroraSdk for PromiseWithCallback;\\n```\\n\\nIn addition, it defines two constants, `SET_NEAR_GAS` and `SET_CALLBACK_NEAR_GAS`, representing the amount of NEAR gas attached to the calls and callbacks. When calling another NEAR contract, you must specify how much NEAR gas will be attached to the call (similar to the `gas` argument in the EVM `call` opcode). The typical unit on Near is the teragas (Tgas), where 1 Tgas = 10^12 gas. For example, the block gas limit on NEAR is 1000 Tgas, and the transaction gas limit is 300 Tgas.\\n\\n```solidity\\nuint64 constant SET_NEAR_GAS = 50_000_000_000_000;\\nuint64 constant SET_CALLBACK_NEAR_GAS = 10_000_000_000_000;\\n```\\n\\nThe core of the SocialDB contract, written in Solidity, comprises two primary functions. The first function, `set`, exposes the contract\'s interface for setting data within the SocialDB contract in NEAR. Access control is essential for this function to ensure that only authorized users can instruct keys to be set in the database. Additionally, an amount of `wNEAR` is necessary for this call to cover the storage cost of the data being saved on NEAR.\\n\\n```solidity\\nfunction set(uint128 attachedNear, bytes memory data) public onlyRole(SETTER_ROLE) {\\n       wNEAR.transferFrom(msg.sender, address(this), attachedNear);\\n       PromiseCreateArgs memory callSet = near.call(socialdbAccountId, \\"set\\", data, attachedNear, SET_NEAR_GAS);\\n       PromiseCreateArgs memory callback = near.auroraCall(address(this), abi.encodePacked(this.setCallback.selector), 0, SET_CALLBACK_NEAR_GAS);\\n       callSet.then(callback).transact();\\n   }\\n```\\n\\nThe second function, `setCallback`, verifies the success of the previous promise result. If unsuccessful, the transaction is reverted. This function is not intended for use by externally owned accounts (EOAs) and should only be executed as a callback from the main `set` method mentioned earlier. Consequently, it employs its own distinct access control mechanism, independent of other functions.\\n\\n```solidity\\nfunction setCallback() public onlyRole(CALLBACK_ROLE) {\\nif (AuroraSdk.promiseResult(0).status != PromiseResultStatus.Successful){\\n           revert(\\"Call to set failed\\");\\n       }\\n }\\n```\\n\\nAs we can see, the SDK provides a way to wrap functions in NEAR contracts easily. Similarly, it is possible to make calls the other way around. Now, let\u2019s look at how to call Aurora contracts from NEAR.\\n\\n### From NEAR to Aurora\\n\\nIn this example, a NEAR contract calls the Uniswap V3 contract deployed on Aurora. A callback is attached to the NEAR contract so that it can check the result of the EVM execution. Because the entire Uniswap API is complex, this example only implements one function\u2013`exactOutputSingle`\u2013to illustrate the pattern. The `exactOutputSingle` function performs a token swap using a single liquidity pool where the swap is constrained to give an exact amount of the \\"output\\" token within some price limitation of the \\"input\\" token. The return value is the number of input tokens spent to make the swap.\\n\\n![](https://www.datocms-assets.com/95026/1682019594-screen-shot-2023-04-20-at-12-39-37-pm.png)\\n\\nTo interact with the Uniswap contract, this contract imports the Aurora SDK.\\n\\n```rust\\nuse aurora_sdk::{\\n   ethabi, near_sdk, Address, CallArgs, FunctionCallArgsV1, SubmitResult, TransactionStatus, U256,\\n};\\n```\\n\\nThe Near contract works as a proxy with a method called `exact_output_single` that takes the same input as Uniswap\'s `exactOutputSingle.` To work well in the Near ecosystem, the `exact_output_single` function takes the arguments as a JSON encoded object and then re-encodes it into the Solidity ABI. The `exact_output_single` function returns a promise because, under the hood, it is making a Near cross-contract call to the Aurora EVM where the Uniswap code is deployed.\\n\\n```rust\\npub fn exact_output_single(&self, params: SerializableExactOutputSingleParams) -> Promise {\\n    let params: ExactOutputSingleParams = params.try_into().unwrap();\\n    let evm_token = ethabi::Token::Tuple(vec![\\n        ethabi::Token::Address(params.token_in.raw()),\\n        ethabi::Token::Address(params.token_out.raw()),\\n        ethabi::Token::Uint(params.fee.into()),\\n        ethabi::Token::Address(params.recipient.raw()),\\n        ethabi::Token::Uint(params.deadline),\\n        ethabi::Token::Uint(params.amount_out),\\n        ethabi::Token::Uint(params.amount_in_max),\\n        ethabi::Token::Uint(params.price_limit),\\n    ]);\\n    let evm_input = ethabi::encode(&[evm_token]);\\n    let aurora_call_args = CallArgs::V1(FunctionCallArgsV1 {\\n        contract: self.uniswap,\\n        input: [\\n            EXACT_OUTPUT_SINGLE_SELECTOR.as_slice(),\\n            evm_input.as_slice(),\\n        ]\\n        .concat(),\\n    });\\n    aurora_sdk::aurora_contract::ext(self.aurora.clone())\\n    .with_unused_gas_weight(3)\\n    .call(aurora_call_args)\\n    .then(Self::ext(env::current_account_id()).parse_exact_output_single_result())\\n}\\n```\\n\\nFinally, it attaches a callback to the promise to interpret the output obtained from Aurora and present it more Near-friendly (i.e., encoding it in JSON instead of a binary format).\\n\\n```rust\\npub fn parse_exact_output_single_result(\\n    &self,\\n    #[serializer(borsh)]\\n    #[callback_unwrap]\\n    result: SubmitResult,\\n) -> ExactOutputSingleResult {\\n    match result.status {\\n        TransactionStatus::Succeed(bytes) => {\\n            let amount_in = U256::from_big_endian(&bytes);\\n            ExactOutputSingleResult {\\n                amount_in: amount_in.to_string(),\\n            }\\n        }\\n        TransactionStatus::Revert(bytes) => {\\n            let error_message =\\n            format!(\\"Revert: {}\\", aurora_sdk::parse_evm_revert_message(&bytes));\\n            env::panic_str(&error_message)\\n        }\\n        other => env::panic_str(&format!(\\"Aurora Error: {other:?}\\")),\\n    }\\n}\\n```\\n\\nUsing the same paradigm as the solidity SDK, the NEAR version provides a way to wrap functions in Aurora contracts easily.\\n\\nIn conclusion, the cross-chain contract calls between Aurora and NEAR offer a powerful and flexible solution for developers and users who wish to access the benefits of both platforms. By leveraging the capabilities of Aurora and the NEAR Protocol, these communications enable seamless interaction between the two ecosystems.\\n\\nMoreover, cross-chain contracts facilitate greater interoperability and foster a more decentralized ecosystem. As more developers build innovative solutions utilizing cross-chain functionality, we can expect an even more vibrant and interconnected space, with enhanced opportunities for users to access a wider array of decentralized products and services.\\n\\nIn the future, we anticipate an increasing number of cross-chain contracts and infrastructure solutions that will further unite Aurora and NEAR ecosystems. By continuing to develop and refine these cross-chain capabilities, we can unlock new levels of innovation, utility, and adoption across the blockchain industry, ultimately paving the way for a more decentralized and interconnected future.\\n\\n*We want to thank Michael Birch for his support and contributions to this article, we really appreciate it!*"},{"id":"/aurora-relayer-2-0","metadata":{"permalink":"/blog/aurora-relayer-2-0","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/aurora-relayer-2-0.md","source":"@site/blog/aurora-relayer-2-0.md","title":"How the Aurora Relayer 2.0 works?","description":"Learn about Aurora\'s relayer inner workings and how those innovate the future of the blockchain technologies","date":"2023-03-31T00:00:00.000Z","tags":[{"inline":false,"label":"Core Tech","permalink":"/blog/tags/core_tech","description":"Posts about core technologies on Aurora"}],"readingTime":3.34,"hasTruncateMarker":true,"authors":[{"name":"Oleksii Krasynskyi","title":"Head of Infrastructure","imageURL":"https://www.datocms-assets.com/95026/1726603153-screenshot-2024-09-17-at-20-59-04.png","key":"oleksii_krasynskyi","page":null}],"frontMatter":{"title":"How the Aurora Relayer 2.0 works?","description":"Learn about Aurora\'s relayer inner workings and how those innovate the future of the blockchain technologies","date":"2023-03-31","authors":["oleksii_krasynskyi"],"tags":["core_tech"],"image":"https://www.datocms-assets.com/95026/1682082014-relayer-article-cover.png"},"unlisted":false,"prevItem":{"title":"Cross-Ecosystem Communication","permalink":"/blog/cross-ecosystem-communication"},"nextItem":{"title":"How to get NEAR transaction from the Aurora\u2019s one?","permalink":"/blog/convert-aurora-transaction-into-near-s-one"}},"content":"In the blockchain world, relayers are off-chain facilitators of data exchange and transactions between blockchain networks and/or layers. They are used primarily in decentralized finance applications, cross-chain communication, and Layer 2 solutions, like sidechains or state channels. In general, relayers listen for events and transactions from one point and then submit the corresponding data or transactions to another. For that, they can charge fees for their services, incentivizing them to operate and maintain their infrastructure.\\n\\nInitially developed in-house at NEAR, the Aurora EVM is the official EVM for the NEAR ecosystem. Powered by the SputnikVM, it accomplishes a 1:1 experience with the Ethereum protocol.\\n\\nThis compatibility between Aurora and Ethereum is achieved by the **Aurora Relayer**, a JSON-RPC compatible server with Ethereum\'s [Web3 API](https://eth.wiki/json-rpc/API) for the [Aurora Engine](https://github.com/aurora-is-near/aurora-engine)It has its own internal database to serve multiple read methods and an indexer that is constantly following the head and indexing blocks, transactions and logs to that internal database.\\n\\n\x3c!-- truncate --\x3e\\n\\n### **Relayer 2.0**\\n\\nAs mentioned above, the Aurora Relayer has two main components. First, an implementation of Ethereum\u2019s JSON-RPC specification\u2014a standard collection of methods that all clients must implement and the canonical interface between users and the Ethereum network\u2014on Aurora\u2019s Ethereum Virtual Machine (EVM), a.k.a. the Aurora Engine. Second, an indexer that continuously reads the NEAR network for blocks and other relevant information relevant to Aurora.\\n\\nThe Relayer had [its first version](https://github.com/aurora-is-near/aurora-relayer) deployed in October 2021. Developed in Typescript and JavaScript. It has been deprecated and replaced by [version 2.0](https://github.com/aurora-is-near/relayer2-public), with a JSON-RPC server written in go-lang and the indexer developed in go-lang and rust.\\n\\n![](https://www.datocms-assets.com/95026/1680267251-relayer-10.png)\\n\\nRelayer 2.0 was motivated by the necessity of migrating from JavaScript to a more reliable language like golang that is designed for concurrency and is particularly good at managing multiple connections and resource-intensive tasks, making it very well-suited for the type of high-performance RPC systems required in blockchains.\\n\\nAdditionally, it required migrating to a more efficient database system, so it was migrated from `PostgreSQL` to `badger-db` an embedded key-value database. As a result, there is now a relayer with faster execution speed,  lower machine resource usage, and lower data latency that is easier to code, debug, optimize, and deploy. Now, let\u2019s have a general overview of some of the internals of the Relayer.\\n\\n#### **The JSON-RPC**\\n\\nWritten in go-lang, it exposes endpoints that implement the methods of Ethereum\u2019s JSON-RPC protocol, commonly known as the Web3 API. This middleware leverages a messaging system that forwards JSON-PRC calls to the NEAR network and vice versa. Its source code is open and available to developers, contributors, and anyone who would like to build, run and experiment with it natively. A list of all the implemented methods and the server\'s source code can be found in the GitHub [*repo*](https://github.com/aurora-is-near/relayer2-public). Also, there is a standalone version available [*here*](https://github.com/aurora-is-near/standalone-rpc).\\n\\n![](https://www.datocms-assets.com/95026/1680267260-relayer-20.png)\\n\\n#### **The Database**\\n\\nEmbedded databases are a better choice for applications that don\'t require complex querying planning, as it provides a lightweight solution with fewer dependencies. They are also well-suited for applications that benefit from local data storage with low latency and need single-process concurrency for concurrent read and write operations without external coordination.\\\\\\n\\\\\\nBadgerDB\u2014our database of choice\u2014is an embeddable, persistent, fast key-value (KV) database written in pure Go. It is ideal for JSON-RPC servers as most methods grab data by key while benefitting from better data compression and lower latency. In addition, other teams inside Aurora are also using it, therefore, the required competencies and know-how were already there.\\n\\n#### **The Indexer**\\n\\nThe new embedded indexer continuously reads JSON files generated by the [Aurora Refiner](https://github.com/aurora-is-near/borealis-engine-lib) that populate a local database. The refiner allows users to download all NEAR Blocks and get all information relevant to Aurora.\\n\\nNEAR Blocks data can be consumed from two different sources: the [NEAR data lake](https://docs.near.org/concepts/advanced/near-lake-framework)\u2014 a repository of blocks and events from the NEAR network as JSON files on AWS \u2014 and an archival instance, [the NEARCore](https://github.com/near/nearcore). In general, Aurora Relayer infrastructure implements an indexer of NEAR blocks, an indexer of blocks from `tar` backups and an indexer of pre-history blocks (height < 34 mln). An open-source repository for the Aurora Refiner can be found [*here*](https://github.com/aurora-is-near/borealis-engine-lib).\\n\\n#### **And more\u2026**\\n\\nIn addition, and due to the nature of Aurora\u2019s relayer infrastructure and its interactions with the NEAR network, it was possible to upgrade our internal infrastructure to use our relayer with additions that allow the implementation\u2013among other things\u2013of complex multi-tenant, rule-based accounting systems that support virtually any possible way to account for transactions, to enforce gas prices, pre- or post-run transactions, etc.\\n\\nSo it is possible to have users with prepaid fees, prepaid gas, no gas, and many other configurations for distributing gas and fees between relayers, users, and owners of smart contracts. This means that anyone willing to spin a relayer will have access to more sophisticated economic mechanisms for its users or on behalf of others, thus acting the same way ERC-4337 bundlers do, i.e., as validators who earn incentives for completing transactions.\\n\\n### **The Future of User Experience**\\n\\nBy improving efficiency and reliability and by adding innovative functionality into the relayer, Aurora builders and developers can offer faster, more robust applications and significant improvements to the user\u2019s experience where \u2014 among other things \u2014 per-transaction fees could be eliminated and accounts could be detached from keys.\\n\\nTherefore, the Aurora Relayer stands as a groundbreaking innovation in the world of decentralised blockchain technologies. Furthermore, as we continue to see rapid advancements and increasing adoption, the Aurora Relayer sets the stage for a more interconnected and efficient future with the potential to unlock unprecedented levels of usability, scalability, security, and cost-effectiveness, ultimately contributing to a more accessible landscape for all types of users.\\n\\nIf you are interested in getting to know Aurora Relayers in more depth, in our next post, we will teach you how to modify and launch a stand-alone version of the relayer that can be called by a smart contract that can execute functions without charging gas to its callers, stay tuned!"},{"id":"/convert-aurora-transaction-into-near-s-one","metadata":{"permalink":"/blog/convert-aurora-transaction-into-near-s-one","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/convert-aurora-transaction-into-near-s-one.md","source":"@site/blog/convert-aurora-transaction-into-near-s-one.md","title":"How to get NEAR transaction from the Aurora\u2019s one?","description":"Let\'s find out how to dig into Aurora transactions and get the underlying NEAR data","date":"2023-03-30T00:00:00.000Z","tags":[{"inline":false,"label":"Tips & Tricks","permalink":"/blog/tags/tips_and_tricks","description":"Short posts about tech for devs on Aurora"}],"readingTime":1.8466666666666667,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"How to get NEAR transaction from the Aurora\u2019s one?","description":"Let\'s find out how to dig into Aurora transactions and get the underlying NEAR data","date":"2023-03-30","authors":["slava"],"tags":["tips_and_tricks"],"image":"https://www.datocms-assets.com/95026/1682082350-na-article-cover.png"},"unlisted":false,"prevItem":{"title":"How the Aurora Relayer 2.0 works?","permalink":"/blog/aurora-relayer-2-0"},"nextItem":{"title":"Demystifying Transaction Failures","permalink":"/blog/demystifying-transaction-failures"}},"content":"In this *Tips & Tricks* article, we will learn how to get a NEAR transaction hash by having the Aurora transaction\'s one.\\n\\n\x3c!-- truncate --\x3e\\n\\nLet\'s consider some random Aurora transaction for our tests, like this one: `0x36e2339784004c5dd40df74e663f1fe6683705a8ad665a05a9ad0aa4e11b559b`*.*\\n\\n### Aurora Helpers\\n\\nIf you\u2019re not interested in the code-solution, you can take a shortcut and use [*Aurora Helpers dApp*](https://aurora-helpers.vercel.app/aurora_to_near). Go there, paste Aurora\u2019s hash \u2013 and you\u2019ll get the result, e.g., for our test transaction, the result will be:\\n\\n![](https://www.datocms-assets.com/95026/1679324662-screenshot-2023-03-20-at-15-03-32.png)\\n\\n### NEAR Receipt: Hex\\n\\nAs developers, we\u2019re eager to know how to get all that information in our code directly without using any third parties. So let\u2019s disentangle that and find out how Aurora Helpers work underneath.\\n\\nFirst of all, let\u2019s configure our [*web3.js*](https://web3js.readthedocs.io/en/v1.8.2/) provider to be Aurora\'s mainnet endpoint and set `tx` variable:\\n\\n```javascript\\nconst mainnet = \'https://mainnet.aurora.dev\';\\nconst web3 = new Web3(new Web3.providers.HttpProvider(mainnet));\\n\\nconst tx = 0x36e2339784004c5dd40df74e663f1fe6683705a8ad665a05a9ad0aa4e11b559b;\\n```\\n\\nNow, we can get the NEAR transaction receipt by getting Aurora transaction receipt information with the [\\\\`eth_getTransactionReceipt\\\\`](https://ethereum.org/en/developers/docs/apis/json-rpc/#eth_gettransactionreceipt) EVM call:\\n\\n```javascript\\nconst getNearReceipt = async () => {\\n    const res = await web3.eth.getTransactionReceipt(tx);\\n    return res.nearReceiptHash;\\n};\\n```\\n\\nBy calling it, you will get the `hex-encoded` hash of the NEAR transaction receipt:\\n\\n`0x583237e9ef4d449cd828ff19668baa581a5532591058d3a886af65b80df7e938`\\n\\n### NEAR Receipt: Base58\\n\\nBut NEAR hashes should be `base58` encoded! And that is what we need to do next \u2013 let\'s add the `bs58` library and convert it:\\n\\n```javascript\\nconst bs58 = require(\'bs58\');\\nconst getNearReceiptBase58 = async () => {\\n   const receipt = await getNearReceipt();\\n   bufferHex = Buffer.from(receipt.slice(2), \\"hex\\");\\n   nearReceiptBase58 = bs58.encode(bufferHex);\\n   return nearReceiptBase58;\\n};\\n```\\n\\nThen, by calling `getNearReceiptBase58` and outputting result to the console, like this: `getNearReceiptBase58().then(console.log)`.\\n\\nYou\'ll get this result: `6wHHsKvNz2uaEaTyuqTDtLdhChQNtPXSfYJQYu7LrxFy`.\\n\\n### NEAR Tx Hash: Using Explorer\\n\\nAt this point, you can go to the NEAR Explorer, enter the receipt, and get your transaction information:\\n\\n![](https://www.datocms-assets.com/95026/1679325885-screenshot-2023-03-20-at-15-24-17.png)\\n\\nYou can check that this is the correct transaction by scrolling down and seeing the corresponding receipt hash in the Transaction Execution Plan section:\\n\\n![](https://www.datocms-assets.com/95026/1679325931-screenshot-2023-03-20-at-15-24-31.png)\\n\\n### NEAR Tx Hash: Using Code\\n\\nBut wait \u2013 we want to code this! How do we do it? No problem \u2013 we can get a NEAR transaction by sending a call to the NEAR Explorer endpoint with the receipt hash in it. Let\'s use a promise-based HTTP client called [Axios](https://axios-http.com/docs/intro) for doing this:\\n\\n```javascript\\nconst axios = require(\'axios\');\\nconst nearExplorerEndpoint = \'https://backend-mainnet-1713.onrender.com/trpc/utils.search?batch=1\';\\nconst getNearTxHash = async () => {\\n   const nearReceipt = await getNearReceiptBase58();\\n   const payload = {\\n       0: {\\n         value: nearReceipt,\\n       },\\n   }\\n   const response = await axios.post(nearExplorerEndpoint, payload);\\n   const transactionHash = response?.data[0]?.result?.data?.transactionHash;\\n   return transactionHash;\\n}\\n```\\n\\nAs you can see, you need to dig into the response result a little bit (in line 11), but we have already done that for you. By running this last script, you will get the final result which is:\\n\\n`7e5nRG8bYkJt1xRgBC38Veh2sA3fDrdepvPxHckojnut`\\n\\n### Conclusion\\n\\nWe\'ve discovered today how to convert Aurora transactions into the corresponding NEAR transactions in 3 different ways (AuroraHelpers, Code+Explorer, Plain Code).\\n\\nBy retrieving a NEAR transaction hash, you can now access all of the associated NEAR information behind it. It could be useful, for example, to understand how an Aurora Rainbow Bridge transaction or Aurora Engine works underneath. But that is the matter for the future articles to come!\\\\\\n\\\\\\nI hope you have enjoyed this short tutorial! Leave any questions or comments below. See you next time!"},{"id":"/demystifying-transaction-failures","metadata":{"permalink":"/blog/demystifying-transaction-failures","editUrl":"https://github.com/aurora-is-near/doc.aurora.dev/edit/master/blog/demystifying-transaction-failures.md","source":"@site/blog/demystifying-transaction-failures.md","title":"Demystifying Transaction Failures","description":"Getting transaction receipts and parsing Aurora Engine\'s transaction statuses","date":"2023-03-30T00:00:00.000Z","tags":[{"inline":false,"label":"Tips & Tricks","permalink":"/blog/tags/tips_and_tricks","description":"Short posts about tech for devs on Aurora"}],"readingTime":2.533333333333333,"hasTruncateMarker":true,"authors":[{"name":"Slava Karkunov","title":"DevRel","socials":{"x":"https://x.com/apocnab","github":"https://github.com/karkunow","linkedin":"https://www.linkedin.com/in/karkunov/"},"imageURL":"https://www.datocms-assets.com/95026/1677167398-photo_2022-12-02-14-55-03.jpeg","key":"slava","page":null}],"frontMatter":{"title":"Demystifying Transaction Failures","description":"Getting transaction receipts and parsing Aurora Engine\'s transaction statuses","date":"2023-03-30","authors":["slava"],"tags":["tips_and_tricks"],"image":"https://www.datocms-assets.com/95026/1682082259-dtf-article-cover.png"},"unlisted":false,"prevItem":{"title":"How to get NEAR transaction from the Aurora\u2019s one?","permalink":"/blog/convert-aurora-transaction-into-near-s-one"}},"content":"In this blog post, I want to discuss transaction failures on the Aurora blockchain and guide developers in understanding what exactly has happened with your transaction.\\n\\n*tl;dr: just use [**Aurora Helpers dApp**](https://aurora-helpers.vercel.app/aurora_to_near) and get the Near transaction error code there*\\n\\n\x3c!-- truncate --\x3e\\n\\n### *Errors and Explorer*\\n\\nOne common challenge that developers may face when dealing with transaction failures is the small amount of information provided by [*Block Explorer*](https://explorer.mainnet.aurora.dev/). While some errors may be clearly displayed in it, and at least give some clue about the problem:\\n\\n![](https://www.datocms-assets.com/95026/1679334253-screenshot-2023-03-16-at-20-55-40.png)\\n\\nOthers may not provide any information at all, leaving developers wondering what went wrong and how to fix it:\\n\\n![](https://www.datocms-assets.com/95026/1679334351-screenshot-2023-03-16-at-20-56-46.png)\\n\\nLet\'s take one of those transactions which fai `Error: Unknown`, e.g., `0x36e2339784004c5dd40df74e663f1fe6683705a8ad665a05a9ad0aa4e11b559b`:\\n\\n![](https://www.datocms-assets.com/95026/1679336814-screenshot-2023-03-20-at-18-25-56.png)\\n\\n### Aurora Helpers Tool\\n\\nIn the case of an `Error: Unknown,` you just could go to the [*Aurora Helpers dApp*](https://aurora-helpers.vercel.app/aurora_to_near) and enter your transaction hash there to get the corresponding Near Receipt/Transaction:\\n\\n![](https://www.datocms-assets.com/95026/1679324662-screenshot-2023-03-20-at-15-03-32.png)\\n\\nBelow you will see the transaction status:\\n\\n![](https://www.datocms-assets.com/95026/1679350478-screenshot-2023-03-20-at-22-14-25.png)\\n\\nThat is it. The task is solved. You can see in Aurora Helpers directly what this status means, but we will talk a little more about those codes in the next section.\\n\\n### Error Types\\n\\nThose `07 03` numbers correspond to the `status` field of the Aurora Engine\'s transaction. The First number indicates the[Aurora Engine API version](https://github.com/aurora-is-near/aurora-engine/pull/299/files#diff-a0e4fe79c7aa101e4b4e969318e18bb3854f0f8607e4b56d5665e131f98fdfa8R116). And the second one corresponds to the [statuses](https://github.com/aurora-is-near/aurora-engine/blob/a00df8e7d83ae49c035348111cc89be28cb93dab/engine-types/src/parameters/engine.rs#L19-L26) which could transactions have inside the Engine after execution.\\n\\nLet\'s compile them into the list below:\\n\\n* 00 \u2013 Succeed: transaction has been executed successfully.\\n* 01 \u2013 Revert: transaction has been reverted, most likely because of internal contract terms.\\n* 02 \u2013 OutOfGas: execution ran out of gas.\\n* 03 \u2013 OutOfFund: not enough funds to start the execution.\\n* 04 \u2013OutOfOffset: an opcode accesses external information, but the request exceeds the offset limit.\\n* 05 \u2013 CallTooDeep: call stack is too deep.\\n\\nWe can create the enum map inside our code to convert easily between codes and error names:\\n\\n```javascript\\nconst TxErrors = {\\n  Succeed: 0,\\n  Revert: 1,\\n  OutOfGas: 2,\\n  OutOfFund: 3,\\n  OutOfOffset: 4,\\n  CallTooDeep: 5\\n};\\n```\\n\\nYou can use better-styled enums by using Enumify or just using Object.Freeze(), if you\'re interested \u2013 read more [here](https://masteringjs.io/tutorials/fundamentals/enum). But first, let\'s find out how to get this status field using a NEAR RPC request. We will use a simple Node.js code snippet to do this.\\n\\n### Calling NEAR RPC\\n\\nFirst, we will need the `getNearTxHash()` function from this article to get the corresponding NEAR transaction hash: [How to get NEAR transaction from the Aurora\u2019s one?](/blog/convert-aurora-transaction-into-near-s-one). We are assuming that this code is already written in your code editor.\\\\\\n\\\\\\nSecond, we will use this helper function to convert `base64` encoding into `decimal` format:\\n\\n```javascript\\nfunction base64ToDecimal(str) {\\n   const text = Buffer.from(str, \'base64\').toString(\'ascii\');\\n   \\n   const decimalArray = []\\n\\n   for (let i in text) {\\n     decimalArray.push(text.charAt(i).charCodeAt(0))\\n   }\\n \\n   return decimalArray;\\n }\\n```\\n\\nWe\'re ready to query the NEAR RPC node (you can get endpoints [here](https://docs.near.org/api/rpc/setup)) using the Axios HTTP client. Notice that we\'re using `archival-rpc` here to query also historical data (older than  [epochs](https://docs.near.org/concepts/basics/epoch) or ~2.5 days):\\n\\n```javascript\\nconst getTransactionStatus = async () => {\\n   const hash = await getNearTxHash();\\n   const nearRPC = \'https://archival-rpc.mainnet.near.org\';\\n\\n   const response = await axios.post(nearRPC, {\\n       jsonrpc: \'2.0\',\\n       method: \'tx\',\\n       params: [hash, \'aurora\'],\\n       id: 1,\\n   })\\n\\n   const status = response?.data?.result?.status?.SuccessValue\\n   const sliced = base64ToDecimal(status).slice(0, 2));\\n   /*just for demonstration purposes*/\\n   console.log(\'status\', status);\\n   console.log(\'status\', base64ToDecimal(status));\\n   console.log(\'status\', sliced);\\n   return sliced;\\n }\\n\\n getTransactionStatus();\\n```\\n\\nBy running the code above you will get this output:\\n\\n```bash\\nstatus BwMAAAAAAAAAAAAAAAA=\\nstatus [\\n  7, 3, 0, 0, 0, 0,\\n  0, 0, 0, 0, 0, 0,\\n  0, 0\\n]\\nstatus [ 7, 3 ]\\n```\\n\\n\\\\\\nAs you can see, we have a `base64` encoded status field in the first line. Then we decode it into decimals and, after it \u2013 slice the first two numbers (others are not in use right now). They\'re precisely the ones we\'ve been expecting! We have an `OutOfFund` error. Now we can use the JSON map from the beginning of the article `TxErrors` to convert transaction status into a readable format:\\n\\n```javascript\\ngetTransactionStatus().then((status) => {\\n  for (var key in TxErrors) {\\n      if (TxErrors[key] == status[1]) {\\n          console.log(\\"Transaction has status: \\" + key);\\n      }\\n  }\\n});\\n```\\n\\n### Final Thoughts\\n\\nIn this post, we\'ve learned how to get the info about Aurora Engine transactions errors which sometimes could be hidden from the naked eye inside the corresponding NEAR transaction.\\\\\\nAnd all of that was done purely with JS code.\\\\\\n\\\\\\nI hope you had fun while reading this! Leave us your feedback, comments, and thoughts below."}]}}')}}]);